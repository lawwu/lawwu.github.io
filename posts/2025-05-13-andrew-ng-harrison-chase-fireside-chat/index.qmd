---
title: Andrew Ng & Harrison Chase Fireside Chat
author: Lawrence Wu
date: '2025-05-14'
categories: [ai, events]
---

The questions and answers extracted from the fireside chat between Harrison Chase (LangChain) and Andrew Ng (AI Fund) at LangChain Interrupt 2025.

---

## Q1: What is “agenticness,” and has your thinking changed?

**Andrew Ng:**  
The debate over whether something "is an agent" is less productive than discussing *degrees of autonomy*. It's more useful to see systems on a spectrum—from simple automation to full autonomy—rather than binary classification. Many business workflows are linear and agentic to a low degree but still valuable.

---

## Q2: What skills are most important for building agent systems?

**Andrew Ng:**  
- Break down complex tasks into modular steps  
- Define the right KPIs (including evals)  
- Interpret traces, debug step-by-step  
- Develop “tactile knowledge” by building, testing, and iterating  
- Use many tools to strengthen decision-making intuition

---

## Q3: Is that tactile knowledge mostly about LLMs?

**Andrew Ng:**  
It extends beyond LLMs. Think of tools like Lego bricks—the more diverse your pieces, the more flexible your build. You need squiggly, odd-shaped blocks sometimes, not just standard ones. Practicing with a wide toolset helps build strong product instincts.

---

## Q4: What “Lego bricks” are underrated?

**Andrew Ng:**  
**Evals.**  
People think they need to be comprehensive and perfect. Start with something fast and imperfect—5 examples and a simple check. Use it to catch regressions. You'll naturally improve it over time.

---

## Q5: Any underrated application areas?

**Andrew Ng:**  
**Voice stack applications.**  
They’re low-friction for users but underexplored. Latency expectations make them hard (users expect 1–2s responses), but agents + voice stack pipelines are more controllable than end-to-end speech models.

---

## Q6: Is building voice agents similar to text-based ones?

**Andrew Ng:**  
Skills are transferable, but differences matter:
- Voice has tighter latency constraints
- Pre-response fillers (“Hmm…”) help mask lag
- Background noise helps users tolerate delays
- Voice interactions are more forgiving and expressive than typed ones

---

## Q7: Thoughts on MCP (Model Component Protocol)?

**Andrew Ng:**  
MCP is a promising step toward standardized tool calling and integration.  
Today’s structure is flat, but future versions need hierarchy and composition.  
MCP could help unify models, tools, and data across ecosystems.

---

## Q8: What about agent-to-agent protocols?

**Andrew Ng:**  
Still early. Multi-agent systems work within single teams, but cross-team agent collaboration isn’t there yet. We’re a few steps away from successful real-world examples.

---

## Q9: Do you like the term “vibe coding”?

**Andrew Ng:**  
Not really.  
The name is misleading—it sounds effortless, but it's cognitively intense.  
Coding is becoming more accessible, not obsolete.  
Understanding how code works is still essential for prompting and debugging.

---

## Q10: Advice for AI startup founders?

**Andrew Ng:**  
- **#1 predictor of success: SPEED**  
- **#2: Technical depth**  
Business knowledge is widespread, but deep tech knowledge and instincts are rare and differentiating.

---

## Full Transcript

Transcribed by whisper-small

[INAUDIBLE] This is a track that we see more and more as a lot of the building blocks are starting to get figured out. I'm really excited for this next section. So we'll be doing a fireside chat with Andrew and Andrew. Probably doesn't need any introduction to most of our stuff here. I'm guessing a lot of people are thinking as soon as classes begin to work, Sarah will learn deep learning. But I have to admit that this is a big part of the building thing of the story. So I met Andrew a little over two years ago at a conference. We started talking about LinkedIn and he graciously invited us to do a course on LinkedIn. He's learning, I think, in my son's best of a second or third one that they ever did. And I know a lot of people here would probably watch that course or I started on LinkedIn because of that course. So Andrew has been a huge part of the LinkedIn journey and I'm super excited to welcome him on stage for a fireside chat. So let's welcome him to it. [Applause] [Music] [Inaudible] [Inaudible] You've obviously touched and thought about so many things in this industry. But one of their takes that I cite a lot and probably people have talked about is your take on kind of like talking about the agendicness of an application as opposed to whether something is an agent. You know as we're here now at an agent conference, maybe we should rename it to an adjunct conference, but would you mind clarifying that? And I think it was like a year and a half, two years ago that you said that and so I'm curious if things have changed in your mind since then. I remember I mentioned, how was it when I spoke at a conference over a year ago and at that time I think both of us were trying to convince a lot of people that agents are a fling machine. And that was before maybe I think it was this summer last year, a bunch of law underscored the agent in terms of starting to save that sticker everywhere it was. But to her, especially, I mean about a year and a half ago I saw that long people are arguing this is an agent, this is not a particular thing. My presence is a child of law, this is not an agent. And I felt that it was not at the argument that we would succeed. And I think that as a community we just say that there are decreases in something that is an agent. So then we just say that if you want to know an agent system, you can move with autonomy or a lot of autonomy, there's a high ability to spend time arguing. This is truly an agent. That's just how it seems an agent system to a different decrease in autonomy. And I think that actually hopefully producing a ton of people, at least it's been argued that something is an agent. This is called an all-agent thing. Where on that spectrum of kind of like a little autonomy to a lot of autonomy do you see people building for this system? So on the team, the team uses many of these problems, right, with complex problems and so on. I'm also seeing tons of these opportunities that frankly are fairly in danger for a food system, they're just vocational cyber-assures. So a lot of businesses are opportunities where you're right now with people looking to form a website, doing a website, checking something. They would be able to see if it's a compliance issue or if there are some issues, some certain stuff too. It's kind of like take something, copy paste it into a website, do it in a different way. So in business processes they're actually a lot of fairly free work. Those are linear with very small business-paginal branches. Usually you could look into a failure with a rejected smartphone though. So I see a lot of work too. But one of my challenges I see businesses have is it's still pretty difficult to look at some stuff that's being done in business and figure out how to turn it into a new, gender-work mode. So for this degree of granularity, we should try to bring down the state into a micro-touch and then out to people in the financial prototype. It doesn't work well enough. Originally, SEVS team worked hard to improve performance. I think that whole bag of skills on how to look at a bunch of stuff that people are doing, break into sequential steps, where the small number of branches hardly put in place in the VALS, all that, that skillset is still hard to work with. And then of course in the national conference agency, I think you heard much about the very complex and most stuff that's very valid as well. But I see much more in terms of number of opportunities that are now valid. There's a lot of simple things that I think are still being done as well. Let's talk about some of those skills. So you've been doing deep learning and a lot of courses are in pursuit of helping people kind of build a general. So what are some of the skills that you think each and every one of those all across the spectrum should kind of like master and get started with? Well, it's a good question. I wish I could answer that. I think a lot about this actually is that I think one of the challenges of having a business process run through your law firm, which would be compliance, people, and the job, whatever the steps. How do you put the business in the background, type integration, how to see if the CEP helps us on that too, to adjust the data, and then how do you process and model steps to build this into a system? And one thing I see about this, putting in place the right key values for your work, to not only understand the performance of your process, but to trace the individual steps, to put in less than one step that is broken, less than one step that is broken to work on. I find that a lot of the teams probably would walk in the nation just using changing key values very effectively. You can sit there and talk about your own things. I see most teams probably slowly take over the place of key values, systematic values in this item. But I find that having the right mistakes, slowly taking two days to college, is still really difficult. The school teams, the teams are still learning how to deal with the off and build-down line-out of these very recent, like a few months, trying to improve one group or another. The most, as he would say, I don't think this can ever be made to work, so just don't just find the different variables as well. I wish I had been more efficient to get this almost tactile knowledge. Often you're there, you know, look at the output, look at the trace, look at the last output, and just sort of make a decision, right, in minutes or hours on the two-to-mix, and that's still very difficult. And is this kind of like tactile knowledge mostly around LLMs and their limitations, or more around like just the product, bringing those things and that skill of taking a job and breaking it down, that's something that's still getting to us. I think it's all we need, actually. So I feel like over the last couple of years, the AI2 companies have created an amazing set of tools that this includes tools like, you know, that graph also helped you. I guess like, how do you think about the chat box, of many, many different ways of approaching family, and what else, how do you believe that was helping with the audience. But I feel like there's this, you know, one strong link, a range of various I think tools. But what I'm trying to have in my head is, if all you have are, you know, purple makeup breaks, right, you can't build out a GCC stuff. And I think of these tools as being the kinds of makeup breaks, right, that the more tools you have, it's as if you don't just have purple makeup breaks, but the red one, the black one, the yellow one, the blue one. And as you get more different colors and shades of makeup breaks, you can very quickly assemble them into really cool things. And so I think a lot of these tools, they want those random products, different types of makeup breaks. And when you're trying to build something, you know, sometimes you need that very squiggly, weird-shaped makeup break, and some of you want to go with a makeup bucket, and just get the job done. But if you've never built e-dots at a certain time, then, you know, then you could actually end up spending three or two months doing something that someone else has done that before, because they all, well, we should just build e-dots this way, just to know how to manage it more. And just go through that process and get it done much faster. So one of the unfortunate things about AI is that it's not just one tool that in my coding, I just use a whole bunch of different stuff, right, a lot of master, and I've stopped myself from doing enough tools to set that up. And I think how that practice with different tools also helps a lot of the chasm decision making. And one of the things, they've also changed, so for example, just all of a sudden, having longer, longer context, longer best practices, or rag, from, you know, a year and a half ago, or whatever, much less than today. You know, and ever, Harrison was pretty early, he took off the same cycle, played with a early man, changed rag frameworks, the crystal civilization and all that. As Elm Contest Reviews got longer, now we've just done the long stuff into our columns. As Elm's practice got way, but the hyper-fronted team has gotten way easier. It's a huge range of hyper-fronted that we're, you know, just fine. So as Elm keeps practicing, the instincts will be holy, you know, two years ago, but they won't be helping rather than you want to. You mentioned a lot of things that I want to talk about. So, okay, what are some of the level breaks that are maybe underrated right now that you would recommend that people aren't talking about? Like, e-balls, I think, we have had, we have three people talking about e-balls, and I think that's top of people's mind. But what are some things that most people maybe haven't thought of or haven't heard of yet that you would recommend that we're moving into? Good question. I don't know. I'm sure, even though people talk about e-balls, there's some ways that people don't do it. I think it's because people often have, I saw a post on e-balls right this long, people think of writing e-balls as this huge thing you have to do, right? I think that e-balls is something I'm going to fill together really quickly, you know, in 20 minutes, and it's not that good, but it starts to complement my human eye-ball e-balls. And so what often happens is that our system has this one problem, right, do you want to get an e-bression? I thought I made it work, and it breaks, I'm sure our average of $1,000 has gotten a $1,000. Then the code is a very simple e-mail, maybe with, you know, five different examples, and some very simple administration to just check for this one regression, right, to this one thing. And then I'm not swapping out human e-mails for a multimeter e-mails, and I'm still looking all through my cell, but when I change something out from just e-mails to just take this word and something, psycho-pattern thing about it, and then what happens is, just like the way we write English, maybe, once you have some slightly helpful but clearly very broken imperfect e-mail, then you're sad, you know what, I can improve my e-mail to make it better, and I can improve the e-mail to make it better. So just as when we build a lot of applications, we build some very quick and dirty thing that doesn't work, and we improve e-mail better. From all of the way I go e-mails, I go really all-only-mails, they're very home, and then when you look at what it does, you go, you know, it's just e-mails broken, I can fix it, and you improve my e-mail to make it better. So that's one thing. Actually, one thing that people have talked about, and I think is so automated, is the voice stack. This one thing is that I'm actually very excited about voice applications, a lot of my friends are very excited about voice applications. I see a bunch of logic interfaces, very excited about voice applications, very logic, very logic interfaces. For some reason, while there are some developers in this community to voice the amount of developer attention on voice stack applications, there is software, it's not really a good thing, but that's one thing that feels so much smaller than the large enterprise of the important ICS, which is what's happening on the market. And not all of this is the real-time voice-in-house, it's not all speech-to-speech-native, what we're working on, all of this. I find those models are very hard to control, but we use more of an agent-to-e-voice stack for the code, which is great, which we find much more controllable. So, in the end, I've been working with a ton of teams on voice stack stuff that some of which hopefully did not seem to be a big problem. And then, other things that are automated, one of the ones that make this not automated, and one of those that should do it, I think many of you have seen that developers that use AI systems in our company is so much faster than developers that don't. I've been, it's been interesting to see how many companies, CIOs and CTOs still have policies that don't let the geniuses use AI systems in their company. I think maybe sometimes they're good reasons, but I think we have to work with them, because I think my teams in our hour just hate to ever have to code again with AI systems in their company, so I think some of this is just something different. I think underrated is the idea that I think everyone should learn to code. One fun fact about AI fun, everyone in the iPhone, including the person that runs out front is perceptionist, and my CFO, and my attorney, and the general counsel, everyone in the iPhone actually knows how to code. It's not that one day to solve it, it's not that they respect their job functions, maybe as a member of the code, but they're able to tell the computer what they wanted to do, and so it's actually driving the whole productivity across all of these job functions that are not solved in AI. Talking about AI, what tools are you using for that first time? So, we're working on something that will not get announced. Exciting. So, maybe I do use cursor, red server, and some other things. Alright. Talking about voice, if people here want to get into voice and they're familiar with building kind of like agents with LLMs, how similar is it? Are there a lot of ideas that are transferable, or what to do, what will they have to learn? So, in terms of the applications where I think voice is important, to increase certain interactions that are not much more important, in terms of the application perspective, input text problems are kind of intimidating. For other applications, we're going to use the same type of machine, because it's a local text problem, very much a text problem. That's very intimidating for users. And one of the problems with that is people can use backspace, and so people are just slowly learning to respond via text. Whereas, the voice, time rules for when you're just thinking, talking, you could change your mind, and you could say, "Oh, I changed my mind to get that early thing that I wanted, which is pretty good to do." But I find that the amount of applications for the user are friction to just giving them to use in this little way. So, you know, tell me what you think, and then they respond to voice. So, in terms of voice, one of the biggest differences in terms of agent and client is the expectancy, is if someone says something, and I don't really want to respond, you know, in some point or second, right? And that's a fact that in those seconds is great, but really, I'm going to use something in a second. And with a lot of agent work flows that were run for many seconds. So, when you do that, then I want to grow avatar to build an avatar, and that is on my vision, tell the avatar if you want. I mean, this show version had kind of, I think, nine seconds of this, and it's just an ad user experience. So, it's something, you know, nine seconds of silence that might have to respond. But some of the building things went from a kind of pre-response. So, just as if you ask a question, I go, "Huh, that's interesting." [laughter] So, how to basically do that to hide the latency, and it actually seems to work great. And there are all these other little tricks as well. So, if you're building a voice console service to chatbot, it turns out that when you play background noise at a console contact center, it's a dead silence. People are much more sensitive of that, of that latency. So, I find that there are all of these things that are different in a pure text based algorithm. But in applications where a voice based modality doesn't use to be comfortable and just not talking, I think it's sometimes really good to use this to use a friction. So, I'm going to give you some information on that. I think when we talk, we don't feel like we need to deliver perfection as much as we're afraid. So, somehow, you see a bridge just starting to tell your ideas and change them on, and then we're going to fail. And that lets us get the information from them that we need to help you use it to the point. [inaudible] Hi. [laughter] One of the new things that's out there you mentioned recently is MCP. How are you seeing that transform of how people are building apps, what types of apps are building or what's happening in the ecosystem? Yeah, I think it's really exciting. Just this morning, we released a new enthralment, I'm sure, was an MCP. I actually saw a lot of stuff, you know, on the internet on MCP that I found quite confusing. So, what's going on there is that, you know, let's put a really good short pause on MCP that explains security. I think MCP is fantastic. I think it's very clear, properly, that that open app adopted it. Also, I think it's based on the importance of this. I think the MCP's standard won't continue to evolve. So, for example, I think many of you know what MCP is, right? It's much easier for agents primarily, but frankly, I think other types of software took over the two types of data. When I'm using OBS myself or when I'm building applications, frankly, for all of us, we spend so much time on the platform, right? So, I think, for those of you from Washington, Pryce, as well, the AI, especially, you know, using OBS, are pretty darn intelligent to evolve stuff when doing the right context. So, I found that I spent my time working and applying on the data integration to get the context of the OBS to make it feel like it's something that offers a pretty sensible market spread for the context. So, MCP, I think, is a fantastic way to try to standardize interface to other tools. You can call us as well, say, as well as this. It feels like, it feels a little bit like, wow, as long as the MCP serves, you finally internet do your work, right? And then the authentication systems are kind of, you know, even for the very large companies, you know, the MCP service of the company, the nuclear authentication token, token worlds, and these bias along that way on. I think the MCP protocol itself is also really, right now, MCP gives a long list of the resources in the role. You know, eventually, I think we'll be something more hierarchical and destructive. So, imagine you want to build something, I don't know, I know that there will be an MCP interface to a land graph, but land graph is still the API calls, you just kind of have like a long list of everything under the sun for agents to sort out. So, I think MCP is a really good task at first step. Definitely encourage you to learn about it. It won't make your life easier. Probably, you'll find a good MCP service in the communications service, in the communications operations. I think what we're important is this idea of, you know, any models for agents and data sources, they show up in any type of effort to do all the integration and plus them. I think MCP is a fantastic first step. It will need to be all like a fantastic first step to what the data integration is. Another type of protocol that seems less likely than MCP is the agent-to-agent system. And I remember when we were in Harvard a year or so ago, I think you were talking about multi-agent systems, which this kind of enabled. So, how do you see some of the multi-agent or agent-to-agent stuff of the protocol? So, I think, you know, agent and AI are still so early. Both of us, right, we struggle, we didn't make our code work. And so, making my code, my agent work with someone else's agent, it feels like a two-miracle. [laughter] So, I see that one team is building multi-agent systems. That often works because people have a bunch of agents, they can be themselves and their protocols, that works. But right now, at least at this moment in time, maybe I'm off. The number of examples I'm seeing of when, you know, one team's agent and correction agent successfully made agents, it's totally different teams' agent and correction agents. I think we're a little bit early to that. I'm sure we'll get there, but I'm not personally seeing, you know, real success, pure success stories of that. Yeah, I don't think that's true. No, I think it's super early. I think if MCP is early, I think the agent stuff is super early. Another thing that's kind of like top of what's mine right now is it's kind of vibe coding. And all that, I touched on it a little bit earlier with how people are using these AI coding systems. But how do you think about vibe coding? Is that a different skill than before or what kind of a mis-disaster? Yeah, so I think many of us code, we're barely looking at the code, right? I think it's a fantastic thing to do. I think it's unfortunate that that code, "vine coding" is misleading a lot of people. I think it just goes by, you know, just like that. And frankly, when I'm coding for a day, you know, with vinyl or whatever, I forget code systems, I'm frankly exhausted by the end of the day, so I'm thinking it's an Android device. And so I think the name is unfortunate, but the phenomenon is real and it's been taking part in this great. So, I mean, over the last year, a few people have been advising others to come up to code on the basis that they have more to be coding. I think we'll back this on the worst career advice that we've ever done. Because over the last many decades, as coding is getting easier, more people started to code. So it turns out, you know, when we went from punch-cost to key-cost, that's how it went, very well. But it turns out, actually, thousands of variable algorithms went probably from a sending language to a literally code wall. There were people arguing back then, "Yeah, code wall is so easy, we don't need programs anymore." And I'll say, it's getting easier, more people are going to code. And so, we've been coding systems, more people should code. But I think, and it turns out, one of the most important schools in the future for developers and developers, is the ability to tell a code to exactly what you want, so they want to do it for you. And I think understanding at some level, which I'll be talking about, understanding at some level how a computer works, lets you prompt on a stronger future, so they're much more accessible. Which is why I still try to advise everyone to learn one program, and I try to hide them by something. And then, I think some of you know this, but I personally about, you know, a much stronger height than developer, I did say JavaScript, right? But with AI system coding, I now write a lot more JavaScript in types of code than I ever used to. But even with debugging, you know, JavaScript code, that something else, really understanding what are the error cases, what does that mean, that it's pretty difficult to write on JavaScript. If you don't like the name "by" coding, do you have a better name for "by"? Oh, that's a good question. I shouldn't think about that. We'll get back to you on that. One of the things that you announced recently is a new fund for AI funds, so if you grab some of that, for people in the audience who are really thinking of starting a startup, what advice would you give them? So, in front of the just studios, we build companies, and we have to consider the investment companies that we co-founded. So, I think in terms of running back on AI funds lessons learned, I would say that the number one predictor of a startup success is split. I know it's looking value, but I see it all the people that I've never seen yet, the speed through which a skilled team can execute, and if you've never seen it before, I know many of you have seen it. It's just so much faster than anything that slow businesses can hardly do. And I think the number two predictor also very important is tech-con knowledge. It turns out that we look at the schools in the new sector to some things like how we market, how we sell, how we price. All that is important, but that knowledge has to be constantly more widespread. The knowledge that's really rare is how this technology actually works, because technology evolves so quickly. So, I have deep respect for good market. How good pricing is hard, how good marketing is hard, position is hard, but that knowledge is more diffused. And the most rare reason is somewhat, they're being understood how the technology works. So, what I found really is that there are community tech-con people that have good instincts, understand, do this, don't do that, just as good ties as that. And then I think along with the business stuff, that the knowledge is very important to the transition needs here to figure out. Alright, that's great advice for starting something. We are going to wrap this up. We're going to go to a break now, but before we do, please join me in giving Andrew a big hand. [Applause] Our next session is in 15 minutes. [Indistinct conversation] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] 
