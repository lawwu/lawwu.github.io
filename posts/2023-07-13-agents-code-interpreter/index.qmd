---
title: "Data Analysis/Science Agents and Code Interpreter"
categories: ["LLMs", "Agents", "Data Analysis", "Data Science", "Code Interpreter"]
---

In this post I'll go over some observations I've had while seeing the output of two types of AI agents. Both are able to do data science and data analytics tasks. One is based on `langchain` and `gpt-3-5.turbo` (but could be swapped with `gpt-4` to improve the results) and is available via an API. The other is OpenAI's Code Interpreter, which is not available as an API, only through the ChatGPT web interface for ChatGPT Plus subscribers ($20/month). 

Overall I am quite impressed with Code Interpreter's capabilities. I would characterize Code Interpreter as a very capable intern whose output you need to validate. That being said it is a very capable agent in doing data analysis tasks. I would estimate this analyses took me 20 minutes to do. If I actually wanted to do it, I'd estimate it woudl've taken me 2 hours, so 6x longer. But it's not just a matter of time savings, it is a matter of cognitiive-load savings. It was not very cognitively-intense to use Code Interpreter whereas I, a human, doing these analyses would've taken me a lot of mental energy. Because of that, I'd held off on running this type of analyses for a long time (sitting on this idea for a year?) but with Code Interpreter, I was able to do it in 20 minutes. And this opens up many other analyses that I would love to do but have not had the time or energy to do.

# Agents with `langchain`

I'm currently working my way through the [Databricks LLM101x Course on EdX](https://courses.edx.org/courses/course-v1:Databricks+LLM101x+2T2023/c). It's actually pretty good. During the third section, there was this interesting example where they created a data science agent called `DaScie`. Given a prompt, the agent was able to carry out some interesting tasks.

## Setting Up the Agent

First to define the agent using `langchain`, `OpenAI` and then giving it some tools.
```python
# For DaScie we need to load in some tools for it to use, as well as an LLM for the brain/reasoning
from langchain.agents import load_tools  # This will allow us to load tools we need
from langchain.agents import initialize_agent
from langchain.agents import (
    AgentType,
)  # We will be using the type: ZERO_SHOT_REACT_DESCRIPTION which is standard
from langchain.llms import OpenAI

# For OpenAI we'll use the default model for DaScie
llm = OpenAI()
tools = load_tools(["wikipedia", "serpapi", "python_repl", "terminal"], llm=llm)
# We now create DaScie using the "initialize_agent" command.
dascie = initialize_agent(
    tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True
)
```

