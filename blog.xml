<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Lawrence Wu</title>
<link>https://lawwu.github.io/blog.html/blog.html</link>
<atom:link href="https://lawwu.github.io/blog.html/blog.xml" rel="self" type="application/rss+xml"/>
<description>This is Lawrence Wu&#39;s personal website</description>
<generator>quarto-1.8.27</generator>
<lastBuildDate>Fri, 16 Jan 2026 00:00:00 GMT</lastBuildDate>
<item>
  <title>Amazon and Costco</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2026-01-16-amazon-costco/</link>
  <description><![CDATA[ 




<p>I’ve had the chance to take my kids on various field trips this year as we’ve been homeschooling them. Two of the more interesting ones were to Costco and Amazon. I love Costco, it’s probably <a href="https://lawwu.github.io/posts/2024-02-28-ode-to-costco/index.html">my favorite retailer</a>. My family looks forward to going every time we go. Anything I can’t get at Costco is likely bought from Amazon. Amazon is the second largest retailer in the US while Costco is #3 (Walmart is #1).</p>
<p>Before sharing some of the things I learned, it was clear both businesses seemed like well-oiled machines. Amazon certainly had a lot more automation and technology deployed in their warehouse which I was very impressed by.</p>
<p>One of the points of contrast was working as a retail employee at Costco seemed much better than in an Amazon fulfillment center (FC). On a basic level, there was virtually no natural light in the FC I toured. It was also quite loud inside. This created a dungeon-like sort of feel. The work environment in the Amazon FC seemed challenging too where it seemed like you are largely isolated (stowing, picking or packing items) for most of your 10-hour shift. At least in the Costco retail location, there is natural sunlight. Overall the work environment at a Costco seems healthier. It was a little hard to find data on the average employment tenure of a worker in one of these FC but California counties with Amazon FC in them have <a href="https://www.nelp.org/insights-research/amazons-disposable-workers-high-injury-turnover-rates-fulfillment-centers-california/#_edn6">higher turnover rates on average</a>. Costco famously has on average high employee tenure where on average their employees are there <a href="https://www.costco.com/f/-/sustainability-people">9 years</a>.</p>
<p>I learned a lot about both businesses. My goal in taking my kids was for them to understand and appreciate how some of the businesses we use frequently operate. I share some of the things we learned below.</p>
<section id="costco" class="level1">
<h1>Costco</h1>
<p>Probably my favorite field trip taken so far. They had Costco name tags printed for all the kids along with kid-sized red aprons. I was disappointed they didn’t print name tags for the adults. And of course they gave all the kids a bag full of Kirkland signature items as a parting gift.</p>
<p>Some things I learned:</p>
<ul>
<li>911 Costcos worldwide</li>
<li>$320k monthly rent payment at this one Costco</li>
<li>Busiest are in Tokyo and Taiwan</li>
<li>312,000 total employees</li>
<li>300 employees at this Costco</li>
<li>Costco is 3rd largest retailer: Walmart and Amazon are larger.</li>
<li>Sell more wine than anyone</li>
<li>Only 4,500 items sold</li>
<li>4 Pennies out of $1 is profit</li>
<li>$900,000 per month in bills</li>
<li>highest grossing item is Kirkland toilet paper, $44,000 sold per week. If the Costco sells gold then it typically is gold.</li>
<li>$17M in merchandise at the store at any given time</li>
<li>Bakery
<ul>
<li>$55,000 of baked goods sold per per week</li>
<li>Thanksgiving is double</li>
<li>8,000 pumpkin pies per year. For Thanksgiving they have to run 3 consecutive 8 hour shifts to make enough pumpkin pies.</li>
</ul></li>
</ul>
</section>
<section id="amazon" class="level1">
<h1>Amazon</h1>
<p>We toured an Amazon fulfillment center (FC) in Eastvale, CA. I <a href="https://events.amazontours.com/na/onsite/LGB3">booked the tour here</a>. Really eye opening.</p>
<ul>
<li>We visited a FC named LGB3. Every FC is named after the closest airport. Ontario (ONT) is the closest but I think they already had ONT1-ONT9, so the one we visited was named after the next closest airport or Long Beach (LGB).</li>
<li>Our tour guide was fantastic. She was so patient in answering all of our questions!</li>
<li>They didn’t allow any phones on the tour</li>
<li>1,000 employees work at LGB3</li>
<li>5,000 employees during peak holiday season</li>
<li>600,000 packages per day</li>
<li>1M+ packages per day during peak season (Thanksgiving to Christmas eve)</li>
<li>Only one day off, Christmas, otherwise the FC runs 24/7 with only two other days where it is closed for half a day to do maintenance</li>
<li>Amazon does have free tuition support for workers to pursue a degree. They actually do not need to pay this back if they leave which is a nice perk.</li>
<li>Amazon workers also get free Amazon prime as of 2025</li>
<li>This one in Eastvale handles packages smaller than a microwave.</li>
</ul>
<p><img src="https://lawwu.github.io/blog.html/posts/2026-01-16-amazon-costco/images/amazon-pod-2016.avif" class="img-fluid"></p>
<ul>
<li>Stow: Amazon’s inventory is kept in these shelves called pods like the one above. The <a href="https://www.theguardian.com/technology/2016/aug/18/amazon-to-open-packing-centre-in-essex">picture is from 2016</a>. It’s interesting the pod hasn’t changed all that much. They still are yellow and sit on top of these flat robots (Amazon bought a robotics company called Kiva and renamed it Amazon Robots). The process of stowing is a robot will bring a pod over to a worker. The worker then puts items into the cubbies in the pod. I was really surprised to learn Amazon randomly distributes items across shelves. They do this so there’s a higher chance a pod with an item someone orders is close to a person who’s job it is to pick the item.</li>
<li>Pick: Pickers are workers who find the items that have been ordered from Amazon’s inventory. They used to walk 15+ miles with a shopping cart up and down aisles grabbing things. Now these pickers are largely stationary because robots bring these large shelving units with inventory, there’s a projector shining a light on the right cubicle with the item and the worker picks the item out and puts it into a yellow bin.</li>
<li>I do wonder if the technology for robotic arms gets good enough will the stow and picking roles be completely automated. These jobs are not the most desirable and the moment this becomes cheaper than hiring people, I imagine those jobs will be replaced.</li>
<li>Pack: this FC had two packing departments, pack-single and pack-multi. If you order one item it goes to pack-single, otherwise it is packed by a department that works on multiple items going into one package. The computer recommends the size of box. The computer also prints the right size tape. But it’s still a manual process of the worker making the box, taping the ends, putting the item(s) in, packing it (Amazon doesn’t use plastic for this anymore), taping it shut and sending it to the next department.</li>
<li>SLAM: Labeling. There is a barcode called the “spoo” that has a bunch of information about the order. Once a box get to this department, it’s red by a high speed scanner, within a second, a label is generated and then put onto the box.</li>
<li>After this, the packed and labeled packages go down massive conveyer belts and are loaded onto trucks that go to sortation facilities. At these locations, the packages are sorted by zip code and then delivered.</li>
<li>While walking the floor, there is a “QB” or quarterback station. There were 4 large monitors, one for each floor of the warehouse. On each screen were thousands of dots, each one representing the robots moving shelves/pods around.</li>
<li>For same-day or overnight deliveries, some of the steps above are skipped.</li>
<li>Yesterday I placed an order at 4pm. It was shipped at 7pm. It arrived at my doorstep at 5am. Amazing stuff Amazon.</li>
</ul>


</section>

 ]]></description>
  <category>personal</category>
  <guid>https://lawwu.github.io/blog.html/posts/2026-01-16-amazon-costco/</guid>
  <pubDate>Fri, 16 Jan 2026 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Year in Review - 2025</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/</link>
  <description><![CDATA[ 




<p>This is the first time I’m taking some time to do a year in review and posting it on my blog. Overall I’ve enjoyed the exercise of writing and sharing ideas about things I’ve learned across a variety of topics with others. The main categories I’ve written about thus far are about AI and personal finances. I wrote my first <a href="https://lawwu.github.io/posts/2025-11-24-little-theology-of-exercise/">book review</a> and would like to write more of those. I’d like to also continue blogging next year.</p>
<p>In this review, I’ll go through blogging, books I read, reflections in Biblical counseling, review of personal finances this year, running and AI (mainly some thoughts on agentic coding and Claude Code).</p>
<section id="blogging" class="level2">
<h2 class="anchored" data-anchor-id="blogging">Blogging</h2>
<p>I started blogging in 2023. The first post I wrote was about <a href="https://lawwu.github.io/posts/2023-03-24-mac-apps/" target="_blank">useful Mac applications</a>. I wrote 20 posts in 2023, 11 posts in 2024 and 16 posts in 2025. Right now I mostly share my posts on Facebook and LinkedIn. The most popular posts by views:</p>
<ul>
<li><a href="https://lawwu.github.io/posts/2025-05-23-langchain-interrupt-2025-recap/" target="_blank">2025-05-23: LangChain Interrupt Conference 2025 AI Recap</a></li>
<li><a href="https://lawwu.github.io/posts/2025-12-19-bunching-strategy/" target="_blank">2025-12-19: Bunching Charitable Contributions in 2025</a></li>
<li><a href="https://lawwu.github.io/posts/2025-10-30-first-marathon-reflections/" target="_blank">2025-10-30: First Marathon Reflections</a></li>
<li><a href="https://lawwu.github.io/posts/2025-07-18-claude-code-camp/" target="_blank">2025-07-18: Claude Code Camp - hosted by Every</a></li>
<li><a href="https://lawwu.github.io/posts/2024-05-23-first-axolotl-finetune/" target="_blank">2024-05-23: Finetuning LLMs with Axolotl</a></li>
</ul>
<p>The posts with the most engagement time:</p>
<ul>
<li><a href="https://lawwu.github.io/posts/2025-05-27-levels-of-ai-use/" target="_blank">2025-05-27: Levels of AI Use</a></li>
<li><a href="https://lawwu.github.io/posts/2025-08-21-open-source-mcp-servers/" target="_blank">2025-08-21: Why Companies Should Open Source and Host Their Own MCP Servers</a></li>
<li><a href="https://lawwu.github.io/posts/2025-10-30-first-marathon-reflections/" target="_blank">2025-10-30: First Marathon Reflections</a></li>
<li><a href="https://lawwu.github.io/posts/2025-12-19-bunching-strategy/" target="_blank">2025-12-19: Bunching Charitable Contributions in 2025</a></li>
<li><a href="https://lawwu.github.io/posts/2024-09-20-langgraph-tutorial/" target="_blank">2024-09-20: Introduction to LangGraph Tutorial</a></li>
</ul>
</section>
<section id="books" class="level2">
<h2 class="anchored" data-anchor-id="books">Books</h2>
<p>Still really enjoy reading. I love reading because the author of the book you are holding has spent countless hours going deep on a topic and taken the time to write a book on this topic. You are literally getting a person’s best thoughts about a topic. Books are so information dense.</p>
<section id="david-mathis---a-little-theology-of-exercise" class="level3">
<h3 class="anchored" data-anchor-id="david-mathis---a-little-theology-of-exercise"><a href="https://amzn.to/4pc5Pc9" target="_blank">David Mathis - A Little Theology of Exercise</a></h3>
<p><a href="https://amzn.to/4pc5Pc9" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-11-24-little-theology-of-exercise/little_theology_of_exercise.jpg" class="img-fluid" width="200"></a></p>
<p>Short read that changed my perspective on exercise from a merely physical activity that was good for my body (which it is) to something that instead is for my mind. Research shows exercise helps the brain and in turn I can use my mind to love God and love others (Matthew 22:37-38). I wrote a review of this book <a href="https://lawwu.github.io/posts/2025-11-24-little-theology-of-exercise/">here</a>.</p>
</section>
<section id="andy-david-naselli---how-to-understand-and-apply-the-new-testament" class="level3">
<h3 class="anchored" data-anchor-id="andy-david-naselli---how-to-understand-and-apply-the-new-testament"><a href="https://amzn.to/3LfW5zF" target="_blank">Andy David Naselli - How to Understand and Apply the New Testament</a></h3>
<p><a href="https://amzn.to/3LfW5zF" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/how-to-read-new-testament.jpg" class="img-fluid" width="200"></a></p>
<p>I read the companion book, <a href="https://amzn.to/3LfW5zF" target="_blank">How to Understand and Apply the Old Testament</a> last year with a friend. We decided to read the NT version. Andy Naselli has a sample of the book on his <a href="https://andynaselli.com/how-to-understand-and-apply-the-new-testament-twelve-steps-from-exegesis-to-theology" target="_blank">blog</a>. Reading these two books gave me a greater appreciation for the current Bible I hold. There are so many people who have dedicated their lives to studying the original languages (Hebrew and/or Greek), studying the original manuscripts and laboring to faithfully translate the Bible. Another idea that stood out is Biblical Theology aka tracing a theme or idea from the Old Testament to the New Testament. It’s neat doing this with things like:</p>
<ul>
<li>Law</li>
<li>Temple</li>
<li>Priest</li>
<li>Kingdom of God</li>
<li>people of God</li>
<li>Holiness</li>
</ul>
</section>
<section id="morgan-housel---the-art-of-spending-money" class="level3">
<h3 class="anchored" data-anchor-id="morgan-housel---the-art-of-spending-money"><a href="https://amzn.to/3YldZ7f" target="_blank">Morgan Housel - The Art of Spending Money</a></h3>
<p><a href="https://amzn.to/3YldZ7f" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/art-of-spending.jpg" class="img-fluid" width="200"></a></p>
<p>Morgan Housel is one of the best personal finance writers right now. He is such a clear and succinct writer with an ability to tell such great stories. He has such good pithy sayings too.</p>
<p>I liked his list of money thoughts that guide his home:</p>
<ul>
<li>Spend less than you make</li>
<li>Quietly compound</li>
<li>Money serves you, not the other way around</li>
<li>No one is thinking about you as much as you are</li>
<li>Independence is wealth</li>
<li>Health is wealth</li>
<li>Aim to be a good ancestor</li>
<li>Love your family</li>
</ul>
</section>
<section id="sahil-bloom---the-5-types-of-wealth" class="level3">
<h3 class="anchored" data-anchor-id="sahil-bloom---the-5-types-of-wealth"><a href="https://amzn.to/44TcdxL" target="_blank">Sahil Bloom - The 5 Types of Wealth</a></h3>
<p><a href="https://amzn.to/44TcdxL" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/5-types-of-wealth.jpg" class="img-fluid" width="200"></a></p>
<p>The author talks about 5 types of wealth:</p>
<ul>
<li>Time</li>
<li>Social</li>
<li>Mental</li>
<li>Physical</li>
<li>Financial</li>
</ul>
<p>I thought it was helpful thinking about wealth from the these other 4 perspectives since we usually think of wealth from a financial perspective. I would add a 6th type of wealth to this: “Spiritual.” These are things that matter to God, have an eternal value, aka treasures in heaven (Matthew 6:19-21).</p>
</section>
<section id="nick-maggiulli---the-wealth-ladder" class="level3">
<h3 class="anchored" data-anchor-id="nick-maggiulli---the-wealth-ladder"><a href="https://amzn.to/4piSMG8" target="_blank">Nick Maggiulli - The Wealth Ladder</a></h3>
<p><a href="https://amzn.to/4piSMG8" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/wealth-ladder.jpg" class="img-fluid" width="200"></a></p>
<p>I didn’t think this had to be a book, I thought Nick’s <a href="https://ofdollarsanddata.com/climbing-the-wealth-ladder/" target="_blank">blog post from 2019</a> already summarized this idea well. His framing for the mindset at each level was helpful (using a rule of thumb you can safely spend 0.1% of your net worth without it making a huge dent). He defines 6 levels of wealth with a different mindset and strategy to get to the next level:</p>
<ul>
<li>Level 1: &lt;$10K (lower class)
<ul>
<li>Mindset: All prices matter</li>
<li>Build marketable skills</li>
</ul></li>
<li>Level 2: $10K–$100K (working class)
<ul>
<li>Mindset: Grocery prices matter less</li>
<li>Get education to unlock higher income</li>
</ul></li>
<li>Level 3: $100K–$1M (middle class)
<ul>
<li>Mindset: Restaurant prices matter less</li>
<li>Invest in income producing assets</li>
</ul></li>
<li>Level 4: $1M–$10M (upper middle class)
<ul>
<li>Mindset: Vacation prices matter less</li>
<li>Own a business</li>
</ul></li>
<li>Level 5: $10M–$100M (upper class)
<ul>
<li>Mindset: Home prices matter less</li>
<li>Scale a business</li>
</ul></li>
<li>Level 6: &gt;$100M (the superrich)
<ul>
<li>Mindset: What are prices?</li>
</ul></li>
</ul>
</section>
<section id="corlette-sande---the-young-peacemaker" class="level3">
<h3 class="anchored" data-anchor-id="corlette-sande---the-young-peacemaker"><a href="https://amzn.to/4qyxw06" target="_blank">Corlette Sande - The Young Peacemaker</a></h3>
<p><a href="https://amzn.to/4qyxw06" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/young-peacemaker.jpg" class="img-fluid" width="200"></a></p>
<p>Similar material from Ken Sande’s book the Peacemaker but designed to go through with your kids on how to respond to conflict in a Biblical manner.</p>
</section>
<section id="michael-and-melissa-kruger---5-things-to-pray-for-your-spouse" class="level3">
<h3 class="anchored" data-anchor-id="michael-and-melissa-kruger---5-things-to-pray-for-your-spouse"><a href="https://amzn.to/4pi1qEM" target="_blank">Michael and Melissa Kruger - 5 Things to Pray for Your Spouse</a></h3>
<p><a href="https://amzn.to/4pi1qEM" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/5-things-pray-spouse.jpg" class="img-fluid" width="200"></a></p>
<p>Found this helpful to diversify my prayers for my wife. Gives you 5 different things to pray for your wife each day based on a verse.</p>
</section>
<section id="melissa-kruger---5-things-to-pray-for-your-kids" class="level3">
<h3 class="anchored" data-anchor-id="melissa-kruger---5-things-to-pray-for-your-kids"><a href="https://amzn.to/3N22AGY" target="_blank">Melissa Kruger - 5 Things to Pray for Your Kids</a></h3>
<p><a href="(https://amzn.to/3N22AGY){target=&quot;_blank&quot;}"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/5-things-pray-kids.jpg" class="img-fluid" width="200"></a></p>
<p>Same book as above but for kids, still helpful. For example</p>
</section>
<section id="marty-machowski---promises-made-promises-kept" class="level3">
<h3 class="anchored" data-anchor-id="marty-machowski---promises-made-promises-kept"><a href="https://amzn.to/4q4dxXg" target="_blank">Marty Machowski - Promises Made, Promises Kept</a></h3>
<p><a href="https://amzn.to/4q4dxXg" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/promises-made-kept.jpg" class="img-fluid" width="200"></a></p>
<p>I really like Marty Machowski’s books. He’s such a great writer, being able to explain theological concepts to children. For example The Ology was a great book. Promises Made, Promises Kept is an interesting book. There are two books in one. You start the Promises Made on December 18 which talk about all of the promises God made that were eventually fulfilled in Christ (through 7 stories). Then on Christmas, December 25, you start Promises Kept which unpacks how Christ’s life, death and resurrection fulfills these promises (again through 7 stories).</p>
</section>
<section id="paul-david-tripp---marriage-6-gospel-commitments-every-couple-needs-to-make" class="level3">
<h3 class="anchored" data-anchor-id="paul-david-tripp---marriage-6-gospel-commitments-every-couple-needs-to-make"><a href="https://amzn.to/3YPwa51" target="_blank">Paul David Tripp - Marriage: 6 Gospel Commitments Every Couple Needs to Make</a></h3>
<p><a href="https://amzn.to/3YPwa51" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/marriage-tripp.jpg" class="img-fluid" width="200"></a></p>
<p>I like how Tripp is faithful to the Bible in his books. I would describe most of his books I’ve read on a given topic are really books about the gospel. So you won’t get a lot of practical advice on how to approach marriage but you will get reoriented on the foundation of marriage.</p>
</section>
<section id="chip-huyen---ai-engineering" class="level3">
<h3 class="anchored" data-anchor-id="chip-huyen---ai-engineering"><a href="https://amzn.to/48YFpWE" target="_blank">Chip Huyen - AI Engineering</a></h3>
<p><a href="https://amzn.to/48YFpWE" target="_blank"><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/images/ai-engineering.jpg" class="img-fluid" width="200"></a></p>
<p>This book came out December 2024. I like Chip Huyen’s writing on her <a href="https://huyenchip.com/blog/" target="_blank">blog</a>. I found this book to be a pretty good overview of this emerging new field of AI Engineering where as an engineer, you build applications on top of AI APIs. It’s a field where I’ve observed software engineering skills matter more than traditional AI/ML/DS skills. Bceause of the pace of AI development, some of the things in this book are likely dated now.</p>
</section>
</section>
<section id="biblical-counseling" class="level2">
<h2 class="anchored" data-anchor-id="biblical-counseling">Biblical Counseling</h2>
<p>I started working toward a Biblical Counseling certificiation through ACBC in 2021. Phase 1 was relatively painless. Phase 2 has been much more of a slog. I finally finished my last essay. One of biggest motivations for pursuing this path was because I wanted to counsel myself and my family in a more Biblical manner. Through going through this process, some things I learned:</p>
<ul>
<li>Everyone counsels - if you talk to people and give advice, you are “unoffiically counseling” people. As a Christian, if I believe the Bible is the greatest source of authority, literally the Word of God or God’s words, then my advice/counsel should be based on the Bible.</li>
<li>The sufficiency of Scripture - this is a theological term that means the Bible contains all that we need to live out the Christian life. Wayne Grudem defines sufficiency as it <em>“means that Scripture contains all the words of God we need for salvation, for trusting him perfectly, and for obeying him perfectly. This definition emphasizes that it is in Scripture alone that we are to search for God’s words to us. It also reminds us that God considers what he has told us in the Bible to be enough for us and that we should rejoice in the great revelation he has given us and be content with it.”</em> (Systematic Theology, page 333-334) More than my experiences, traditions or worldly wisdom, Scripture is what I need to go back to find answers.</li>
<li>AI can write a pretty good ACBC essay. However, the value in writing these essays (and writing in general) is gives you the writer an opportunity to process what you’ve learned. <a href="https://www.nature.com/articles/s44222-025-00323-4" target="_blank">Writing is thinking</a>. As we enter the age of AI, I actually believe thinking is even more important. We cannot allow AI to think for us. Having to write essays on a variety of theological and counseling based situations gave me an opportunity to consume material on the topic, synthesize the material into an outline and then bring it all together by writing hopefully coherent paragraphs.</li>
</ul>
</section>
<section id="personal-finances" class="level2">
<h2 class="anchored" data-anchor-id="personal-finances">Personal Finances</h2>
<section id="investments" class="level3">
<h3 class="anchored" data-anchor-id="investments">Investments</h3>
<p>I stopped trading individual securities around 10 years ago. I’m content just earning the market return year in and year out, without needing to choose the best stocks, fund managers or sector ETFs. I don’t need to monitor them for when to sell them. I don’t need to worry about quarterly earnings. The market and low-cost market-cap index funds/ETFs weighted are one of the greatest innovations that retail investors like myself have access to. If you buy and hold these investment vehicles, you’ll likely beat 90+% of professional money managers.</p>
<p>My portfolio hasn’t changed over the last 5 years. It is:</p>
<ul>
<li>90% stocks</li>
<li>10% cash</li>
</ul>
<p>The stock portion is:</p>
<ul>
<li>70% US Stocks</li>
<li>30% International</li>
</ul>
<p>The funds I own are either US funds like a total stock VTI or an S&amp;P 500 fund like FXAIX, international funds (VXUS, FTIHX, FSPSX), a world fund like VT or a Bitcoin ETF (FBTC).</p>
<p>Here are the VT (Vanguard Total World Stock ETF) returns since 2016:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Year</th>
<th>VT Returns</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>2016</td>
<td>8.5%</td>
</tr>
<tr class="even">
<td>2017</td>
<td>24.5%</td>
</tr>
<tr class="odd">
<td>2018</td>
<td>-9.8%</td>
</tr>
<tr class="even">
<td>2019</td>
<td>26.8%</td>
</tr>
<tr class="odd">
<td>2020</td>
<td>16.6%</td>
</tr>
<tr class="even">
<td>2021</td>
<td>18.3%</td>
</tr>
<tr class="odd">
<td>2022</td>
<td>-18.0%</td>
</tr>
<tr class="even">
<td>2023</td>
<td>22.0%</td>
</tr>
<tr class="odd">
<td>2024</td>
<td>16.5%</td>
</tr>
<tr class="even">
<td>2025</td>
<td>23.6%</td>
</tr>
</tbody>
</table>
<p>It’s been an amazing 10 year run. 8 years of 10+% gains, 7 of them have been 15% or more with only 2 down years. If you invested $10,000 at the beginning of 2016, you will have tripled your investment.</p>
<div id="0da0c5bb" class="cell" data-execution_count="1">
<div class="cell-output cell-output-display">
<div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-3.3.0.min.js" integrity="sha256-bO3dS6yCpk9aK4gUpNELtCiDeSYvGYnK7jFI58NQnHI=" crossorigin="anonymous"></script>                <div id="024deb7a-ccbf-47e7-ba75-c52de94f5844" class="plotly-graph-div" style="height:450px; width:800px;"></div>            <script type="text/javascript">                window.PLOTLYENV=window.PLOTLYENV || {};                                if (document.getElementById("024deb7a-ccbf-47e7-ba75-c52de94f5844")) {                    Plotly.newPlot(                        "024deb7a-ccbf-47e7-ba75-c52de94f5844",                        [{"hovertemplate":"\u003cb\u003e%{x}\u003c\u002fb\u003e\u003cbr\u003eReturn: %{y}%\u003cextra\u003e\u003c\u002fextra\u003e","marker":{"color":"#2563eb"},"name":"Annual Return","x":{"dtype":"i2","bdata":"4AfhB+IH4wfkB+UH5gfnB+gH6Qc="},"y":{"dtype":"f8","bdata":"AAAAAAAAIUAAAAAAAIA4QJqZmZmZmSPAzczMzMzMOkCamZmZmZkwQM3MzMzMTDJAAAAAAAAAMsAAAAAAAAA2QAAAAAAAgDBAmpmZmZmZN0A="},"yaxis":"y","type":"bar"},{"hovertemplate":"\u003cb\u003e%{x}\u003c\u002fb\u003e\u003cbr\u003eValue: $%{y:,.0f}\u003cextra\u003e\u003c\u002fextra\u003e","line":{"color":"#10b981","width":3},"marker":{"size":8},"mode":"lines+markers","name":"Growth of $10,000","x":{"dtype":"i2","bdata":"4AfhB+IH4wfkB+UH5gfnB+gH6Qc="},"y":{"dtype":"f8","bdata":"AAAAAAAxxUABAAAAIGLKQJluEoM4zMdA+QDdl+8szkAWzB48o5fRQLg9nKbNz9RAfq1CecwQ0UBYG8c379HUQCPhGaZfQdhAoSV8Ksn63UA="},"yaxis":"y2","type":"scatter"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermap":[{"type":"scattermap","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"},"margin":{"b":0,"l":0,"r":0,"t":30}}},"shapes":[{"line":{"color":"#666","dash":"dash","width":1},"type":"line","x0":0,"x1":1,"xref":"x domain","y0":0,"y1":0,"yref":"y"}],"yaxis":{"title":{"text":"Annual Return (%)"},"gridcolor":"lightgray","range":[-20,30]},"yaxis2":{"title":{"text":"Portfolio Value ($)"},"overlaying":"y","side":"right","gridcolor":"lightgray","showgrid":false,"range":[-4822.733585986192,32234.10037897929]},"legend":{"orientation":"h","yanchor":"bottom","y":1.02,"xanchor":"right","x":1},"title":{"text":"VT Returns (2016-2025)"},"xaxis":{"title":{"text":"Year"}},"plot_bgcolor":"white","width":800,"height":450,"hovermode":"x unified"},                        {"responsive": true}                    ).then(function(){
                            
var gd = document.getElementById('024deb7a-ccbf-47e7-ba75-c52de94f5844');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };            </script>        </div>
</div>
</div>
</section>
<section id="cash-emergency-fund" class="level3">
<h3 class="anchored" data-anchor-id="cash-emergency-fund">Cash / Emergency Fund</h3>
<p>I no longer own any I-Bonds. I sold my last ones in 2024. All of our cash / emergency funds is in a Fidelity CMA account that currently earns 3.42%. All of it is automatically invested in SPAXX, Fidelity’s Government Money Market Fund. One of the great things about a CMA account is you can pay bills from it and Fidelity will sell your core cash position (SPAXX is the default) to pay the bill. The Frugal Professor has written a post on the Fidelity CMA <a href="https://frugalprofessor.com/the-ultimate-guide-to-fidelitys-cash-management-account-cma/" target="_blank">here</a>.</p>
</section>
<section id="credit-cards" class="level3">
<h3 class="anchored" data-anchor-id="credit-cards">Credit Cards</h3>
<p>The US Bank Smartly 4% cash back card came and went. It was a little too good to be true and I got the infamous <a href="https://www.doctorofcredit.com/u-s-bank-to-nerf-existing-smartly-cardholders-on-september-15/" target="_blank">bad letter</a> in September. I moved all of our credit card spending to the <a href="https://www.bankofamerica.com/credit-cards/products/premium-rewards-elite-credit-card/" target="_blank">BofA Premium Rewards Elite</a> where I earn 3.5% on travel/dining and 2.625% on all other spend.</p>
<p>I got a couple credit card sign up bonuses this year:</p>
<ul>
<li>American Express - Marriott Bonvoy Bevy - 155,000 Marriott points</li>
<li>American Express - Platinum - 80,000 MR points</li>
</ul>
<p>The Amex Platinum takes a fair amount of work to maximize it’s rewards. I don’t really like the overhead and probably won’t keep it.</p>
</section>
</section>
<section id="running" class="level2">
<h2 class="anchored" data-anchor-id="running">Running</h2>
<p>Ran my <a href="https://lawwu.github.io/posts/2025-02-02-second-half-marathon/">second half-marathon</a> and <a href="https://lawwu.github.io/posts/2025-10-30-first-marathon-reflections/">first full-marathon</a> this year. Running continues to be my favorite form of cardio. God willing, hopefully I have many more years of running ahead of me.</p>
<section id="strava---year-in-sport" class="level3">
<h3 class="anchored" data-anchor-id="strava---year-in-sport">Strava - Year in Sport</h3>
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/strava/stats.PNG" class="img-fluid" width="600"></p>
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/strava/trophy_case.PNG" class="img-fluid" width="600"></p>
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/strava/hours_active.PNG" class="img-fluid" width="600"></p>
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/strava/days_active.PNG" class="img-fluid" width="600"></p>
</section>
</section>
<section id="ai" class="level2">
<h2 class="anchored" data-anchor-id="ai">AI</h2>
<section id="agentic-coding" class="level3">
<h3 class="anchored" data-anchor-id="agentic-coding">Agentic Coding</h3>
<p>One of the big changes this year was the rise of agentic coding tools like Claude Code. I started using it in <a href="https://lawwu.github.io/posts/2025-07-18-starting-to-use-claude-code/">July 2025</a> and have been using it almost daily since it came out. Anthropic has created an amazing tool. We’ve seen the underlying model improve. It’s still hard to believe the intial release of Claude Code used Claude 3.7 Sonnet (I would’ve guessed this was last year)! We’re now on Claude Opus 4.5. There has also been improvements in the Claude Code agentic harness too with todo lists, subagents, improvements to the system prompts, better tool calling, adding agent skills. Just look at the <a href="https://github.com/anthropics/claude-code/blob/main/CHANGELOG.md" target="_blank">CHANGELOG</a> to look at all these improvements over time.</p>
<p>Some of the things I’ve used Claude Code for this year:</p>
<ul>
<li>Agentic ML: using the <code>bq</code> cli to explore data source in Big Query, create ML features and create ML training scripts</li>
<li>Exploring and understanding new code using the <a href="https://github.com/cli/cli" target="_blank">gh cli</a> - I find Claude Code is more effective at using CLI tools than an MCP Server. I prefer Claude Code using the Github CLI rather than the <a href="https://github.com/github/github-mcp-server" target="_blank">Github MCP</a></li>
<li>Creating slides that are themed according to my company using Quarto and RevealJS</li>
<li>Troubleshooting Kubernetes pods</li>
<li>Writing documentation</li>
<li>Writing Confluence documentation using the <a href="https://github.com/sooperset/mcp-atlassian" target="_blank">mcp-atlassian</a> MCP Server</li>
<li>Creating MCP Servers using <a href="https://github.com/jlowin/fastmcp" target="_blank">FastMCP</a></li>
<li>Adding graphs / visuals to my blg posts</li>
<li>Creating Github Actions</li>
<li>Creating and maintaining Cookiecutter templates for Python libraries and services</li>
<li>Scraping Long Beach Marathon data to get the total finishers in the last 15 years for this <a href="https://lawwu.github.io/posts/2025-10-30-first-marathon-reflections/#lesson-3-running-is-getting-popular">post</a></li>
</ul>
<p>Claude Code really does amplify and leverage a developer’s (or even non-developer’s) ideas. Whatever ideas you have, you can bring them into reality so much faster.</p>
<p>There are many world class software developers that now use tools like Claude Code:</p>
<p><strong>Andrej Karpathy</strong> - <a href="https://x.com/karpathy/status/2002118205729562949" target="_blank">Year in Review where he talks about Claude Code and Vibe Coding</a></p>
<iframe src="https://platform.twitter.com/embed/Tweet.html?id=2004607146781278521" width="550" height="400" frameborder="0">
</iframe>
<p><strong>Boris Cherny</strong></p>
<blockquote class="blockquote">
<p>A year ago, Claude struggled to generate bash commands without escaping issues. It worked for seconds or minutes at a time. We saw early signs that it may become broadly useful for coding one day. Fast forward to today. In the last thirty days, I landed 259 PRs – 497 commits, 40k lines added, 38k lines removed. Every single line was written by Claude Code + Opus 4.5. Claude consistently runs for minutes, hours, and days at a time (using Stop hooks). Software engineering is changing, and we are entering a new period in coding history. And we’re still just getting started..</p>
</blockquote>
<iframe src="https://platform.twitter.com/embed/Tweet.html?id=2004887829252317325" width="550" height="400" frameborder="0">
</iframe>
<p><strong>Armin Ronacher</strong> - Summarized the year as a <a href="https://lucumr.pocoo.org/2025/12/22/a-year-of-vibes/" target="_blank">Year of Vibes</a></p>
<p><strong>Simon Willison</strong> - prolific blogger and prolific user of LLMs, one of his posts he talked about <a href="https://simonwillison.net/2025/Oct/8/claude-datasette-plugins/" target="_blank">how Claude Opus 4.5 can create full datasette plugins now</a>.</p>
<p>It’s fun to see how things have evolved in the last year just looking at Anthropic’s Claude and Claude Code releated announcements:</p>
<ul>
<li><a href="https://www.anthropic.com/news/claude-3-7-sonnet" target="_blank">Feb 24, 2025 - Initial Claude Code Release alongside Claude 3.7 Sonnet</a> - <a href="https://github.com/anthropics/claude-code" target="_blank">repo</a> though this doesn’t have the source code</li>
<li><a href="https://www.anthropic.com/news/Introducing-code-with-claude" target="_blank">April 3, 2025 - Anthropic announces their first developer conference</a> - which I summarized the talks <a href="https://lawwu.github.io/posts/2025-08-14-claude-code-conference-summary/">here</a>.</li>
<li><a href="https://www.anthropic.com/news/claude-4" target="_blank">May 22, 2025 - Claude Sonnet and Opus 4 released</a></li>
<li><a href="https://www.anthropic.com/news/claude-opus-4-1" target="_blank">August 5, 2025 - Claude Opus 4.1 released</a></li>
<li><a href="https://github.com/anthropics/claude-code-action/" target="_blank">August 26, 2025 - Claude Code Github Action 1.0 Release</a></li>
<li><a href="https://www.anthropic.com/news/claude-sonnet-4-5" target="_blank">September 29, 2025 - Claude Sonnet 4.5</a></li>
<li><a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk" target="_blank">September 29, 2025 - Claude Agents SDK</a></li>
<li><a href="https://github.com/anthropics/claude-plugins-official/" target="_blank">October 9, 2025 - Claude Code Plugins</a></li>
<li><a href="https://www.anthropic.com/news/claude-opus-4-5" target="_blank">October 15, 2025 - Claude Haiku 4.5</a></li>
<li><a href="https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills" target="_blank">October 16, 2025 - Claude Skills</a></li>
<li><a href="https://www.anthropic.com/news/claude-opus-4-5" target="_blank">November 24, 2025 - Claude Opus 4.5</a></li>
<li><a href="https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone" target="_blank">December 2, 2025 - Claude Code reaches $1B run-rate revenue</a></li>
</ul>
</section>
<section id="chatgpt---year-in-review" class="level3">
<h3 class="anchored" data-anchor-id="chatgpt---year-in-review">ChatGPT - Year in Review</h3>
<p>ChatGPT created a year in review for me based on my chat history. Here are some highlights:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/recap_chatgpt/year_in_poem.png" class="img-fluid figure-img" width="600"></p>
<figcaption>Year in Poem</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/recap_chatgpt/chat_stats.png" class="img-fluid figure-img" width="600"></p>
<figcaption>Chat Stats</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/recap_chatgpt/3_themes.png" class="img-fluid figure-img" width="600"></p>
<figcaption>3 Themes</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/recap_chatgpt/image_summary.png" class="img-fluid figure-img" width="600"></p>
<figcaption>Image Summary</figcaption>
</figure>
</div>


</section>
</section>

 ]]></description>
  <category>personal</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/</guid>
  <pubDate>Wed, 31 Dec 2025 00:00:00 GMT</pubDate>
  <media:content url="https://lawwu.github.io/blog.html/posts/2025-12-31-year-in-review/strava/stats.PNG" medium="image"/>
</item>
<item>
  <title>Bunching Charitable Contributions in 2025</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-12-19-bunching-strategy/</link>
  <description><![CDATA[ 




<p>I recently took advantage of a strategy called “bunching” where you combine multiple years of charitable contributions into one year. I’ll use a made up example here but you could plug in your own numbers.</p>
<p><del>This strategy has worked in years past but it’s gotten better because of the 2025 One Big Beautiful Bill Act which increased the SALT cap to $40,000 (from $10,000). SALT = state and local taxes, which can include income taxes (or sales taxes instead), plus property taxes. It’s important here because you are allowed to deduct state and local income taxes from your federal return. This change is <a href="https://www.hrblock.com/tax-center/irs/tax-law-and-policy/one-big-beautiful-bill-salt-deduction/">effective for tax years 2025-2029</a>.</del></p>
<div class="callout callout-style-default callout-important callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
<span class="screen-reader-only">Important</span>Correction
</div>
</div>
<div class="callout-body-container callout-body">
<p>I was mistaken. The increase in SALT from $10,000 to $40,000 actually makes bunching make sense less in most years because if you live in a high tax state you can now deduct up to $40,000 in SALT. If your SALT is above $31,500 in a given year, it doesn’t make a lot of sense to bunch.</p>
</div>
</div>
<section id="what-is-bunching" class="level2">
<h2 class="anchored" data-anchor-id="what-is-bunching">What is Bunching?</h2>
<p>The idea is simple:</p>
<ul>
<li><strong>Year 1:</strong> Donate 2 years worth of charity in one year → Itemize deductions
<ul>
<li>When I’ve done this, I give next year’s amount (2026) in the last month of the prior year (Dec 2025).</li>
<li>You could also put two years of charitable contributions into a Donor Advised Fund, take the itemized deduction in that year and then spread the donations out over two years.</li>
</ul></li>
<li><strong>Year 2:</strong> Make no charitable donations → Take standard deduction</li>
<li><strong>Result:</strong> More total deductions over 2 years than taking the standard deduction both years</li>
</ul>
<p>You can also prepay property tax payments. Property tax is deductible in the year you <em>pay</em> it, not when it’s due. In <a href="https://taxbill.octreasurer.gov/">Orange County, CA, property tax</a> comes in two installments (December and April). In your bunching year, you can pay three installments: April, December and the next April (early).</p>
<p>It’s kind of interesting if you search “california prepay property taxes”, many of the articles (like <a href="https://www.sfchronicle.com/business/networth/article/Should-you-prepay-your-state-income-and-property-12448762.php">this one</a> and this <a href="https://www.bogleheads.org/forum/viewtopic.php?t=235950">Bogleheads post</a>) are from 2017 because the TCJA capped SALT deductions (including property tax) at $10,000 so it didn’t make a lot of sense to prepay property tax like this.</p>
</section>
<section id="example-scenario" class="level2">
<h2 class="anchored" data-anchor-id="example-scenario">Example Scenario</h2>
<p>Let’s use a realistic example to see how this works:</p>
<ul>
<li>Income: $150,000 (married filing jointly)</li>
<li>Location: California (or another high tax state)</li>
<li>Charitable giving: 10% of income = $15,000 per year, so $30,000 over 2 years</li>
<li>Property tax: $5,000/year</li>
<li>Mortgage interest: $10,000/year</li>
</ul>
</section>
<section id="the-result" class="level2">
<h2 class="anchored" data-anchor-id="the-result">The Result</h2>
<p><strong>Traditional approach:</strong> Itemize $36,035 each year (charity + property tax + state tax + mortgage interest), total of $72,070 of total deductions.</p>
<p><strong>Bunching strategy:</strong></p>
<ul>
<li>Year 1: Itemize $53,535 (bunch 2 years of charity + accelerate property tax)</li>
<li>Year 2: Take $31,500 standard deduction (no charity, less property tax)</li>
<li>Total deductions of $85,035 (increased deductions of $12,965) which results in a tax savings of <strong>~$2,803 over 2 years</strong></li>
</ul>
<p>Here’s the visual breakdown:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-19-bunching-strategy/images/deductions_comparison.png" class="img-fluid figure-img"></p>
<figcaption>Total deductions over 2 years</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-12-19-bunching-strategy/images/deductions_breakdown.png" class="img-fluid figure-img"></p>
<figcaption>Year-by-year breakdown</figcaption>
</figure>
</div>
</section>
<section id="should-you-do-this" class="level2">
<h2 class="anchored" data-anchor-id="should-you-do-this">Should You Do This?</h2>
<p>Bunching works when your Year 1 itemized deductions exceed $31,500.</p>
<p><strong>You’re a good candidate if you have:</strong></p>
<ul>
<li>Mortgage interest ($3,000+)</li>
<li>Regular charitable giving (8-10%+ of income)</li>
<li>High state taxes (CA, NY, NJ, etc.)</li>
<li>Property tax to prepay</li>
</ul>
</section>
<section id="try-it-yourself-interactive-calculator" class="level2">
<h2 class="anchored" data-anchor-id="try-it-yourself-interactive-calculator">Try It Yourself: Interactive Calculator</h2>
<p>Want to see if bunching works for your situation? Adjust the sliders below to run your own numbers:</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb1" data-startfrom="76" data-source-offset="-1" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 75;"><span id="cb1-76">viewof income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Inputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500000</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {</span>
<span id="cb1-77">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">value</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">150000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-78">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">step</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-79">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annual Income (MFJ):"</span></span>
<span id="cb1-80">})</span>
<span id="cb1-81"></span>
<span id="cb1-82">viewof charityPct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Inputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">20</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {</span>
<span id="cb1-83">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">value</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-84">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">step</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-85">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Charitable Giving (% of income):"</span></span>
<span id="cb1-86">})</span>
<span id="cb1-87"></span>
<span id="cb1-88">viewof propertyTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Inputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50000</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {</span>
<span id="cb1-89">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">value</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">5000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-90">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">step</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">500</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-91">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annual Property Tax:"</span></span>
<span id="cb1-92">})</span>
<span id="cb1-93"></span>
<span id="cb1-94">viewof mortgageInterest <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Inputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">range</span>([<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">30000</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {</span>
<span id="cb1-95">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">value</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">10000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-96">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">step</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1000</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-97">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Annual Mortgage Interest:"</span></span>
<span id="cb1-98">})</span>
<span id="cb1-99"></span>
<span id="cb1-100">viewof state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Inputs<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">select</span>([<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"California"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New York"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New Jersey"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Texas"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Florida"</span>]<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {</span>
<span id="cb1-101">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">value</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"California"</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb1-102">  <span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">label</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"State:"</span></span>
<span id="cb1-103">})</span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-5" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb2" data-startfrom="110" data-source-offset="-54" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 109;"><span id="cb2-110"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateStateTax</span>(income<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> state) {</span>
<span id="cb2-111">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> caStdDeduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11080</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-112">  <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">const</span> taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> caStdDeduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-113"></span>
<span id="cb2-114">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"California"</span>) {</span>
<span id="cb2-115">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// CA MFJ brackets (simplified)</span></span>
<span id="cb2-116">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">21512</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.01</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-117">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50998</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">215</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">21512</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.02</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-118">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80490</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">805</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">50998</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.04</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-119">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">111732</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1985</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80490</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.06</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-120">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">141212</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">3860</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">111732</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.08</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-121">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">6220</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">141212</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.093</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-122">  }</span>
<span id="cb2-123">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New York"</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.065</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Simplified</span></span>
<span id="cb2-124">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New Jersey"</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.055</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Simplified</span></span>
<span id="cb2-125">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Texas"</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">||</span> state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">===</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Florida"</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// No state income tax</span></span>
<span id="cb2-126">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-127">}</span>
<span id="cb2-128"></span>
<span id="cb2-129"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Calculate federal tax</span></span>
<span id="cb2-130"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">function</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateFederalTax</span>(taxableIncome) {</span>
<span id="cb2-131">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">23850</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.10</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-132">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96950</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2385</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">23850</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.12</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-133">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">206700</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">11157</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">96950</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.22</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-134">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&lt;=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">394600</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">35301</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">206700</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.24</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-135">  <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">80405</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (taxableIncome <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">394600</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.32</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-136">}</span>
<span id="cb2-137"></span>
<span id="cb2-138"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Calculations</span></span>
<span id="cb2-139">charityPerYear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> charityPct <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-140">stateTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateStateTax</span>(income<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> state)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-141">standardDeduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">31500</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-142"></span>
<span id="cb2-143"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Traditional approach (itemize each year)</span></span>
<span id="cb2-144">traditionalItemized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> charityPerYear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> propertyTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> stateTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> mortgageInterest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-145">traditionalDeduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(traditionalItemized<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> standardDeduction)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-146">traditionalFederalTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateFederalTax</span>(income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> traditionalDeduction)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-147">traditionalTotal2Year <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> traditionalFederalTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-148"></span>
<span id="cb2-149"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Bunching approach</span></span>
<span id="cb2-150">bunchedYear1Itemized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (charityPerYear <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (propertyTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">1.5</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> stateTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> mortgageInterest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-151">bunchedYear1FederalTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateFederalTax</span>(income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> bunchedYear1Itemized)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-152"></span>
<span id="cb2-153">bunchedYear2Itemized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> (propertyTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.5</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> stateTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> mortgageInterest<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-154">bunchedYear2Deduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">max</span>(bunchedYear2Itemized<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> standardDeduction)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-155">bunchedYear2FederalTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">calculateFederalTax</span>(income <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> bunchedYear2Deduction)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-156"></span>
<span id="cb2-157">bunchedTotal2Year <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> bunchedYear1FederalTax <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> bunchedYear2FederalTax<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-158"></span>
<span id="cb2-159"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">// Savings</span></span>
<span id="cb2-160">savings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> traditionalTotal2Year <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> bunchedTotal2Year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-161">savingsPercent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (savings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span> traditionalTotal2Year) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span>
<span id="cb2-162">worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> savings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">;</span></span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-4" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-5" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-6" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-7" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-8" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-9" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-10" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-11" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-12" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-13" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-14" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-15" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-16" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-17" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-18" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb3" data-startfrom="166" data-source-offset="0" style="background: #f1f3f5;"><pre class="sourceCode js code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 165;"><span id="cb3-166"><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">html</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span></span>
<span id="cb3-167"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;div style="background-color: #f0f8ff; padding: 20px; border-radius: 10px; margin: 20px 0; border: 2px solid #3498db;"&gt;</span></span>
<span id="cb3-168"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;h3 style="margin-top: 0; color: #2c3e50;"&gt;📊 Results&lt;/h3&gt;</span></span>
<span id="cb3-169"></span>
<span id="cb3-170"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;div style="display: grid; grid-template-columns: 1fr 1fr; gap: 20px; margin: 20px 0;"&gt;</span></span>
<span id="cb3-171"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;div style="background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);"&gt;</span></span>
<span id="cb3-172"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;h4 style="margin-top: 0; color: #555;"&gt;Traditional Approach&lt;/h4&gt;</span></span>
<span id="cb3-173"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;Year 1 Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>traditionalDeduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-174"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;Year 2 Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>traditionalDeduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-175"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;2-Year Total Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>(traditionalDeduction <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">*</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-176"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;hr style="border: none; border-top: 1px solid #eee; margin: 10px 0;"&gt;</span></span>
<span id="cb3-177"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 16px;"&gt;&lt;strong&gt;Total Federal Tax:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>traditionalTotal2Year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-178"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;/div&gt;</span></span>
<span id="cb3-179"></span>
<span id="cb3-180"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;div style="background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1); border: 2px solid </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#28a745'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#6c757d'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">;"&gt;</span></span>
<span id="cb3-181"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;h4 style="margin-top: 0; color: #555;"&gt;Bunching Strategy&lt;/h4&gt;</span></span>
<span id="cb3-182"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;Year 1 Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>bunchedYear1Itemized<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-183"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;Year 2 Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>bunchedYear2Deduction<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-184"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 14px;"&gt;&lt;strong&gt;2-Year Total Deductions:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>(bunchedYear1Itemized <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> bunchedYear2Deduction)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-185"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;hr style="border: none; border-top: 1px solid #eee; margin: 10px 0;"&gt;</span></span>
<span id="cb3-186"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      &lt;p style="margin: 5px 0; font-size: 16px;"&gt;&lt;strong&gt;Total Federal Tax:&lt;/strong&gt; $</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>bunchedTotal2Year<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/p&gt;</span></span>
<span id="cb3-187"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;/div&gt;</span></span>
<span id="cb3-188"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;/div&gt;</span></span>
<span id="cb3-189"></span>
<span id="cb3-190"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;div style="background: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#d4edda'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#fff3cd'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">; padding: 20px; border-radius: 8px; text-align: center; border: 3px solid </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#28a745'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#ffc107'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">;"&gt;</span></span>
<span id="cb3-191"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;h3 style="margin: 0; color: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#155724'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#856404'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">; font-size: 24px;"&gt;</span></span>
<span id="cb3-192"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'✓'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'⚠️'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;"> Tax Savings: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>savings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'$'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'-$'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}${</span><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">Math</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">abs</span>(savings)<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toLocaleString</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'en-US'</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span> {<span class="dt" style="color: #AD0000;
background-color: null;
font-style: inherit;">maximumFractionDigits</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>})<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb3-193"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;/h3&gt;</span></span>
<span id="cb3-194"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;p style="margin: 10px 0 0 0; font-size: 16px; color: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#155724'</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'#856404'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">;"&gt;</span></span>
<span id="cb3-195"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">      </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>worthIt</span>
<span id="cb3-196">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`You save </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">${</span>savingsPercent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span><span class="fu" style="color: #4758AB;
background-color: null;
font-style: inherit;">toFixed</span>(<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">% over 2 years with bunching! 🎉`</span></span>
<span id="cb3-197">        <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> savings <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">&gt;</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span></span>
<span id="cb3-198">          <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">?</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Small benefit - bunching might not be worth the hassle'</span></span>
<span id="cb3-199">          <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">:</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Bunching doesn</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">\'</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">t help - stick with traditional approach'</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb3-200"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    &lt;/p&gt;</span></span>
<span id="cb3-201"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;/div&gt;</span></span>
<span id="cb3-202"></span>
<span id="cb3-203"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;p style="margin-top: 15px; font-size: 12px; color: #666; font-style: italic;"&gt;</span></span>
<span id="cb3-204"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">    💡 Note: This calculator uses simplified tax calculations and assumes you're in the 2025 tax year with the new $40k SALT cap. It doesn't account for AMT, phase-outs, or all state-specific rules. Consult a tax professional for accurate advice specific to your situation.</span></span>
<span id="cb3-205"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">  &lt;/p&gt;</span></span>
<span id="cb3-206"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/div&gt;</span></span>
<span id="cb3-207"><span class="vs" style="color: #20794D;
background-color: null;
font-style: inherit;">`</span></span></code></pre></div></div>
<div class="cell-output cell-output-display">
<div id="ojs-cell-3" data-nodetype="expression">

</div>
</div>
</div>
</section>
<section id="my-takeaway" class="level2">
<h2 class="anchored" data-anchor-id="my-takeaway">My Takeaway</h2>
<p>After running the numbers on scenarios like this, it’s clear that bunching can be worthwhile for many households, especially with the higher SALT cap in 2025.</p>
<p>Don’t assume bunching works without running your own numbers. The 2025 tax changes help here. Under the old $10k SALT cap, this example would save $2,530. Under the new $40k cap, it saves $2,803.</p>
<p>If you’re in a high-tax state with a mortgage and regular charitable giving, spend some time to run the numbers for your specific situation.</p>
<hr>
<p><em>AI Disclaimer</em>: Claude Code &amp; Claude Sonnet 4.5 helped me write this article and generate the ocde for these visualizations. I reviewed the output and made a bunch of edits which included deleting 75% of what was generated.</p>
<p><em>Disclaimer: This blog post is for educational purposes only and does not constitute tax, legal, or financial advice. Tax laws are complex and change frequently. Consult with a qualified tax professional about your specific situation before making any tax-related decisions.</em></p>


</section>

 ]]></description>
  <category>personal finance</category>
  <category>taxes</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-12-19-bunching-strategy/</guid>
  <pubDate>Fri, 19 Dec 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Little Theology of Exercise</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-11-24-little-theology-of-exercise/</link>
  <description><![CDATA[ 




<p>Starting a new type of post where I’ll review books. I recently read <a href="https://amzn.to/4rkSRv4">A Little Theology of Exercise: Enjoying Christ in Body and Soul</a> by <a href="https://www.desiringgod.org/authors/david-mathis/books">David Mathis</a>. The beginning part of the book is available for free <a href="https://document.desiringgod.org/a-little-theology-of-exercise-en.pdf">here</a>. The audio book (~2 hours) is also free on <a href="https://open.spotify.com/show/4DFqfFXiAhrjHzvBGL7ue1">Spotify</a> if you’re a premium subscriber.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 50%; margin-bottom: 20px;">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-11-24-little-theology-of-exercise/little_theology_of_exercise.jpg" class="img-fluid figure-img" width="400"></p>
<figcaption>A Little Theology of Exercise</figcaption>
</figure>
</div>
<section id="table-of-contents" class="level1">
<h1>Table of Contents</h1>
<ul>
<li>Preface (p.&nbsp;ix)</li>
<li>Introduction — Joy Set Before Us (p.&nbsp;1)</li>
<li><strong>Part 1: Move the Body</strong> (p.&nbsp;15)
<ul>
<li>1 His Word — What God Says About Our Bodies (p.&nbsp;19)</li>
<li>2 Our Prayers — How We Ask for Help (p.&nbsp;39)</li>
</ul></li>
<li><strong>Part 2: Condition the Soul</strong> (p.&nbsp;45)
<ul>
<li>3 For Our God — Glorify Him in the Body (p.&nbsp;51)</li>
<li>4 For the Mind — Build and Condition the Brain (p.&nbsp;57)</li>
<li>5 For the Will — Learn to Lean into the Hill (p.&nbsp;67)</li>
<li>6 For Joy — Seek Satisfaction in Jesus (p.&nbsp;77)</li>
<li>7 For Love’s Sake — Get Fit for Good Works (p.&nbsp;83)</li>
</ul></li>
<li>Conclusion — Move the Needle (p.&nbsp;93)</li>
</ul>
<p>This is a book I wish I read when I started running in <a href="https://lawwu.github.io/posts/2024-10-13-running-6-months/">early 2024</a>. I had never heard of an author connecting theology and exercise. Overall I thoroughly enjoyed this book. It was a quick read.</p>
<p>In the preface, Mathis opens by quoting C.S. Lewis who argued that man has three views of the body:</p>
<ul>
<li>Pagans - prison or tomb of the soul. It is a “sack of dung”</li>
<li>Neo-Pagans - the body is glorious</li>
<li>St.&nbsp;Francis - his body is “Brother Ass” - aka “Brother donkey.” He says “It is useful, sturdy, lazy, obstinate, patient, lovable, and infuriating beast; deserving now a stick and now a carrot; both pathetically and absurdly beautiful. So the body.” (pg. x)</li>
</ul>
<p>As a Christian, I shouldn’t have too low of a view of the body. I also shouldn’t have too high of bodies and make it an idol. But what does it look like to have a right view? I think it means to view the body as a vehicle God has given me to love and glorify Him. Mathis goes on to explain why he wrote the book:</p>
<blockquote class="blockquote">
<p>Why would a pastor, of all people, write a book about exercise? In short, I&nbsp;want to help people know and enjoy Jesus more and, so, make much of him in the world as he deserves. As a pastor, that often means that I’m speaking and writing about Jesus himself, or teaching portions of the Bible, or commending various spiritual disciplines (which I&nbsp;call <a href="https://amzn.to/4pBpByF">“Habits of Grace”</a>). And God made us embodied creatures. <strong>The physical body has a vital part to play in our spiritual and holistic health and God-honoring joy.</strong> In my adult life, especially in the last decade, I’ve found that physical exercise serves my soul, and I’m eager to commend that to you to serve your growth “in the grace and knowledge of our Lord and Savior Jesus Christ” (2&nbsp;Pet. 3:18). To be clear, my appreciation for exercise and “bodily training” (1&nbsp;Tim. 4:8) is not as an end in itself. <strong>One of the reasons I&nbsp;take exercise seriously, rather than neglecting it, is precisely because of how it serves the joy, strength, and stability of my soul.</strong></p>
</blockquote>
<p>He goes on to argue that the main motivations to exercise are:</p>
<ul>
<li>For God</li>
<li>For our minds</li>
<li>For our will</li>
<li>For joy</li>
<li>For loving others</li>
</ul>
<p>I found the chapters on our minds and our wills to be the most interesting as I’ve actually experienced the impact of both. Mathis quotes from John Ratey’s book Spark extensively in this chapter:</p>
<blockquote class="blockquote">
<p>We all know that exercise makes us feel better, but most of us have no idea why. We assume it’s because we’re burning off stress or reducing muscle tension or boosting endorphins, and we leave it at that. But the real reason we feel so good when we get our blood pumping is that it makes the brain function at its best, and in my view, this benefit of physical activity is far more important—and fascinating—than what it does for the body. Building muscles and conditioning the heart and lungs are essentially side effects. I&nbsp;often tell my patients that the point of exercise is to build and condition the brain. (p.&nbsp;58)</p>
</blockquote>
<p>I didn’t really know there was such a close connection between exercise and the brain’s health. As a Christian who is commanded to love the Lord your God with all your heart, soul and <strong>mind</strong> (Matthew 22:37), exercise is one way I can develop my mind in order to love God better. My <a href="https://lawwu.github.io/posts/2024-10-13-running-6-months/#why-i-started-running">original motivation for running</a> was forward looking but at its core still physical. I wanted to be healthier so I could play with my grandkids one day. I realized if I was a normal person who ate the typical American diet I probably wouldn’t be able to do normal activities in my 70s and 80s. Learning that exercise trains not just the body but more importantly the mind was such a motivating truth.</p>
<p>The chapter on exercise training our wills was also good.</p>
<blockquote class="blockquote">
<p><strong>Exercise can train us to press through mild resistance in any difficult task and not quit—which is a priceless instinct to develop not just for life and work but also for the soul.</strong> After getting in shape as a runner, I&nbsp;learned to push myself in various ways, such as “leaning into the hill.” (p.69-70)</p>
</blockquote>
<blockquote class="blockquote">
<p>But in Christ, we have cause to move in another direction—to&nbsp;“not be conformed to this world, but be transformed by the renewal of [our minds]” (Rom. 12:2) through the renewal of our bodies—to&nbsp;present them as living sacrifices (Rom 12:1). When in doubt, we don’t want to default to what’s easiest. We want to pursue what’s most important, knowing that such things are typically the most mentally, emotionally, and physically demanding. (p.72-73)</p>
</blockquote>
<p>Through running, I have developed greater will power to do uncomfortable things. There were many runs I didn’t want to wake up early for. There were many runs that looked too difficult before I started (looking at you Race Practice Long Run). There were many runs that felt too difficult during like the 4th 800m repeat or the middle-third of a 5k time trial. Through pushing past my physical and mental limits I had placed on myself, I’ve learned my body and my mind can be trained. It can be trained to do ever harder things. Honestly, I’ve also seen this discipline and willingness to “push through” translate to other areas of my life like in work, at home or writing <a href="https://biblicalcounseling.com/training/certification/phase-2-exams-and-evaluations">ACBC essays</a>.</p>
<blockquote class="blockquote">
<p>When the author of Hebrews exhorts us to “run with endurance the race that is set before us” (Heb. 12:1), he also shows us how: “looking to Jesus, the founder and perfecter of our faith”—who leaned in, looking to the reward—“who for the joy that was set before him endured the cross, despising the shame, and is seated at the right hand of the throne of God” (12:2). (p.75)</p>
</blockquote>
<blockquote class="blockquote">
<p>Yet such pain and shame didn’t send Jesus retreating. Rather, he looked through the obstacle, horrific as it was, and saw the reward on the other side of the shame. Even as such barriers were set immediately before his face, he looked to the joy on the far side: being seated at the right hand of his Father. And so he leaned into the hill. (p.75-76)</p>
</blockquote>
<p>Overall, I found this book quite helpful in framing the proper heart I should whenever I exercise. It’s not to get faster and set PRs. It’s not to run races and experience the temporary high of race day. It’s not to be merely physically healthy so I can wrestle with my grandkids one day. Rather exercise is for training the body and mind, disciplining both so that I can love God and his people better. May I continue to exercise and run for his glory. “So, whether you eat or drink, or whatever you do, do all to the glory of God.” (1 Corinthians 10:31)</p>
<!-- 
He also reminds us of the definition of Christian Hedonism: "as one persuaded that God is most glorified in us when are most satisfied in him—I have a serious interest in how the human body serves not only natural joy but also spiritual joy."
-->


</section>

 ]]></description>
  <category>book review</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-11-24-little-theology-of-exercise/</guid>
  <pubDate>Mon, 24 Nov 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>First Marathon Reflections</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/</link>
  <description><![CDATA[ 




<p>I did it. I ran a marathon. Long Beach 2025 Marathon is finished. What an amazing race day and training block. I’ve heard that a race is a celebration of the training you have put in. That rings so much truer now that the race is over. All those easy runs, tempo/interval runs, long runs on Saturday or Sundays. It’s been a long journey with many ups and downs along the way.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 50%; margin-bottom: 20px;">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/long_beach_2025_marathon.jpg" class="img-fluid figure-img" width="400"></p>
<figcaption>Post marathon joy</figcaption>
</figure>
</div>
<section id="race-report" class="level1">
<h1>Race Report</h1>
<p>The race didn’t start out great. Parking was a pain. It felt way more crowded than last year.The spot I booked turned out to be not open. But the weather was good at the start. I started out in the 3:45-4:15 corral and I found myself with the 3:50 pacers and stuck with them for probably the first half of the race. The first half of the marathon was relatively easy since it was the same as <a href="https://lawwu.github.io/posts/2024-10-13-running-6-months/">last year’s HM course</a>. When the course split and then rounded CSULB, it got tough around mile 18 because of the hills, the unfamiliar course and some pain in my left foot. I tried my best to dig deep at that point and just push through. Thankfully the pain was tolerable and didn’t get much worse. I then had some more pain in my right leg at mile 22 but mentally the end felt pretty close. Seeing people cramp up left and right didn’t help my confidence. The course narrowed a lot at mile 23-25 so it was hard to maintain a sub 9 pace but I don’t think I could’ve physically managed that so it was God’s mercy on me. I imagine if I pushed hard the last 6 miles I could’ve tried for sub 3:50 but didn’t want to get greedy and also didn’t want to get hurt. I ended up finishing with a time of 3:52:12 which is about a 8:51 min per mile pace. I was and am so happy with this result.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 50%; margin-bottom: 20px;">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/long_beach_2025_marathon_splits.png" class="img-fluid figure-img" width="400"></p>
<figcaption>Mile splits</figcaption>
</figure>
</div>
<p>The above were my mile splits. Starting around mile 20 was when I started to slow down. Heart rate started creeping up too. I still had some left in the tank the last stretch though!</p>
</section>
<section id="race-goals" class="level1">
<h1>Race Goals</h1>
<p>My goals for the race were:</p>
<ul>
<li>Goal A: to train for it in a way that most glorifies God</li>
<li>Goal B: not get injured</li>
<li>Goal C: Go sub 4-hours</li>
</ul>
<p>By God’s grace, I was able to achieve all those goals!</p>
<section id="training-in-a-god-glorifying-way" class="level2">
<h2 class="anchored" data-anchor-id="training-in-a-god-glorifying-way">Training in a God Glorifying Way</h2>
<p>Since starting to run in 2024, I had run two previous half marathons that I wrote about <a href="https://lawwu.github.io/posts/2024-10-13-running-6-months/">here</a> and <a href="https://lawwu.github.io/posts/2025-02-02-second-half-marathon/">here</a>. I had wanted to run a full marathon before turning 40 and I thought the Long Beach Marathon would be a good fit since the majority of the training would happen during summer months when I had more time because my church’s Bible study is on break. In training for the two half marathons I’ve done, there were times I prioritized preparing for it over other more important responsibilities like my family. I told myself I had to be able to prioritize the right things first before even considering training for the full. I tried my best to do my long runs early Saturday or Sunday morning and to be back in time before my kids woke up. It didn’t always work out and I definitely had to sacrifice some time spent with my wife and kids if I otherwise wasn’t training.</p>
</section>
<section id="not-get-injured" class="level2">
<h2 class="anchored" data-anchor-id="not-get-injured">Not Get Injured</h2>
<p>My B goal was to not get injured. I’ve had a number of serious leg injuries playing basketball. I’m really grateful God has allowed me to run still and now run longer distances. I have yet to have a serious injury yet while running. The pain in my left foot and right leg wasn’t manageable during the race. Going for sub 3:50 crossed my mind but the risk of blowing up and getting hurt also crossed my mind. I tried running 5 days after the race but my foot still had a little pain. The same thing happened a week later. In total I took 2.5 weeks off after the race to let my foot heal.</p>
</section>
</section>
<section id="run-sub-4-hours" class="level1">
<h1>Run sub 4 hours</h1>
<p>To run a sub-4-hour marathon, you have to maintain a pace of 9:09 min per mile. I used <a href="https://web.runna.com/welcome?redirectUrl=https%3A%2F%2Fweb.runna.com%2Fredeem%3Fcode%3DRUNNANSB2XBJ">Runna</a> again to train for my marathon. I thought the app prepared me well for the race. About 4 weeks out, I was pretty confident I was going to be able to run sub 4. Runna had me do a Race Practice Long Run that was 22 miles with 12 miles of race pace (at the end!). That was by far the hardest workout mentally and physically. But completing that workout gave me confidence that sub 4 was going to be do-able since I was able to do the 12 mile block at a 9:08 pace. Going into race day, I felt like I had put in the necessary work and it was just time to reap the fruit and enjoy the race. Praise God I was able to cross the finish line 8 minutes faster than my goal at 3:52:12. You can see the official results <a href="https://results2.xacte.com/#/e/2611/searchable/23299">here</a>.</p>
</section>
<section id="lesson-1-training-was-the-most-valuable-piece" class="level1">
<h1>Lesson 1: Training was the most valuable piece</h1>
<p>My training block:</p>
<ul>
<li>May 5, 2025 to Oct 5, 2025</li>
<li>152 days</li>
<li>20 weeks</li>
<li>~100 runs</li>
<li>~600 miles</li>
<li>28 miles per week</li>
<li>95 hours, 4.4 hours per week</li>
<li>4 19+ mi runs</li>
<li>14 10+ mi runs</li>
</ul>
<p>Reflecting on the training block numbers, it was 20 weeks at about 30 miles per week. I spent 95 hours running or 4.4 hours per week. For this block I also added strength training at around once a week. I ran 19+ miles 4 times.</p>
<p>The race being around 4 hours was &lt;5% of the total time. So 95% of the time related to the marathon was spent training for it. This makes me think about all of the sports I watch, 95% of the time and effort has already been put in. I imagine this also applies to any sort of public performance (musical, comedy, etc). Simply going through the training my VO2 max has improved going from 43.7 in May 2024 to 57.7 in October 2025.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 50%; margin-bottom: 20px;">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/post_marathon_vo2_max.jpg" class="img-fluid figure-img" width="400"></p>
<figcaption>VO2 Max</figcaption>
</figure>
</div>
<p><a href="https://lawwu.github.io/posts/2024-10-13-running-6-months/#why-i-started-running">I started running</a> because I wanted to be able to do normal activities like play with my grandchildren in my 70s and 80s. I’m so grateful to have gotten to this point of having better cardio fitness (as measured by VO2 max). I feel better physically. I have clearer thinking. I have more energy through the day.</p>
<p>It’s been awhile since I’ve set a goal and worked for many months to accomplish that goal. Training for a marathon and using a training plan through Runna (though there are many other plans too), broke this down into manageble pieces. It was 20 weeks with 5 scheduled runs per week. The app took much of the mental strain of planning runs (tpye of runs, distance) which I really enjoyed. It’s so meaningful looking back to put my mind and body toward a goal and then finally accomplishing it. Going through this journey with running challenges me to set goals in other areas of life to grow in.</p>
</section>
<section id="lesson-2-there-are-so-many-facets-to-improving-as-a-runner-or-anything-else" class="level1">
<h1>Lesson 2: There are so many facets to improving as a runner (or anything else)</h1>
<p>There are so many different facets to improving as a runner. There are the different types of runs you can do: easy, tempo, intervals, progression runs, fartlek, long runs, strides, long runs with race pace blocks, etc. There’s also strength training, nutrition (in general) and during runs. There’s running shoes and other gear. There’s all these metrics you can look at: pace, heart rate, VO2 max, cadence, stride length, etc. And I’m only 1.5 years into this running journey.</p>
<p>There are different types of practicing, depending on what your goal is. For the marathon training block, I had less speed work. Much more of the time was spent extending the long runs from 13 miles (in a half marathon training plan) to 22 miles. I actually don’t think I improved my 1 mile, 5k, 10k or half-marathon time.</p>
<p>To grow in any area, it’s important to keep in mind the different types of knowledge and the different types of practice in that domain. For example:</p>
<ul>
<li>Personal finances:
<ul>
<li>knowledge: understanding taxes, knowing different investment accounts (Roth IRA, Backdoor IRA, Megabackdoor Roth, HSAs)</li>
<li>practice: managing spending/saving, growing your income, being a disciplined investor, opening different accounts, taking advantage of credit card rewards, giving</li>
</ul></li>
<li>Professionally in AI, ML, Data Science, AI Engineering:
<ul>
<li>knowledge: how businesses work, what <a href="https://r4ds.had.co.nz/tidy-data.html">tidy data</a> is, how machine learning models work, how language models are trained, different types of services a cloud provider has, MLOps best practices</li>
<li>practice: working with data, <a href="https://missing.csail.mit.edu/">how to use a command line, git and other topics</a>, using languages like SQL/Python, training ML models, creating an AI agent with different AI frameworks, understanding the mechanics of agentic coding</li>
</ul></li>
<li>Prayer:
<ul>
<li>knowledge: understanding what prayer is, studying the different types of prayers in the Bible</li>
<li>practice: praying differnt types of prayers like adoration, confession, thanksgiving, supplication, prayer walks, secret prayer, corporate prayer, prayer with spouse, prayer with kids</li>
</ul></li>
<li>Bible:
<ul>
<li>knowledge: understanding the reliability of the Bible, different genre’s of the Bible (I really benefitted from Fee’s <a href="https://amzn.to/4nHxh0Y">How to Read the Bible for All It’s Worth</a>), understanding different types of theology: Biblical Theology, Historical Theology, Systematic Theology and Practical Theology (I’ve learned a lot from DeRouchie and Naselli’s books on <a href="https://amzn.to/43NgRg7">Old Testament</a> and <a href="https://amzn.to/4nHxktG">New Testament Exegesis</a>)</li>
<li>practice: there are different ways to grow in the Word. Devotions (reading 1 chapter a day, reading a few verses at a time, reading 4 chapters a day (Disciples reading plan, Piper likes this), reading 1 book of the Bible a day (JMac)), there’s doing inductive Bible study by reading one passage (reading multiple translations, understanding the context, asking questions), doing deeper study Biblical theology type study on a topic like what is the temple and how that idea develops between the OT and</li>
</ul></li>
</ul>
<p>This applies to all kinds of topics like:</p>
<ul>
<li>reading</li>
<li>writing</li>
<li>marriage</li>
<li>parenting/kids</li>
<li>lifting weights</li>
<li>eating / nutrition</li>
<li>fishing</li>
<li>camping</li>
<li>learning a music instrument</li>
<li>cooking, baking</li>
<li>personal productivity</li>
</ul>
<p>The lesson here is if you want to grow in an area, there’s knowledge you need to accumulate and different forms of practice you need to engage in.</p>
</section>
<section id="lesson-3-running-is-getting-popular" class="level1">
<h1>Lesson 3: Running is getting popular!</h1>
<p>The graph below shows the number of half-marathon, marathon and total participants in the Long Beach races. You can see since the COVID 2020 year, the number of runners has gone up each year.</p>
<div class="quarto-figure quarto-figure-center" style="border-radius: 50%; margin-bottom: 20px;">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/long_beach_marathon_participants_by_year.png" class="img-fluid figure-img" width="800"></p>
<figcaption>Long Beach Marathon Participation by year</figcaption>
</figure>
</div>
<p>There were 20,126 total participants in 2025 compared to 16,818, a 20% increase. I really felt it this year as everything felt more crowded: parking, race start, on the course, finishing the race felt like we were cattle being herded.</p>
<p>The data and code for every year for the Long Beach marathon is <a href="https://github.com/lawwu/long_beach_marathons">here</a>. Note I did use <a href="https://github.com/openai/codex">codex</a> to pull this data.</p>
</section>
<section id="lesson-4-physical-training-is-of-some-value" class="level1">
<h1>Lesson 4: Physical training is of some value</h1>
<blockquote class="blockquote">
<p>For physical training is of some value, but godliness has value for all things, holding promise for both the present life and the life to come. (<a href="https://www.biblegateway.com/passage/?search=1%20timothy%204%3A8&amp;version=NIV">1 Timothy 4:8, NIV</a>)</p>
</blockquote>
<p>This verse says that physical training is of some value. I have certainly seen the “some value” play out in my life. We weren’t created to be sedentary creatures. I feel overall healthier, have lost &gt;5 lbs, have higher VO2 max and have finally found a form of cardio that I enjoy and can do regularly.</p>
<p>The verse goes on to say that “godliness has value for all things” because it holds “promise for both the present life and the life to come.” Growing in godliness and Christ-likeness is what I hope to learn to value more than physical training and grow in more in the coming months and years. I am interested in reading this book <a href="https://amzn.to/3JEccGu">A Little Theology of Exercise: Enjoying Christ in Body and Soul</a> by David Mathis. I heard about this book through this video:</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/7diw2lK1aZ0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>


</section>

 ]]></description>
  <category>running</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-10-30-first-marathon-reflections/</guid>
  <pubDate>Thu, 30 Oct 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>How to Learn AI</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-09-09-how-to-learn-ai/</link>
  <description><![CDATA[ 




<p>I was recently asked how you can learn AI. This is a pretty difficult question to answer because 1) AI’s development is so rapid and 2) everyone is coming from a different starting place and 3) people have different use cases. Il’l try my best here.</p>
<p>My recommendations are different if you are someone who writes code vs.&nbsp;someone who doesn’t. There are many forms of AI but in this article I’ll mainly talk about how one can learn about Generative AI as opposed to more traditional forms of AI like machine learning. First some resources for both groups:</p>
<section id="coders-and-non-coders" class="level1">
<h1>Coders and Non-Coders</h1>
<section id="watch-some-helpful-videos" class="level2">
<h2 class="anchored" data-anchor-id="watch-some-helpful-videos">Watch some helpful videos</h2>
</section>
<section id="blue1brown---large-language-models-explained-briefly" class="level2">
<h2 class="anchored" data-anchor-id="blue1brown---large-language-models-explained-briefly">3Blue1Brown - Large Language Models Explained Briefly</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LPZh9BOjkQs" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="karpathy---intro-to-llms" class="level3">
<h3 class="anchored" data-anchor-id="karpathy---intro-to-llms">Karpathy - Intro to LLMs</h3>
<p>For everyone I recommend this 1-hour talk by Andrej Karpathy as an introduction to Large Language Models. He is a fantastic educator who can explain complicated topics quite simply.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/zjkBMFhNj_g" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="karpathy---how-i-use-llms" class="level2">
<h2 class="anchored" data-anchor-id="karpathy---how-i-use-llms">Karpathy - How I Use LLMs</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/EWvNQjAaOHw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="curate-some-trusted-learning-sources" class="level2">
<h2 class="anchored" data-anchor-id="curate-some-trusted-learning-sources">Curate some trusted learning sources</h2>
<p>There is a ton of AI-related content. You’ll need to curate a set of trusted sources that is appropriate to your level. I’ve compiled some of my favorite resources <a href="https://lawwu.github.io/ai_resources.html">here</a>.</p>
</section>
<section id="take-a-course" class="level2">
<h2 class="anchored" data-anchor-id="take-a-course">Take a course</h2>
<p>I’ve taken a few of the short courses from <a href="https://www.deeplearning.ai/courses/">DeepLearning.ai</a> and found them helpful.</p>
</section>
</section>
<section id="non-coders" class="level1">
<h1>Non-Coders</h1>
<section id="start-using-ai" class="level2">
<h2 class="anchored" data-anchor-id="start-using-ai">Start using AI</h2>
<p>I recommend starting with ChatGPT. ChatGPT is the de-facto chat-based interface to a large language model. You can access their flagship model <code>gpt-5</code> for free. You can use it for things you would normally search for. You will develop intuition for things it is good for and not good for. You’ll get a sense for when the model will use more reasoning or some of it’s built in tools like Search or Coding. Some of the things I use ChatGPT for are:</p>
<ul>
<li>Creating summaries of long-form content like sermons or <a href="https://lawwu.github.io/transcripts/">YouTube videos</a>. I record talks I listen to with my iPhone and generate transcripts on device. These transcripts can be fed into AI to generate summaries, extract quotes, etc.</li>
<li>Acting as a running coach: giving me feedback on completed runs, recommended nutrition for an upcoming race, random questions I have about different types of runs</li>
<li>Helping me learn new tools like <a href="https://obsidian.md/">Obsidian</a>, how to use templates to organize notes from reading books</li>
<li>Taking pictures of things to identify them, figure out what is wrong (e.g.&nbsp;plants in our garden or something broken)</li>
<li>Taking pictures of documents to extract text. For example a handout at church or seminar, you can take a picture and extract the text</li>
<li>asking how to explain a certain word or concept to an 8-year old</li>
<li>using voice mode to explain things to myself and the kids or do live translation</li>
</ul>
</section>
<section id="learn-to-code" class="level2">
<h2 class="anchored" data-anchor-id="learn-to-code">Learn to Code</h2>
<p>I would actually recommend you learn how to code. Even though I think AI will write the majority of code in the future, if you know how to code and what is possible with code, you will 1) be better able to prompt AI and 2) be able to take AI generated code and modify it for your purposes. Now is actually the best time to learn because AI can help you learn.. This course <a href="https://www.deeplearning.ai/short-courses/ai-python-for-beginners/">AI Python for Beginners</a> would be a good place to start.</p>
</section>
<section id="understand-ai-tools-in-your-domain" class="level2">
<h2 class="anchored" data-anchor-id="understand-ai-tools-in-your-domain">Understand AI-tools in your domain</h2>
<p>Companies are now creating AI-powered products. Your domain likely has one or will have one soon. For example lawyers have <a href="https://www.harvey.ai/">Harvey</a>. Product Managers have Replit or Lovable to quickly create functional prototypes of software or a new feature.</p>
</section>
</section>
<section id="coders" class="level1">
<h1>Coders</h1>
<section id="watch-some-of-karpathys-talks" class="level2">
<h2 class="anchored" data-anchor-id="watch-some-of-karpathys-talks">Watch some of Karpathy’s talks</h2>
<section id="karpathy---software-engineering-is-changing-again" class="level3">
<h3 class="anchored" data-anchor-id="karpathy---software-engineering-is-changing-again">Karpathy - Software engineering is changing again</h3>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/LCEmiRjPEtQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="karpathy---deep-dive-into-llms" class="level3">
<h3 class="anchored" data-anchor-id="karpathy---deep-dive-into-llms">Karpathy - Deep Dive into LLMs</h3>
<p>Long but pretty good</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/7xTGNNLPyMI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
</section>
<section id="use-an-ai-assistant-in-an-ide" class="level2">
<h2 class="anchored" data-anchor-id="use-an-ai-assistant-in-an-ide">Use an AI Assistant in an IDE</h2>
<p>AI Code Assistants have come a long way from Github Copilot in early 2023 which provided code completion. We now have agents that now live in our IDEs like VS Code, Cursor and Windsurf. It’s hard to recommend one but you can’t really go wrong with one of these.</p>
</section>
<section id="use-agentic-coding" class="level2">
<h2 class="anchored" data-anchor-id="use-agentic-coding">Use Agentic Coding</h2>
<p>Claude Code was the first truly useful agentic coding tool. I started using it in <a href="https://lawwu.github.io/posts/2025-07-18-starting-to-use-claude-code/">mid July</a> and wrote about it <a href="https://lawwu.github.io/posts/2025-07-18-claude-code-camp/">here</a> and again <a href="https://lawwu.github.io/posts/2025-08-14-armin-agentic-coding-ecosystem/">here</a>. I use it daily now during work. It has largely replaced the AI Assistants in an IDE. The power of coding agents lies in the fact it lives on your machine in a terminal. They are given very generic tools like a <code>Bash</code> and <code>Edit</code> file tool. Paired with a powerful foundational LLM that has reasoning capabilities, you now have an agent that can create plans, choose which tools it will use, run those tools, see the output and debug anything that goes wrong. The amount of things you can do in <code>Bash</code> is mind-boggling given how many built in tools there are AND how many command line utilities there are. Some of the recent things I’ve done with Claude Code are:</p>
<ul>
<li>created a presentation Quarto (basically creating powerpoint slides in Markdown) that I can convert to RevealJS or Powerpoint</li>
<li>explored data in Big Query (I actually didn’t know there was a <code>bq</code> command line tool until Claude Code started using it to explore some Big Query tables)</li>
<li>wrote and executed Kubeflow machine learning pipelines in VertexAI</li>
<li>implemented ideas from a research paper</li>
<li>created an MCP server for Lightcast called <a href="https://github.com/lawwu/mcp-lightcast">mcp-lightcast</a></li>
</ul>
</section>
<section id="understand-standard-interfaces-to-ai" class="level2">
<h2 class="anchored" data-anchor-id="understand-standard-interfaces-to-ai">Understand Standard Interfaces to AI</h2>
<p>This may deserve a longer post but you should be aware of the common interfaces to AI. Every company has an API you will call to gain access to their models. OpenAI, Google and Anthropic are the 3 largest providers. There are libraries like <a href="https://github.com/langchain-ai/langchain">langchain</a> that provide a common interface to call these models if you use a supported language (in this case it’s Python or Typescript). However at the API level there are common interfaces. OpenAI’s Chat Completions schema is one of those standard interfaces. The docs are <a href="https://platform.openai.com/docs/api-reference/chat/create">here</a> and the endpoint is a <code>POST</code> to <code>https://api.openai.com/v1/chat/completions</code>. If you use <a href="https://github.com/openai/openai-python">OpenAI’s Python SDK</a>, you can call the LLM using this code below:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> openai <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAI</span>
<span id="cb1-2">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAI()</span>
<span id="cb1-3"></span>
<span id="cb1-4">completion <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb1-5">  model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-5"</span>,</span>
<span id="cb1-6">  messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[</span>
<span id="cb1-7">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"developer"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are a helpful assistant."</span>},</span>
<span id="cb1-8">    {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hello!"</span>}</span>
<span id="cb1-9">  ]</span>
<span id="cb1-10">)</span>
<span id="cb1-11"></span>
<span id="cb1-12"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(completion.choices[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>].message)</span></code></pre></div></div>
<p>What is powerful about this interface is, other companies have adopted it. For example, <a href="https://github.com/ollama/ollama">ollama</a> <a href="https://ollama.com/blog/openai-compatibility">started supporting the OpenAI Chat Completions API in 2024</a>. There are LLM proxies like <a href="https://github.com/BerriAI/litellm/">LiteLLM</a> that expose a Chat Completions API interface to EVERY model provider. So you can call Google, Anthropic or any vendor’s model through the same API. For example if you have a deployed LiteLLM proxy server and you’ve authenticated to Google’s models, you can call them with the same OpenAI Python SDK, just swapping in your LiteLLM <code>base_url</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> openai</span>
<span id="cb2-2">client <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> openai.OpenAI(</span>
<span id="cb2-3">    api_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"sk-1234"</span>,             <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># pass litellm proxy key, if you're using virtual keys</span></span>
<span id="cb2-4">    base_url<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"http://0.0.0.0:4000"</span> <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># litellm-proxy-base url</span></span>
<span id="cb2-5">)</span>
<span id="cb2-6"></span>
<span id="cb2-7">response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> client.chat.completions.create(</span>
<span id="cb2-8">    model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"team1-gemini-pro"</span>,</span>
<span id="cb2-9">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [</span>
<span id="cb2-10">        {</span>
<span id="cb2-11">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb2-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"what llm are you"</span></span>
<span id="cb2-13">        }</span>
<span id="cb2-14">    ],</span>
<span id="cb2-15">)</span>
<span id="cb2-16"></span>
<span id="cb2-17"><span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(response)</span></code></pre></div></div>
<p>Some other common interfaces you should learn and be aware of:</p>
<ul>
<li>OpenAI Responses API</li>
<li><a href="https://github.com/modelcontextprotocol/modelcontextprotocol">MCP</a> - Model Context Protocol is a protocol original from Anthropic to standarize the interface between AI and tools. Well adopted by many companies and has become a standard. Though in many cases, especially in the case of coding agents, I’ve had more success giving the agent the ability to just use a command line tool. For example, using the <code>gh cli</code> instead of the <a href="https://github.com/github/github-mcp-server">Github MCP Server</a>.</li>
<li><a href="https://github.com/a2aproject/A2A">A2A</a> - a protocol from Google that is to standardize the interface between AI Agents</li>
<li><a href="https://github.com/ag-ui-protocol/ag-ui">AG-UI</a> - Agent-User Interaction protocol from copilotkit. This is a newer framework that is supposed to standardize the interface between a user (frontend) and the agent/AI backend.</li>
<li><a href="https://github.com/BerriAI/litellm/">LiteLLM</a> - LLM Proxies like LiteLLM are very powerful and useful in large organizations to give developers a common interface to AI. <a href="https://www.youtube.com/watch?v=u-3IILWQPRM&amp;t=1306s&amp;ab_channel=ThePragmaticEngineer">Shopify uses LiteLLM internally</a>. You can also read about their usage <a href="https://newsletter.pragmaticengineer.com/p/how-ai-is-changing-software-engineering">here</a>.</li>
<li>Agent Frameworks like LangGraph, Google’s ADK. There are dozens of these now.</li>
</ul>
</section>
<section id="understand-what-foundation-models-are-capable-of" class="level2">
<h2 class="anchored" data-anchor-id="understand-what-foundation-models-are-capable-of">Understand What Foundation Models are Capable of</h2>
<p>ChatGPT was first released in 2022. Since that time there has been so many capabilities added to these model APIs that is difficult to keep up. A non-complete list is:</p>
<ul>
<li>Structured Output - you can define schemas and pass these schemas to the LLM to force it to generate valid JSON, useful for tasks like data extraction</li>
<li>Longer Context Windows</li>
<li>Tool Calling</li>
<li>Search tools</li>
<li>Code Execution</li>
<li>Computer Use</li>
<li>Memory</li>
<li>Deep Research</li>
<li>Reasoning - these models have thinking/reasoning budgets</li>
<li>Audio Understanding / Generation</li>
<li>Image Understanding / Generation</li>
<li>Video Understanding / Generation</li>
<li>Realtime audio capabilities</li>
</ul>
<p>No matter your background, the best way to learn AI is by using it, experimenting, and staying curious. The landscape changes constantly, but the principles of exploration and practice remain the same.</p>


</section>
</section>

 ]]></description>
  <category>ai</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-09-09-how-to-learn-ai/</guid>
  <pubDate>Tue, 09 Sep 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Why Companies Should Open Source and Host Their Own MCP Servers</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-08-21-open-source-mcp-servers/</link>
  <description><![CDATA[ 




<p><a href="https://github.com/modelcontextprotocol/modelcontextprotocol"><strong>Model Context Protocol (MCP)</strong></a> has quickly become a standard interface for how agents and LLM-powered clients interact with tools and APIs. What’s exciting is that some companies are already hosting <strong>public-facing MCP servers</strong> with authorization. For example, Atlassian provides one here: <a href="https://support.atlassian.com/rovo/docs/getting-started-with-the-atlassian-remote-mcp-server/">Getting Started with the Atlassian Remote MCP Server</a>. Their MCP server lives at: <a href="https://mcp.atlassian.com/v1/sse">https://mcp.atlassian.com/v1/sse</a>.</p>
<p>This means customers can simply plug in that URL, add their authentication credentials, and instantly connect <strong>any MCP client</strong>—whether that’s VS Code, Windsurf, ChatGPT (<a href="https://platform.openai.com/docs/guides/tools-remote-mcp">directly now in their Responses API</a>, <a href="https://docs.anthropic.com/en/docs/claude-code/mcp">Claude Code</a>), or agent frameworks like <a href="https://github.com/langchain-ai/langgraph">LangGraph</a> and <a href="https://github.com/google/adk-python">ADK</a>. Users don’t have to worry about deploying or managing their own MCP instance. Users also do not need to rely on companies to build agents or AI applications for their services. Users can go ahead and use their LLM or AI tool of choice and plug in these remote MCP servers to build their own agents and AI applications.</p>
<p>That’s a powerful model—and one that more companies should follow.</p>
<hr>
<section id="why-this-matters-for-companies" class="level2">
<h2 class="anchored" data-anchor-id="why-this-matters-for-companies">Why This Matters for Companies</h2>
<p>Each company has an opportunity to be forward-leaning and recognized as an <strong>AI-first company</strong> in how they adopt and expose MCP internally and externally. By exposing MCPs, they will allow their customers the flexibility to build custom agents and AI applications on top of the company’s APIs and their data in the vendor.</p>
<p>For example, now that there is an Atlassian MCP Server that is compatible with JIRA and Confluence, anyone can build a:</p>
<ul>
<li>JIRA Agent that uses JIRA tools in the Atlassian MCP Server in any AI tool: ChatGPT, Claude, Claude Code, LangGraph, you name it.</li>
<li>Confluence Deep Research Agent that uses Confluence tools in the Atlassian MCP Server in any AI tool with any reasoning model like <a href="https://platform.openai.com/docs/models/o3-deep-research">o3-deep-research</a> or <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-5-pro">gemini-2.5-pro</a> or any open source model of your choice.</li>
</ul>
<p>Right now, very few companies are both:</p>
<ul>
<li><strong>Open sourcing their MCP Server code</strong>, and<br>
</li>
<li><strong>Hosting public remote MCP servers</strong>.</li>
</ul>
<p>I think companies should do both. Here’s how.</p>
<hr>
</section>
<section id="recommended-next-steps" class="level2">
<h2 class="anchored" data-anchor-id="recommended-next-steps">Recommended Next Steps</h2>
<section id="identify-endpoints-and-workflows-to-expose-as-mcp-tools" class="level3">
<h3 class="anchored" data-anchor-id="identify-endpoints-and-workflows-to-expose-as-mcp-tools">1. Identify Endpoints and Workflows to Expose as MCP Tools</h3>
<p>Not every REST API makes a good MCP tool. Instead of exposing every single endpoint, you should focus on <strong>common workflows</strong> that agents will use.</p>
<ul>
<li><p>Example: When I built a Python SDK for the Lightcast API, a frequent operation was normalizing job titles and retrieving related skills. Doing this directly required <em>three</em> separate API calls (normalize_title, map normalized title to a Lightcast Specialized Occupation and get related skills to that Lightcast Specialized Occupation). Instead, I created a <strong>dedicated tool/API</strong> that bundled those calls together—much more natural for an agent.</p></li>
<li><p>Jeremiah Lowin (creator of FastMCP) describes this well in <a href="https://www.jlowin.dev/blog/stop-converting-rest-apis-to-mcp">Stop Converting REST APIs to MCP</a>:<br>
&gt; <em>“An API that is ‘sophisticated’ for a human is one with rich, composable, atomic parts. An API that is sophisticated for an agent is one that is ruthlessly curated and minimalist.”</em></p></li>
</ul>
<p>You should design with the agent in mind. That might mean rethinking data formats (YAML is often better than JSON) or collapsing multi-step operations into a single MCP tool.</p>
<hr>
</section>
<section id="build-the-api-client-mcp-server-and-tools" class="level3">
<h3 class="anchored" data-anchor-id="build-the-api-client-mcp-server-and-tools">2. Build the API Client, MCP Server, and Tools</h3>
<p>The typical stack looks like this:</p>
<ul>
<li><strong>API Client</strong>: Handles authentication and connectivity to your company’s APIs.<br>
</li>
<li><strong>MCP Server</strong>: Implements the MCP protocol on top of that client.</li>
</ul>
<p>All of the MCP servers I’ve written so far are in Python, using <a href="https://github.com/jlowin/fastmcp">FastMCP</a> as the framework. The pattern is straightforward:</p>
<ol type="1">
<li>Write an API Client.<br>
</li>
<li>Layer the MCP protocol logic on top.</li>
</ol>
<p>You can use agentic coding tools like Claude Code to quickly spin these up.</p>
<hr>
</section>
<section id="deploy-the-mcp-server-publicly" class="level3">
<h3 class="anchored" data-anchor-id="deploy-the-mcp-server-publicly">3. Deploy the MCP Server Publicly</h3>
<p>There are more options than ever for running lightweight public services:</p>
<ul>
<li><a href="https://cloud.google.com/blog/topics/developers-practitioners/build-and-deploy-a-remote-mcp-server-to-google-cloud-run-in-under-10-minutes">Google Cloud Run</a><br>
</li>
<li><a href="https://blog.cloudflare.com/remote-model-context-protocol-servers-mcp/">Cloudflare Workers</a></li>
</ul>
<p>Each of these can make your MCP server accessible with minimal operational overhead.</p>
<hr>
</section>
<section id="provide-example-clients-and-agents" class="level3">
<h3 class="anchored" data-anchor-id="provide-example-clients-and-agents">4. Provide Example Clients and Agents</h3>
<p>To encourage adoption, publish sample implementations that connect to the server. These could be:</p>
<ul>
<li>VS Code extensions<br>
</li>
<li>LangGraph or ADK agents<br>
</li>
<li>Example workflows in ChatGPT or Claude</li>
</ul>
<p>This lowers the barrier for customers to experiment quickly.</p>
<hr>
</section>
<section id="open-source-the-mcp-server" class="level3">
<h3 class="anchored" data-anchor-id="open-source-the-mcp-server">5. Open Source the MCP Server</h3>
<p>Some of the most popular MCP servers today aren’t even official. For example, the <strong><a href="https://github.com/sooperset/mcp-atlassian">mcp-atlassian</a></strong> project is developed by an open-source developer <a href="https://github.com/sooperset">Hyeonsoo Lee</a> and not by Atlassian. That’s a missed opportunity.</p>
<p>If companies open source their MCP servers, the benefits are significant:</p>
<ul>
<li>Community contributions and bug fixes<br>
</li>
<li>Customer self-hosting when desired<br>
</li>
<li>Stronger trust and transparency</li>
</ul>
<hr>
</section>
<section id="lightcast-mcp-server" class="level3">
<h3 class="anchored" data-anchor-id="lightcast-mcp-server">6. Lightcast MCP Server</h3>
<p>I’ve interacted with the Lightcast API a fair amount and open-sourced an MCP Server for Lightcast called <a href="https://github.com/lawwu/mcp-lightcast">mcp-lightcast</a>.</p>
</section>
</section>
<section id="popular-remote-mcp-servers" class="level2">
<h2 class="anchored" data-anchor-id="popular-remote-mcp-servers">Popular Remote MCP Servers</h2>
<p>Several companies are already providing remote MCP servers that you can connect to directly. Here are some notable examples from the <a href="https://docs.anthropic.com/en/docs/claude-code/mcp">Claude Code MCP docs</a> and from <a href="https://github.com/jaw9c/awesome-remote-mcp-servers">awesome-remote-mcp-servers</a>.</p>
<section id="adding-remote-servers-to-claude-code" class="level3">
<h3 class="anchored" data-anchor-id="adding-remote-servers-to-claude-code">Adding Remote Servers to Claude Code</h3>
<p>You can easily add these servers to Claude Code using the CLI. Note some of these are not remote MCP servers. Here are the exact commands:</p>
<section id="development-testing-tools" class="level4">
<h4 class="anchored" data-anchor-id="development-testing-tools">Development &amp; Testing Tools</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http sentry https://mcp.sentry.dev/mcp</span>
<span id="cb1-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http socket https://mcp.socket.dev/</span>
<span id="cb1-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http hugging-face https://huggingface.co/mcp</span>
<span id="cb1-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http jam https://mcp.jam.dev/mcp</span></code></pre></div></div>
</section>
<section id="project-management" class="level4">
<h4 class="anchored" data-anchor-id="project-management">Project Management</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse asana https://mcp.asana.com/sse</span>
<span id="cb2-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse atlassian https://mcp.atlassian.com/v1/sse</span>
<span id="cb2-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add clickup <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--env</span> CLICKUP_API_KEY=YOUR_KEY <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--env</span> CLICKUP_TEAM_ID=YOUR_ID <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--</span> npx <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> @hauptsache.net/clickup-mcp</span>
<span id="cb2-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http intercom https://mcp.intercom.com/mcp</span>
<span id="cb2-5"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse linear https://mcp.linear.app/sse</span>
<span id="cb2-6"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http notion https://mcp.notion.com/mcp</span>
<span id="cb2-7"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http box https://mcp.box.com/</span>
<span id="cb2-8"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http fireflies https://api.fireflies.ai/mcp</span>
<span id="cb2-9"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse monday https://mcp.monday.com/sse</span></code></pre></div></div>
</section>
<section id="databases" class="level4">
<h4 class="anchored" data-anchor-id="databases">Databases</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add airtable <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--env</span> AIRTABLE_API_KEY=YOUR_KEY <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--</span> npx <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-y</span> airtable-mcp-server</span>
<span id="cb3-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http daloopa https://mcp.daloopa.com/server/mcp</span>
<span id="cb3-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http hubspot https://mcp.hubspot.com/anthropic</span></code></pre></div></div>
</section>
<section id="payments-commerce" class="level4">
<h4 class="anchored" data-anchor-id="payments-commerce">Payments &amp; Commerce</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http paypal https://mcp.paypal.com/mcp</span>
<span id="cb4-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse plaid https://api.dashboard.plaid.com/mcp/sse</span>
<span id="cb4-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse square https://mcp.squareup.com/sse</span>
<span id="cb4-4"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http stripe https://mcp.stripe.com</span></code></pre></div></div>
</section>
<section id="design" class="level4">
<h4 class="anchored" data-anchor-id="design">Design</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http figma-dev-mode-mcp-server http://127.0.0.1:3845/mcp</span>
<span id="cb5-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> sse invideo https://mcp.invideo.io/sse</span>
<span id="cb5-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http canva https://mcp.canva.com/mcp</span></code></pre></div></div>
</section>
<section id="infrastructure-devops" class="level4">
<h4 class="anchored" data-anchor-id="infrastructure-devops">Infrastructure / DevOps</h4>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb6-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http netlify https://netlify-mcp.netlify.app/mcp</span>
<span id="cb6-2"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http stytch http://mcp.stytch.dev/mcp</span>
<span id="cb6-3"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> mcp add <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--transport</span> http vercel https://mcp.vercel.com/</span></code></pre></div></div>
<p>For more details, see the <a href="https://docs.anthropic.com/en/docs/claude-code/mcp">Claude Code MCP documentation</a>.</p>
<hr>


</section>
</section>
</section>

 ]]></description>
  <category>ai</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-08-21-open-source-mcp-servers/</guid>
  <pubDate>Thu, 21 Aug 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Summaries of Talks from Code with Claude Conference 2025</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-08-14-claude-code-conference-summary/</link>
  <description><![CDATA[ 




<section id="code-with-claude-conference-2025-key-insights-summaries" class="level1">
<h1>Code with Claude Conference 2025: Key Insights &amp; Summaries</h1>
<p>Claude had a <a href="https://www.anthropic.com/events/code-with-claude-2025">conference</a> recently all about Claude Code. I transcribed all of the talks using <a href="https://github.com/lawwu/transcripts">transcripts</a> and hosted it <a href="https://lawwu.github.io/transcripts/index_claude_code_conference.html">here</a>. The YouTube playlist is <a href="https://www.youtube.com/playlist?list=PLf2m23nhTg1P5BsOHUOXyQz5RhfUSSVUi">here</a>. Below are summaries of the talks.</p>
<section id="overall-summary" class="level2">
<h2 class="anchored" data-anchor-id="overall-summary">Overall Summary</h2>
<p>The Claude Code Conference 2025 showcased groundbreaking developments in AI-powered development tools, enterprise AI implementations, and the future of human-AI collaboration in software engineering. The conference highlighted the evolution from simple AI assistants to sophisticated autonomous agents capable of complex reasoning and long-term task execution.</p>
<p>Key themes included the introduction of Claude 4’s extended thinking capabilities, the emergence of Model Context Protocol (MCP) as the universal standard for AI-tool integration, and real-world enterprise implementations demonstrating significant productivity gains. The conference also emphasized the importance of proper prompting techniques, agent evaluation frameworks, and the shift toward “agentic” development paradigms.</p>
</section>
<section id="top-10-key-takeaways-for-developers" class="level2">
<h2 class="anchored" data-anchor-id="top-10-key-takeaways-for-developers">Top 10 Key Takeaways for Developers</h2>
<ol type="1">
<li><p><strong>Start with codebase Q&amp;A before writing code</strong> - This approach reduces onboarding time from 2-3 weeks to 2-3 days and helps understand existing patterns and architecture.</p></li>
<li><p><strong>Invest in Claude.md configuration files</strong> - These provide persistent context and coding standards across sessions, dramatically improving AI performance on your specific projects.</p></li>
<li><p><strong>Embrace parallel tool calling and extended thinking</strong> - Claude 4’s new capabilities enable more efficient workflows and better planning between actions.</p></li>
<li><p><strong>Use MCP servers as the standard for AI-tool integration</strong> - MCP is becoming the “USB-C of LLMs” and provides a standardized way to connect AI to external systems.</p></li>
<li><p><strong>Focus on tool design over complex prompting</strong> - Clear tool descriptions and proper interfaces are more important than elaborate prompt engineering for agent performance.</p></li>
<li><p><strong>Implement proper evaluation frameworks</strong> - Use realistic tasks and LLM-as-judge approaches rather than relying solely on benchmarks like SweeBench.</p></li>
<li><p><strong>Think beyond traditional code review for AI-generated code</strong> - Design verifiable systems with clear inputs/outputs rather than trying to review every line of AI-generated code.</p></li>
<li><p><strong>Leverage the model-tool binding principle</strong> - The best performing agents use foundation models specifically trained on the tools they use (like Sonnet with bash commands).</p></li>
<li><p><strong>Build composable, multi-step agent systems</strong> - Enterprise reliability comes from breaking complex tasks into manageable, evaluable components with clear feedback loops.</p></li>
<li><p><strong>Prepare for rapid capability growth</strong> - AI task capability is doubling every 7 months, requiring adaptive development approaches and architectural thinking.</p></li>
</ol>
<hr>
</section>
<section id="claude-plays-pokemon-tool-use-and-agent-improvements" class="level2">
<h2 class="anchored" data-anchor-id="claude-plays-pokemon-tool-use-and-agent-improvements">Claude Plays Pokemon: Tool Use and Agent Improvements</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/0XUzn-DEoY8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Speaker:</strong> David (Creator of Claude Plays Pokemon, Anthropic’s PodAI team)</p>
<section id="key-points-and-insights" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights">Key Points and Insights</h3>
<ul>
<li><strong>Extended thinking between tool calls</strong>: Claude 4 introduces extended thinking between tool calls, allowing models to plan, reflect, and question assumptions before acting</li>
<li><strong>Parallel tool calling capability</strong>: Models can now make multiple tool calls simultaneously, improving efficiency and reducing latency</li>
<li><strong>Tool use evolution</strong>: From simple calculator aids to driving complex agentic workflows with plan-act-learn loops</li>
<li><strong>Scale of tool handling</strong>: Models can now handle 50-100 tools effectively with proper tool design and clear descriptions</li>
<li><strong>Real-world validation</strong>: Claude 4 Opus successfully executed a 24-hour Pokemon catching session, demonstrating improved long-term planning</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers">Main Takeaways for Developers/Users</h3>
<ul>
<li>Focus on tool design and clear descriptions rather than complex prompting</li>
<li>Extended thinking mode helps agents recover from errors and adapt plans dynamically</li>
<li>Parallel tool calling significantly reduces development time by eliminating sequential tool call overhead</li>
<li>Models are becoming more capable agents that can work over longer time horizons with less human intervention</li>
</ul>
<hr>
</section>
</section>
<section id="mastering-claude-code-in-30-minutes" class="level2">
<h2 class="anchored" data-anchor-id="mastering-claude-code-in-30-minutes">Mastering Claude Code in 30 Minutes</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/6eBSHbLKuN0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Speaker:</strong> Boris (Member of Technical Staff at Anthropic, Creator of Claude Code)</p>
<section id="key-points-and-insights-1" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-1">Key Points and Insights</h3>
<ul>
<li><strong>Codebase Q&amp;A first</strong>: Start with codebase Q&amp;A before writing code - reduces onboarding from 2-3 weeks to 2-3 days at Anthropic</li>
<li><strong>Full multimodal support</strong>: Claude Code is fully multimodal and works across all IDEs without requiring workflow changes</li>
<li><strong>Context is king</strong>: Use claude.md files, slash commands, and MCP servers to provide relevant project information</li>
<li><strong>Hierarchical configuration</strong>: Configuration system allows enterprise policies, project configs, and personal preferences</li>
<li><strong>SDK capabilities</strong>: Claude Code SDK enables building agents and automation pipelines with Unix-style utility approach</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-1" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-1">Main Takeaways for Developers/Users</h3>
<ul>
<li>Begin every new project/codebase with Q&amp;A to understand structure and patterns</li>
<li>Invest time in configuring claude.md and context files for dramatic performance improvements</li>
<li>Use iterative workflows with verification tools (testing, screenshots) for better results</li>
<li>Leverage the SDK for CI/CD pipelines, incident response, and automated workflows</li>
</ul>
<hr>
</section>
</section>
<section id="spotlight-on-databricks-enterprise-ai-implementation" class="level2">
<h2 class="anchored" data-anchor-id="spotlight-on-databricks-enterprise-ai-implementation">Spotlight on Databricks: Enterprise AI Implementation</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/67a5yrKH-nI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Speaker:</strong> Craig (Product Management Leader at Databricks, former Google Vertex AI/AWS SageMaker)</p>
<section id="key-points-and-insights-2" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-2">Key Points and Insights</h3>
<ul>
<li><strong>Enterprise governance requirements</strong>: Enterprise AI requires governance and evaluation for production deployment in high-risk environments</li>
<li><strong>Multi-step agent superiority</strong>: Multi-step agentic systems outperform simple input-output models (Berkeley research validation)</li>
<li><strong>Tool calling excellence</strong>: Claude’s superior tool calling enables deterministic systems using probabilistic backends</li>
<li><strong>Real customer results</strong>: FactSet improved accuracy from 59% to 85% and reduced latency from 15s to 6s by decomposing prompts into multi-step workflows</li>
<li><strong>Productivity transformation</strong>: Claude integration reduces analyst questionnaire work from hundreds of hours to editing near-final drafts</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-2" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-2">Main Takeaways for Developers/Users</h3>
<ul>
<li>Build composable, multi-node agent systems for enterprise reliability</li>
<li>Implement rigorous evaluation frameworks to measure and improve system performance</li>
<li>Use Claude’s governance features to control data, model, and tool access at granular levels</li>
<li>Focus on connecting AI systems deeply with enterprise data infrastructure</li>
</ul>
<hr>
</section>
</section>
<section id="building-ai-agents-with-claude-in-amazon-bedrock" class="level2">
<h2 class="anchored" data-anchor-id="building-ai-agents-with-claude-in-amazon-bedrock">Building AI Agents with Claude in Amazon Bedrock</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/8gTpgWru0Wg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Speakers:</strong> Dewan Lightfoot, Banjo Abiyami, Suman Devanath (AWS Developer Advocates)</p>
<section id="key-points-and-insights-3" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-3">Key Points and Insights</h3>
<ul>
<li><strong>Strands Agent SDK simplicity</strong>: Simplifies agent building to just three components: models, tools, and prompts</li>
<li><strong>Claude 3.5 Sonnet default</strong>: Default model with built-in tools like HTTP requests requiring minimal setup</li>
<li><strong>MCP server integration</strong>: Provides structured way to connect LLMs to external APIs and documentation</li>
<li><strong>Live demo success</strong>: Showed creating weather agents, AWS documentation agents, and architecture diagram generators</li>
<li><strong>Seamless Bedrock integration</strong>: Claude Code integration with Bedrock enables development without requiring separate Anthropic API keys</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-3" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-3">Main Takeaways for Developers/Users</h3>
<ul>
<li>Use Strands for rapid prototyping with minimal boilerplate code</li>
<li>MCP servers are the “USB-C of LLMs” for connecting to external systems and data</li>
<li>AWS provides comprehensive MCP server ecosystem for cloud services integration</li>
<li>Agents work best when given specific context and clear tool definitions</li>
</ul>
<hr>
</section>
</section>
<section id="startups-building-new-products-with-claude" class="level2">
<h2 class="anchored" data-anchor-id="startups-building-new-products-with-claude">Startups Building New Products with Claude</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/91Haz1CRoxY" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p><strong>Speakers:</strong> Multiple startup founders (Tempo Labs, Zen, Gamma, Bitto, Refusion, Create)</p>
<section id="key-points-and-insights-4" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-4">Key Points and Insights</h3>
<ul>
<li><strong>Tempo Labs democratization</strong>: “Cursor for PMs and designers” - enables non-engineers to generate 10-15% of frontend PRs directly</li>
<li><strong>Gamma model upgrade impact</strong>: Sonnet 3.5 to 3.7 upgrade with web search improved user satisfaction metrics by 8%</li>
<li><strong>Bitto code review transformation</strong>: AI code review platform reducing PR closure time from 50 hours to 5 hours using Claude’s reasoning capabilities</li>
<li><strong>Refusion creative applications</strong>: Claude powers “Ghostwriter” for music lyric generation, used tens of millions of times</li>
<li><strong>Create democratized app development</strong>: Text-to-app builder enabling non-technical users to create full mobile apps end-to-end</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-4" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-4">Main Takeaways for Developers/Users</h3>
<ul>
<li>Claude enables product categories that democratize technical capabilities to non-engineers</li>
<li>Model upgrades (especially with new capabilities like web search) can dramatically impact user metrics</li>
<li>Successful products leverage Claude’s reasoning for domain-specific applications (code review, music, design)</li>
<li>Integration of frontend design tools with Claude enables visual, collaborative development workflows</li>
</ul>
<hr>
</section>
</section>
<section id="spotlight-on-canva-democratizing-interactive-prototyping" class="level2">
<h2 class="anchored" data-anchor-id="spotlight-on-canva-democratizing-interactive-prototyping">Spotlight on Canva: Democratizing Interactive Prototyping</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Ac4LiuoJT20" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Danny Wu (Head of AI Products at Canva)</p>
<section id="key-points-and-insights-5" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-5">Key Points and Insights</h3>
<ul>
<li><strong>Canva Code democratization</strong>: Built to democratize interactive prototyping using Claude, allowing non-technical users to create apps with simple prompts</li>
<li><strong>Functional prototype strategy</strong>: Used functional prototypes built with Claude to test concepts and gather user feedback before integrating into the main codebase</li>
<li><strong>Model selection beyond metrics</strong>: Chose Claude’s models for their ability to handle under-specified prompts, create beautiful web designs, and generate quality SVGs and animations</li>
<li><strong>User-focused targeting</strong>: Focused on targeting non-technical users first, then scaling up to more sophisticated functionality</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-5" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-5">Main Takeaways for Developers/Users</h3>
<ul>
<li>Think beyond traditional evals when choosing models - consider complete user experience including design quality and creativity</li>
<li>Build functional prototypes outside main codebase to enable faster experimentation in AI product development</li>
<li>Focus on your unique strengths and target specific user segments rather than trying to serve everyone</li>
<li>Communicate AI limitations clearly to users to prevent confusion and set proper expectations</li>
</ul>
<hr>
</section>
</section>
<section id="building-headless-automation-with-claude-code" class="level2">
<h2 class="anchored" data-anchor-id="building-headless-automation-with-claude-code">Building Headless Automation with Claude Code</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/dRsjO-88nBs" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Sirbit Asaria (Engineer on Claude Code team)</p>
<section id="key-points-and-insights-6" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-6">Key Points and Insights</h3>
<ul>
<li><strong>SDK programmatic access</strong>: Claude Code SDK enables programmatic access to Claude Code agent in headless mode, opening new automation possibilities</li>
<li><strong>Unix tool philosophy</strong>: Can be used as Unix tool, integrated into CI/CD pipelines, and for building custom chatbots or remote coding environments</li>
<li><strong>Advanced features</strong>: Features structured JSON output, session state management, and permission prompt tools for real-time user interaction</li>
<li><strong>GitHub Actions integration</strong>: Demonstrated GitHub Action built on SDK that can review code, create features, and manage pull requests automatically</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-6" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-6">Main Takeaways for Developers/Users</h3>
<ul>
<li>Claude Code SDK acts as a new primitive for building applications that weren’t possible before</li>
<li>Unix-style tool philosophy makes it pluggable anywhere you can run bash or terminal commands</li>
<li>Structured output and session management enable building interactive user experiences on top of the SDK</li>
<li>GitHub Actions integration shows how to safely automate code review and development workflows</li>
</ul>
<hr>
</section>
</section>
<section id="vibe-coding-in-production" class="level2">
<h2 class="anchored" data-anchor-id="vibe-coding-in-production">Vibe Coding in Production</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/fHWFF_pnqDk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Eric (Researcher at Anthropic focused on coding agents)</p>
<section id="key-points-and-insights-7" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-7">Key Points and Insights</h3>
<ul>
<li><strong>Vibe coding philosophy</strong>: Means fully embracing AI code generation and “forgetting the code exists” while staying focused on product outcomes</li>
<li><strong>AI capability acceleration</strong>: AI task capability is doubling every 7 months, making traditional code review approaches unsustainable for large-scale AI-generated work</li>
<li><strong>Production deployment success</strong>: Successfully deployed 22,000-line AI-generated change to production by focusing on leaf nodes, creating verifiable tests, and acting as Claude’s product manager</li>
<li><strong>Abstraction layer focus</strong>: Key is finding abstraction layers you can verify without understanding implementation details</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-7" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-7">Main Takeaways for Developers/Users</h3>
<ul>
<li>Focus vibe coding on “leaf nodes” in codebase where tech debt won’t impact core architecture</li>
<li>Act as an effective product manager for Claude by providing context, requirements, and guidance</li>
<li>Design systems with verifiable inputs/outputs and stress tests to validate correctness without reading all code</li>
<li>Embrace the exponential growth in AI capabilities rather than trying to review every line of generated code</li>
</ul>
<hr>
</section>
</section>
<section id="claude-code-best-practices" class="level2">
<h2 class="anchored" data-anchor-id="claude-code-best-practices">Claude Code Best Practices</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gv0WHhKelSE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Cal (Applied AI team at Anthropic, core Claude Code contributor)</p>
<section id="key-points-and-insights-8" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-8">Key Points and Insights</h3>
<ul>
<li><strong>Agentic search approach</strong>: Claude Code works as a pure agent using agentic search (glob, grep, find) rather than code indexing to understand codebases</li>
<li><strong>Claude.md importance</strong>: Claude.md files are essential for sharing context and instructions across sessions and team members</li>
<li><strong>Workflow optimization</strong>: Permission management, CLI tool integration, and context management (using /clear or /compact) are crucial for effective workflows</li>
<li><strong>New feature releases</strong>: Features include model switching, thinking between tool calls, and improved VS Code/JetBrains integrations</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-8" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-8">Main Takeaways for Developers/Users</h3>
<ul>
<li>Use Claude.md files in projects to provide persistent context and coding standards for Claude</li>
<li>Master permission management and auto-accept modes to speed up workflow without sacrificing safety</li>
<li>Leverage Claude’s terminal expertise by integrating CLI tools and MCP servers for expanded capabilities</li>
<li>Stay updated with rapid feature releases and experiment with advanced techniques like multi-agent workflows</li>
</ul>
<hr>
</section>
</section>
<section id="mcp-201-advanced-model-context-protocol" class="level2">
<h2 class="anchored" data-anchor-id="mcp-201-advanced-model-context-protocol">MCP 201: Advanced Model Context Protocol</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/HNzH5Us1Rvg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> David (Member of Technical Staff at Anthropic, co-creator of MCP)</p>
<section id="key-points-and-insights-9" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-9">Key Points and Insights</h3>
<ul>
<li><strong>Five MCP primitives</strong>: Offers 5 primitives beyond basic tool calling: prompts (user-driven templates), resources (application-driven data), tools (model-driven actions), sampling (server requests completion from client), and roots (client context inquiry)</li>
<li><strong>Interaction model clarity</strong>: Defines when to use what: prompts for user-driven interactions, resources for application-driven data access, tools for model-driven actions</li>
<li><strong>Evolution to web-based</strong>: MCP is evolving from local experiences to web-based servers with OAuth 2.1 authorization and streamable HTTP for scaling</li>
<li><strong>Future developments</strong>: Include asynchronous tasks, elicitation (user input requests), official registry, and multi-modality support</li>
<li><strong>Sampling power</strong>: Allows powerful chaining where servers can request model completions without managing API keys, keeping clients in control</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-9" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-9">Main Takeaways for Developers/Users</h3>
<ul>
<li>Use the full power of MCP’s primitives to build richer interactions beyond simple tool calling</li>
<li>Consider the interaction model when designing MCP servers: user-driven vs application-driven vs model-driven</li>
<li>Prepare for web-based MCP servers with proper OAuth implementation for enterprise integration</li>
<li>Future-proof applications by understanding upcoming features like sampling and async task support</li>
</ul>
<hr>
</section>
</section>
<section id="mcp-at-sourcegraph-building-enterprise-coding-agents" class="level2">
<h2 class="anchored" data-anchor-id="mcp-at-sourcegraph-building-enterprise-coding-agents">MCP at Sourcegraph: Building Enterprise Coding Agents</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/j8NlbEWAsmc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Biong (CTO and co-founder of Sourcegraph)</p>
<section id="key-points-and-insights-10" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-10">Key Points and Insights</h3>
<ul>
<li><strong>Three waves of AI architecture</strong>: Evolution through co-pilot era (text completion), RAG chat era, and now the agents era with tool calling and MCP</li>
<li><strong>AMP agent architecture</strong>: Sourcegraph built AMP, a new coding agent from scratch using the “recipe for AI agents”: strong tool-use LLM + MCP + feedback loops + imperative UX</li>
<li><strong>Comprehensive MCP integration</strong>: Spans local tools (Playwright, Postgres) and external services (Linear, Sentry) with secure secret handling via OAuth proxy</li>
<li><strong>Toolmageddon avoidance</strong>: Too many MCP tools can confuse models; focus on three buckets: context finding, feedback provision, and success declaration</li>
<li><strong>Future agent patterns</strong>: Sub-agents and dynamic tool synthesis represent the future, with parallels to early programming language development</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-10" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-10">Main Takeaways for Developers/Users</h3>
<ul>
<li>Rethink application architecture for the agentic era rather than retrofitting existing RAG-chat applications</li>
<li>Focus on feedback loops and design patterns that make agents reliable and self-correcting</li>
<li>Implement secure MCP integration with proper OAuth handling for enterprise environments</li>
<li>Consider sub-agents as tools and prepare for more sophisticated tool composition patterns</li>
</ul>
<hr>
</section>
</section>
<section id="taking-claude-to-the-next-level-claude-4-features" class="level2">
<h2 class="anchored" data-anchor-id="taking-claude-to-the-next-level-claude-4-features">Taking Claude to the Next Level: Claude 4 Features</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nZCy8E5jlok" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Lisa Crowfoot (Research Product Manager at Anthropic)</p>
<section id="key-points-and-insights-11" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-11">Key Points and Insights</h3>
<ul>
<li><strong>Four major improvements</strong>: Claude 4 (Opus and Sonnet) introduces interleaved thinking and tool use, memory capabilities, complex instruction following, and reduced reward hacking</li>
<li><strong>Memory enables persistence</strong>: Sustained performance over hours, with Claude Opus tracking progress across 64 Pokemon battles (12+ hours of gameplay)</li>
<li><strong>Better instruction following</strong>: Claude 4 models are less “over-eager” by default and better at following complex system prompts (16k+ tokens)</li>
<li><strong>Reduced reward hacking</strong>: 80%+ reduction in reward hacking behavior makes Claude more trustworthy for autonomous tasks</li>
<li><strong>Model specialization</strong>: Opus excels at complex tasks (large codebases, migrations), while Sonnet 4 is optimized for speed and human-in-the-loop scenarios</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-11" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-11">Main Takeaways for Developers/Users</h3>
<ul>
<li>Remove anti-over-eagerness language from prompts when upgrading to Claude 4</li>
<li>Leverage parallel tool calling and specify thinking targets for better agent performance</li>
<li>Use Opus for complex, long-horizon tasks and Sonnet for rapid iteration and human collaboration</li>
<li>Invest in prompt engineering as small changes can significantly impact performance</li>
</ul>
<hr>
</section>
</section>
<section id="building-blocks-for-tomorrows-ai-agents" class="level2">
<h2 class="anchored" data-anchor-id="building-blocks-for-tomorrows-ai-agents">Building Blocks for Tomorrow’s AI Agents</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/oDks2gVHu4k" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Brad Abrams (Product Manager at Anthropic)</p>
<section id="key-points-and-insights-12" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-12">Key Points and Insights</h3>
<ul>
<li><strong>Three pillars for agents</strong>: Build (Claude 4 + code execution), Connect (web search + MCP connector), and Optimize (caching + batch + priority tiers)</li>
<li><strong>Code execution capabilities</strong>: Provides dedicated containers per organization with streaming results, enabling complex data analysis and computational tasks</li>
<li><strong>Agentic web search</strong>: Delivers agentic, multi-turn search with automatic citation and domain restriction capabilities</li>
<li><strong>MCP Connector enterprise</strong>: Enables secure OAuth-based integration with remote MCP servers (Asana, Zapier, CloudFlare-hosted services)</li>
<li><strong>Optimization features</strong>: 1-hour prompt caching, batch API as async agentic API, and priority tier for dedicated capacity</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-12" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-12">Main Takeaways for Developers/Users</h3>
<ul>
<li>Combine code execution with web search for powerful analytical capabilities</li>
<li>Leverage remote MCP servers with OAuth for enterprise-grade integrations</li>
<li>Use batch processing as an async agentic API with 50% cost savings</li>
<li>Take advantage of extended prompt caching (1 hour) for long-running agent sessions</li>
</ul>
<hr>
</section>
</section>
<section id="how-students-build-with-claude" class="level2">
<h2 class="anchored" data-anchor-id="how-students-build-with-claude">How Students Build with Claude</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/PHuXXeadV_g" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speakers:</strong> Greg (Student Outreach Lead), Isabel (Stanford), Mason (UC Berkeley), Rohil (UC Berkeley), Daniel (USC)</p>
<section id="key-points-and-insights-13" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-13">Key Points and Insights</h3>
<ul>
<li><strong>Nuclear research breakthrough</strong>: Isabel used Claude to build nuclear weapon detection simulations using CERN’s Geant4 software, enabling graduate-level research as an undergraduate</li>
<li><strong>Top-down learning approach</strong>: Mason learned coding through Claude, building CalGBT and codebase visualization tools without traditional CS education</li>
<li><strong>Innovative role reversal</strong>: Rohil created SideQuest, flipping the script to have AI agents hire humans for physical tasks with real-time video verification</li>
<li><strong>Multi-agent systems</strong>: Daniel built Claude Cortex, a multi-agent system that dynamically creates specialized agents for complex decision-making scenarios</li>
<li><strong>Rapid iteration cycles</strong>: Students demonstrate rapid prototyping cycles (1 day to 1 week) and focus on user value over technical perfection</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-13" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-13">Main Takeaways for Developers/Users</h3>
<ul>
<li>No learning curve is too steep with AI assistance - tackle existential problems and complex domains</li>
<li>Focus on iterative workflows with AI rather than trying to build perfect systems upfront</li>
<li>Think of AI as infrastructure and system architecture rather than just feature development</li>
<li>Emphasize practical outcomes and user impact over technical sophistication or completeness</li>
</ul>
<hr>
</section>
</section>
<section id="building-ai-agents-with-claude-in-google-clouds-vertex-ai" class="level2">
<h2 class="anchored" data-anchor-id="building-ai-agents-with-claude-in-google-clouds-vertex-ai">Building AI Agents with Claude in Google Cloud’s Vertex AI</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/TUysIAtxyrQ" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Ivan Nardini, Developer Advocate at Google Cloud</p>
<section id="key-points-and-insights-14" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-14">Key Points and Insights</h3>
<ul>
<li><strong>Four-component agent stack</strong>: Google Cloud’s agent stack includes Agent Development Kit (ADK), MCP integration, Vertex AI Agent Engine, and Agent-to-Agent Protocol</li>
<li><strong>ADK developer-friendly</strong>: Open-source, developer-friendly framework for building, evaluating, and deploying agents at scale</li>
<li><strong>Standardized MCP integration</strong>: Allows standardized communication between agents and tools</li>
<li><strong>Managed platform</strong>: Vertex AI Agent Engine provides managed platform for deploying and scaling agents in production with built-in monitoring and governance</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-14" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-14">Main Takeaways for Developers/Users</h3>
<ul>
<li>Use ADK for rapid agent development with minimal code (just 3 files needed: agent.py, environment variables, and init file)</li>
<li>Leverage MCP servers to avoid reinventing tools - any existing MCP server can be integrated with just 2 lines of code</li>
<li>Deploy agents to production easily using Vertex AI Agent Engine for automatic scaling and operational management</li>
<li>Focus on building agent logic rather than infrastructure concerns</li>
</ul>
<hr>
</section>
</section>
<section id="spotlight-on-manus-building-hands-for-ai-models" class="level2">
<h2 class="anchored" data-anchor-id="spotlight-on-manus-building-hands-for-ai-models">Spotlight on Manus: Building Hands for AI Models</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/UjboGsztHd8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Tao (HighCloud), Co-founder and CPO of Manus AI</p>
<section id="key-points-and-insights-15" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-15">Key Points and Insights</h3>
<ul>
<li><strong>AI hands concept</strong>: Manus provides AI models with “hands” through virtual machines with full access to browsers, terminals, VS Code, and file systems</li>
<li><strong>Less structure, more intelligence</strong>: Philosophy of minimal predefined workflows, maximum model autonomy</li>
<li><strong>High engagement metrics</strong>: Users can achieve 2+ hours of daily GPU consumption, with goal to reach 24-hour influence per user</li>
<li><strong>Inspiration from non-coders</strong>: Inspired by observing non-coders using Cursor to solve daily tasks without caring about the underlying code</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-15" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-15">Main Takeaways for Developers/Users</h3>
<ul>
<li>Agent frameworks should provide computing environments rather than just chat interfaces</li>
<li>Cloud-based execution enables fire-and-forget task assignment without requiring user attention</li>
<li>Teaching agents through personal knowledge systems is more effective than hard-coded workflows</li>
<li>Focus on giving models the right tools and context rather than micromanaging their decision process</li>
</ul>
<hr>
</section>
</section>
<section id="spotlight-on-shopify-structured-workflow-orchestration-with-roast" class="level2">
<h2 class="anchored" data-anchor-id="spotlight-on-shopify-structured-workflow-orchestration-with-roast">Spotlight on Shopify: Structured Workflow Orchestration with Roast</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xlEQ6Y3WNNI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speaker:</strong> Obi Fernandez, Principal Engineer, Shopify’s Augmented Engineering Group</p>
<section id="key-points-and-insights-16" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-16">Key Points and Insights</h3>
<ul>
<li><strong>Complementary approaches</strong>: Two approaches: agentic tools (for exploratory/ambiguous tasks) vs structured workflows (for predictable, repeatable tasks)</li>
<li><strong>Roast framework</strong>: <a href="https://github.com/Shopify/roast">Roast</a>: Open-source Ruby framework for orchestrating deterministic workflows with AI components</li>
<li><strong>Powerful combinations</strong>: Interleaving structured workflows with Claude Code creates powerful combinations for large-scale code transformations</li>
<li><strong>Scale at Shopify</strong>: 500+ daily active users of Claude Code with 250k requests/second at peak</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-16" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-16">Main Takeaways for Developers/Users</h3>
<ul>
<li>Use structured workflows for tasks like legacy migrations, test generation, and systematic refactoring</li>
<li>Combine deterministic steps with non-deterministic AI reasoning for optimal results</li>
<li>Roast provides session saving, function caching, and convention-oriented development</li>
<li>Scale AI applications by minimizing instructions per step and breaking complex tasks into manageable components</li>
</ul>
<hr>
</section>
</section>
<section id="prompting-for-agents" class="level2">
<h2 class="anchored" data-anchor-id="prompting-for-agents">Prompting for Agents</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/XSZP9GhhuAc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speakers:</strong> Hannah and Jeremy from Anthropic’s Applied AI team</p>
<section id="key-points-and-insights-17" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-17">Key Points and Insights</h3>
<ul>
<li><strong>Agent definition</strong>: Agents are “models using tools in a loop” - best for complex, valuable tasks with unclear solution paths</li>
<li><strong>Think like your agents</strong>: Simulate their environment and tool responses to understand their perspective</li>
<li><strong>Provide guidance</strong>: Reasonable heuristics and budgets (e.g., “use under 5 tool calls for simple queries”)</li>
<li><strong>Interleaved thinking</strong>: Guide the thinking process and use interleaved thinking between tool calls for better reasoning</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-17" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-17">Main Takeaways for Developers/Users</h3>
<ul>
<li>Start with simple prompts and iterate based on edge cases and failures</li>
<li>Use structured evals with small sample sizes initially - focus on realistic tasks over arbitrary benchmarks</li>
<li>Tool selection is crucial - provide clear guidance on which tools to use in different contexts</li>
<li>LLM-as-judge with rubrics is effective for evaluating agent outputs</li>
<li>Context window management through compaction, external files, or sub-agents extends agent capabilities</li>
</ul>
<hr>
</section>
</section>
<section id="prompting-101-fundamentals-of-effective-ai-communication" class="level2">
<h2 class="anchored" data-anchor-id="prompting-101-fundamentals-of-effective-ai-communication">Prompting 101: Fundamentals of Effective AI Communication</h2>
<p><strong>Watch:</strong> </p><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/ysPbXH0LpIE" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div><p></p>
<p><strong>Speakers:</strong> Hannah and Christian from Anthropic’s Applied AI team</p>
<section id="key-points-and-insights-18" class="level3">
<h3 class="anchored" data-anchor-id="key-points-and-insights-18">Key Points and Insights</h3>
<ul>
<li><strong>Programming in natural language</strong>: Prompt engineering is “programming in natural language” requiring clear structure and organization</li>
<li><strong>Recommended structure</strong>: Task context → content → detailed instructions → examples → reminders → output formatting</li>
<li><strong>XML tags and delimiters</strong>: Use XML tags and delimiters to help Claude understand and organize information</li>
<li><strong>Order of analysis matters</strong>: Guide Claude through logical step-by-step reasoning processes</li>
</ul>
</section>
<section id="main-takeaways-for-developersusers-18" class="level3">
<h3 class="anchored" data-anchor-id="main-takeaways-for-developersusers-18">Main Takeaways for Developers/Users</h3>
<ul>
<li>Follow iterative, empirical approach - start simple and build based on what fails</li>
<li>Provide background context and data that won’t change (great for prompt caching)</li>
<li>Use examples and few-shot learning for difficult edge cases</li>
<li>Include clear reminders about guidelines and confidence requirements</li>
<li>Structure output with XML tags or pre-filled responses for downstream processing</li>
<li>Extended thinking can serve as a debugging tool to understand Claude’s reasoning process</li>
</ul>


</section>
</section>
</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <category>summary</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-08-14-claude-code-conference-summary/</guid>
  <pubDate>Fri, 15 Aug 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Summary of Armin’s Talk - Agentic Coding Ecosystem 2025: Navigating the Tool Explosion</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-08-14-armin-agentic-coding-ecosystem/</link>
  <description><![CDATA[ 




<section id="agentic-coding-ecosystem-2025-navigating-the-tool-explosion" class="level1">
<h1>Agentic Coding Ecosystem 2025: Navigating the Tool Explosion</h1>
<p>I’ve learned a lot about Claude Code and agentic coding tools from Armin Ronacher. He’s the creator of Flask and Jinja and he’s very interested in Agentic coding tools. This talk was really great. Some things I learned:</p>
<ul>
<li>There is a tight relationship between a foundation model (Claude Sonnet 4) and the agentic coding harness (Claude Code). The foundation models are trained to use tools that the agentic harness is programmed/prompted to use. So you should expect given similar models from different model providers, the model from the same company will perform better. For example, Claude Sonnet 4 + Claude Code will perform better than gpt-5 + Claude Code. This makes me think about open source agentic coding tools like <a href="https://github.com/cline/cline">Cline</a> that may not use tools as correctly as Claude Code.</li>
<li>Just because a model is cheaper per token, doesn’t mean it is cheaper to use overall in an agentic coding tool.</li>
<li>I didn’t know Claude Code had a safety harness that uses Haiku to validate the code.</li>
</ul>
<p>Below is a talk and a summary by Claude Code.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/xfm99Tb7CNo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="key-points-and-insights" class="level2">
<h2 class="anchored" data-anchor-id="key-points-and-insights">Key Points and Insights</h2>
<ul>
<li><p><strong>Explosion of agentic coding tools</strong>: Since May, there has been a massive proliferation of AI-powered coding tools (30+ command line tools), making it difficult to evaluate and compare them effectively</p></li>
<li><p><strong>Tool-model binding is critical</strong>: The best performing agents have foundation models that have been specifically trained on the tools they use (like Anthropic’s Sonnet with bash, text editor, web search commands), creating tight coupling between specific agents and models</p></li>
<li><p><strong>Evaluation challenges</strong>: Current benchmarks like SweeBench are insufficient for real-world assessment; practical evaluation is extremely difficult due to varying token usage, execution speed, safety measures, and user interface differences across tools</p></li>
<li><p><strong>Infrastructure and safety matter</strong>: Quality agents implement pre-flight and post-flight checks (like Claude Code using Haiku for safety validation), better error recovery, and protection against inappropriate commands - not all tools are safe to run autonomously</p></li>
<li><p><strong>Cost complexity</strong>: Cheaper per-token pricing doesn’t necessarily mean lower total costs, as some models require more tokens and turns to achieve the same results, making true cost comparison difficult</p></li>
</ul>
</section>
<section id="main-takeaways-for-developersusers" class="level2">
<h2 class="anchored" data-anchor-id="main-takeaways-for-developersusers">Main Takeaways for Developers/Users</h2>
<ul>
<li><p>Don’t rely solely on social media hype or simple benchmarks when choosing agentic coding tools - practical daily use experience is more valuable than terminal UI aesthetics or marketing claims</p></li>
<li><p>Consider the specific model-tool combinations rather than just the underlying LLM, as tool integration quality significantly impacts performance and safety</p></li>
<li><p>Expect continued consolidation in the market as the current number of tools is unsustainable, but evaluation remains challenging due to multiple variables affecting performance</p></li>
<li><p>Self-hosting open-weight models is currently more expensive than using hosted services, despite the appeal of control and potential cost savings</p></li>
</ul>
</section>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<p>This analysis provides a sobering look at the current state of AI coding assistants, highlighting the challenges developers face when trying to choose between the rapidly multiplying options. The key insight is that effective evaluation requires looking beyond surface-level features to understand the deep integration between models and tools, safety implementations, and real-world performance characteristics that only emerge through extended use.</p>


</section>
</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <category>summary</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-08-14-armin-agentic-coding-ecosystem/</guid>
  <pubDate>Thu, 14 Aug 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Claude Code Camp - hosted by Every</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/</link>
  <description><![CDATA[ 




<p><a href="https://every.to/">Every</a> hosted a Claude Code Camp today for an hour. Different members from their team shared in detail how they use <a href="https://github.com/anthropics/claude-code">Claude Code</a>. I’ve only started using Claude Code in my developer workflow in the past 2-3 weeks so it was super helpful to see how the team was using it.</p>
<section id="some-of-notes-and-takeaways" class="level2">
<h2 class="anchored" data-anchor-id="some-of-notes-and-takeaways">1. Some of notes and takeaways:</h2>
<ul>
<li>Compounding Engineering
<ul>
<li>Each unit of engineering work should make subsequent units of work easier</li>
<li>Loop - These 4 steps below were really helpful!
<ul>
<li>Plan –&gt; plan out a feature or bug fix in detail
<ul>
<li>A lot of prompts to plan. Check if they share it.</li>
</ul></li>
<li>Delegate -&gt; do the work</li>
<li>Assess –&gt; make sure it works as expected
<ul>
<li>Testing</li>
</ul></li>
<li>Codify –&gt; record learnings for the next time
<ul>
<li>CLAUDE.md</li>
</ul></li>
</ul></li>
</ul></li>
<li>Some of Kieran Klaasan’s tips
<ul>
<li>bash aliases to set up
<ul>
<li><code>cc</code> with <code>claude --dangerously-skip-permissions</code></li>
<li><code>wt</code> create a git worktree</li>
<li><code>ccw</code> - run claude code with a git worktree
<ul>
<li><img src="https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/ccw.png" class="img-fluid"></li>
</ul></li>
</ul></li>
<li>He had a ton of slash commands saved in <code>.claude/commands</code>
<ul>
<li>LOT OF PROMPTS HERE!</li>
<li>slash commands</li>
<li>issues.md</li>
<li>/work 309
<ul>
<li>implements Github issue 309</li>
</ul></li>
<li>Pull Request review
<ul>
<li>/review - default in claude code</li>
<li>/best_practice</li>
</ul></li>
</ul></li>
<li>use monologue for voice to text - <a href="https://monologue.to/" class="uri">https://monologue.to/</a></li>
</ul></li>
<li>Plan
<ul>
<li>Make a context file prompt
<ul>
<li><img src="https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/context_file_prompt.png" class="img-fluid"></li>
</ul></li>
<li>Make an Experiment Log
<ul>
<li><img src="https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/experiment_log.png" class="img-fluid"></li>
</ul></li>
</ul></li>
<li>Delegate
<ul>
<li>This step is easy when your plan is good</li>
</ul></li>
<li>Assess
<ul>
<li>Other notes
<ul>
<li>Kieran had Claude Code assess itself to understand how to push it</li>
<li>Consider alternative methods</li>
<li>Make Claude think outside the box</li>
</ul></li>
</ul></li>
<li>Codify
<ul>
<li>Dictating to Monologue</li>
<li>Take learnings from comments and update CLAUDE.md
<ul>
<li><img src="https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/learnings.png" class="img-fluid"></li>
</ul></li>
<li>Subagents of Claude Code?!
<ul>
<li>Can call up to 10 subagents</li>
<li>Use Cases
<ul>
<li>Process Data</li>
<li>Opponent processors - agents with different personas
<ul>
<li>Expense report - 1 from my own perspective, 2 from an auditor’s perspective</li>
</ul></li>
</ul></li>
</ul></li>
</ul></li>
<li>Other tools
<ul>
<li>vibe tunnel - <a href="https://github.com/amantus-ai/vibetunnel" class="uri">https://github.com/amantus-ai/vibetunnel</a></li>
<li>claude-prune
<ul>
<li><a href="https://x.com/DannyAziz97/status/1945958948227461329" class="uri">https://x.com/DannyAziz97/status/1945958948227461329</a></li>
<li><a href="https://github.com/DannyAziz/claude-prune" class="uri">https://github.com/DannyAziz/claude-prune</a></li>
</ul></li>
<li>Claude Conductor: <a href="https://github.com/superbasicstudio/claude-conductor" class="uri">https://github.com/superbasicstudio/claude-conductor</a></li>
</ul></li>
<li>Quotes:
<ul>
<li>Someone asked a question around you guys all have different ways of approaching plans
<ul>
<li>Alex Duffy: “AI is a leverage for your subject matter expertise”</li>
<li>Kieran: Be inspired by what others do</li>
</ul></li>
</ul></li>
</ul>
<p>Below are some learnings extracted by o3 from the transcribed transcript.</p>
<hr>
</section>
<section id="key-learnings-top-510" class="level2">
<h2 class="anchored" data-anchor-id="key-learnings-top-510">2. Key Learnings (Top 5–10)</h2>
<ul>
<li>Claude Code enables shipping features in unfamiliar codebases far faster than traditional onboarding.</li>
<li>Productivity follows a repeatable loop: <strong>Plan → Delegate → Assess → Codify</strong>.</li>
<li>Strong up‑front plans let agents “just build” while poor plans create rework.</li>
<li>GitHub issues and PRs are the contract between Claude and humans for traceability.</li>
<li>Dictation (e.g., Monologue) captures richer prompts; voice often beats typing.</li>
<li>Folder‑level context files shrink token usage and boost model accuracy.</li>
<li>Keep <strong>experiment logs</strong> so goals, findings, and next steps survive context resets.</li>
<li><strong>Subagents</strong> provide parallel processing and multiple viewpoints.</li>
<li>Codify every PR lesson into commands or <code>Claude.md</code> to create compounding returns.</li>
<li>Git worktrees, session‑pruning, and remote terminals keep multi‑feature work safe and light.</li>
</ul>
<hr>
</section>
<section id="actionable-advice" class="level2">
<h2 class="anchored" data-anchor-id="actionable-advice">3. Actionable Advice</h2>
<ul>
<li>Start with one simple planning command; iterate after each run.</li>
<li>Auto‑generate a GitHub issue from the plan; use <code>/work &lt;issue&gt;</code> to delegate.</li>
<li>Use multi‑persona reviews (strict bot + human style) on each PR.</li>
<li>Distill review comments into updated best‑practice commands or <code>Claude.md</code>.</li>
<li>Summarize each folder in an <code>llms.txt</code> or similar for leaner context loading.</li>
<li>Maintain an <strong>experiment_log.md</strong> with goals, errors and revised plans.</li>
<li>Explicitly ask for parallel subagents when processing large corpora.</li>
<li>Adopt TDD in plans; require failing tests before code generation.</li>
<li>Use dictation tools to give fuller context rapidly.</li>
<li>Employ git worktrees (or Conductor UI) for parallel agent branches; prune chat history regularly.</li>
</ul>
<hr>
</section>
<section id="memorable-quotes" class="level2">
<h2 class="anchored" data-anchor-id="memorable-quotes">4. Memorable Quotes</h2>
<blockquote class="blockquote">
<p>“Claude Code has radically altered the way we work—processes, parameters, mental models—everything.” — Dan</p>
</blockquote>
<blockquote class="blockquote">
<p>“I shipped two features this week in codebases I’d never touched; that shouldn’t be possible.” — Dan</p>
</blockquote>
<blockquote class="blockquote">
<p>“Each unit of engineering should make the next one easier—that’s compounding engineering.” — Dan</p>
</blockquote>
<blockquote class="blockquote">
<p>“If your plan is amazing, the feature basically builds itself.” — Dan</p>
</blockquote>
<blockquote class="blockquote">
<p>“CC is my alias that starts Claude Code bypassing permissions—so it just works.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Forty‑five minutes of uninterrupted Claude work is my personal record.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Make your own system; be inspired, but tailor it to your workflow.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Voice prompts give fuller context; I get better results than typing.” — Naveen</p>
</blockquote>
<blockquote class="blockquote">
<p>“AI is leverage for your subject‑matter expertise.” — Alex</p>
</blockquote>
<blockquote class="blockquote">
<p>“Let it run, move on, come back when it’s done—that’s the mindset shift.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Don’t juggle mega‑prompts; lean into agents and their tools.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Experiment logs keep the model honest across context resets.” — Alex</p>
</blockquote>
<blockquote class="blockquote">
<p>“Reviewing with strict TypeScript bot against Ruby creates constructive tension.” — Kieran</p>
</blockquote>
<blockquote class="blockquote">
<p>“Prune old chat instead of trusting weak auto‑summaries.” — Danny</p>
</blockquote>
<hr>
</section>
<section id="important-data-stats-frameworks" class="level2">
<h2 class="anchored" data-anchor-id="important-data-stats-frameworks">5. Important Data / Stats / Frameworks</h2>
<ul>
<li><strong>Compounding Engineering Loop:</strong> Plan → Delegate → Assess → Codify.</li>
<li><strong>Time‑Savings Example:</strong> Two unfamiliar‑codebase features shipped in a week vs.&nbsp;~2‑3 weeks ramp‑up each.</li>
<li><strong>Continuous Work Duration:</strong> 45‑minute single Claude session noted.</li>
<li><strong>Business‑Model Change (Monologue):</strong> Paid‑only to freemium cap (~2 k words) requiring full‑stack update.</li>
<li><strong>Parallelization:</strong> Up to 10 subagents requested for concurrent processing.</li>
<li><strong>Subscription Bundle:</strong> Every subscription includes Cora, Monologue, Spiral, Sparkle at no add’l cost.</li>
<li><strong>Context Principle:</strong> Larger windows can hurt accuracy; mitigate with hierarchical summaries.</li>
<li><strong>Bug‑avoidance Strategy:</strong> Multi‑model reviews, experiment logs, TDD catch shortcut fixes.</li>
<li><strong>Session Management:</strong> Use <code>world prune</code> to keep recent N messages; avoid poor auto‑summaries.</li>
</ul>
<hr>
</section>
<section id="suggested-followup-resources" class="level2">
<h2 class="anchored" data-anchor-id="suggested-followup-resources">6. Suggested Follow‑up Resources</h2>
<ul>
<li><strong>Claude Code</strong> terminal agent (Anthropic)<br>
</li>
<li><strong>Claude.md / folder context files</strong> (<code>/init</code>)<br>
</li>
<li><strong>Custom <code>/issues</code>, <code>/work</code>, <code>/review</code> commands</strong><br>
</li>
<li><strong>Monologue</strong> dictation app<br>
</li>
<li><strong>Cora</strong> email chief‑of‑staff; <strong>Spiral</strong> copywriter; <strong>Sparkle</strong> desktop organizer<br>
</li>
<li><strong>AI Diplomacy</strong> game (Alex)<br>
</li>
<li><strong>Warp Terminal</strong>; <strong>Vibe Tunnel</strong> (remote terminal)<br>
</li>
<li><strong>World Prune</strong> (<code>npx world prune</code>) chat‑trim tool<br>
</li>
<li><strong>Conductor</strong> git‑worktree UI<br>
</li>
<li><strong>Every Newsletter, Discord, Consulting</strong> for ongoing training &amp; content.</li>
</ul>
<hr>
</section>
<section id="onesentence-summary-25-words" class="level2">
<h2 class="anchored" data-anchor-id="onesentence-summary-25-words">7. One‑Sentence Summary (25 words)</h2>
<p>Every’s team demonstrates how Claude Code enables “compounding engineering”—plan, delegate, assess, codify—to ship multi‑codebase features rapidly by capturing and recycling best‑practice knowledge.</p>


</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-07-18-claude-code-camp/</guid>
  <pubDate>Fri, 18 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Starting to Use Claude Code</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-07-18-starting-to-use-claude-code/</link>
  <description><![CDATA[ 




<p>I had tried Claude Code briefly when it first came out <a href="https://www.youtube.com/watch?v=AJpK3YTTKZ4&amp;ab_channel=Anthropic">4 months ago</a>. However I wasn’t that impressed. Lately though, I’ve seen more and more people turn to Claude Code. The step change was the <a href="https://www.anthropic.com/news/claude-4">release of Claude 4 Sonnet and Opus</a> on May 22, 2025. I think something was unlocked where given a powerful enough reasoning model (Claude 4) and access to generic tools, Claude Code is an amazing tool.</p>
<p>Some of the things I read/watched that motivated me to try it again:</p>
<ul>
<li>Watching Claude Code creator’s, Boris Chemy’s talk about the <a href="https://www.youtube.com/watch?v=Lue8K2jqfKk&amp;ab_channel=AIEngineer">evolution of agentic coding</a> <div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Lue8K2jqfKk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></li>
<li>seeing Eric J Ma’s post about it where it created a receipt scanner in <a href="https://ericmjl.github.io/blog/2025/7/1/one-hour-and-eight-minutes-building-a-receipt-scanner-with-the-weirdest-tech-stack-imaginable/">1 hour and 8 minutes</a></li>
<li><a href="https://www.youtube.com/@ArminRonacher">Armin Ronacher’s</a> YouTube Tutorials: <a href="https://www.youtube.com/watch?v=nfOVgz_omlU&amp;ab_channel=ArminRonacher">here</a> and <a href="https://www.youtube.com/watch?v=Y4_YYrIKLac&amp;t=2184s&amp;ab_channel=ArminRonacher">here</a>. The second one I only watched the first 30 minutes. <div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/nfOVgz_omlU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div> <div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Y4_YYrIKLac" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></li>
</ul>
<section id="set-up" class="level2">
<h2 class="anchored" data-anchor-id="set-up">Set Up</h2>
<p>At work, we use VertexAI. Google has signed an agreement with Anthropic to license Claude models that you can then call via VertexAI. The <a href="https://docs.anthropic.com/en/docs/claude-code/google-vertex-ai">instructions</a> are easy to follow. In my <code>~/.zshrc</code>, I just have:</p>
<pre><code>export CLAUDE_CODE_USE_VERTEX=1
export CLOUD_ML_REGION=YOUR_GCP_REGION
export ANTHROPIC_VERTEX_PROJECT_ID=YOUR_GCP_PROJECT_ID
export ANTHROPIC_MODEL='claude-sonnet-4@20250514'</code></pre>
<p>You then authenticate with Google Cloud:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">gcloud</span> auth login</span></code></pre></div></div>
<p>Install Claude Code:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">npm</span> install <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">-g</span> @anthropic-ai/claude-code</span></code></pre></div></div>
<p>Then in your project directory or a new directory, start Claude Code:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb4-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span></span></code></pre></div></div>
<p>I eventually started running:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb5-1"><span class="ex" style="color: null;
background-color: null;
font-style: inherit;">claude</span> <span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">--dangerously-skip-permissions</span></span></code></pre></div></div>
</section>
<section id="first-experiments" class="level2">
<h2 class="anchored" data-anchor-id="first-experiments">First Experiments</h2>
<p>While I was on PTO during the July 4th week, I used Claude Code to build an application I’ve always wanted internally at my company. I had wanted to make a website using <a href="https://github.com/AnswerDotAI/fasthtml">FastHTML</a> since I had heard it was much more flexible than Streamlit/Gradio apps. So I finally got around to it thanks to Claude Code. It also figured out you can combine a FastHTML and a FastAPI service because they are both Starlette applications.</p>
<p>The second thing I built was an MCP Server using <a href="https://github.com/jlowin/fastmcp">FastMCP</a> that implemented <a href="https://gofastmcp.com/servers/auth/bearer">bearer token authentication</a>.</p>
<p>Both of the above tasks I estimate would’ve taken me 2-3 days to do but it take Claude Code &lt;2 hours with ~5 prompts to implement.</p>
</section>
<section id="some-best-practices-ive-arrived-at" class="level2">
<h2 class="anchored" data-anchor-id="some-best-practices-ive-arrived-at">Some best practices I’ve arrived at</h2>
<ul>
<li>Right now I just run Claude Code in a terminal. Sometimes I run it in an IDE (VS Code, Windsurf) where the UI is a little different.</li>
<li><code>claude --dangerously-skip-permissions</code> so Claude doesn’t have to ask for permissions.</li>
<li>Run the slash command <code>/init</code> to create CLAUDE.md</li>
<li>add links to documentation in your prmopts so Claude Code can use it’s fetch tool to learn how to use APIs. Many services/projects have <a href="https://llmstxt.org/">llms.txt</a> that are a good starting point. For example when working with FastHTML, I passed it <a href="https://www.fastht.ml/docs/llms-ctx.txt">this</a>.</li>
<li>ask Claude to make plans and write those plans in a markdown file in <code>docs/</code> with a date, e.g.&nbsp;<code>docs/plan_20250715_implement_feature_a.md</code> with ‘ultrathink’ which increases the thinking budget to the max</li>
<li>Then you can ask Claude Code to implement the plan</li>
<li>Make commits after each successful run of the agent</li>
<li>Though today I attended a Claude Code Camp hosted by Every. <a href="https://lawwu.github.io/posts/2025-07-18-claude-code-camp/">I learned a ton</a> about aliases, slash commands, how you can trigger subagents in Claude Code and how to think about the 4 step loop of development: planning, delegating, assessing and codifying.</li>
</ul>
</section>
<section id="claude-code-utilities" class="level2">
<h2 class="anchored" data-anchor-id="claude-code-utilities">Claude Code Utilities</h2>
<ul>
<li>Monitor your usage and cost: <a href="https://github.com/chiphuyen/sniffly" class="uri">https://github.com/chiphuyen/sniffly</a></li>
<li><a href="https://www.vibekanban.com/">Vibe Kanban</a> - tried it but didn’t really like it</li>
</ul>
</section>
<section id="other-links" class="level2">
<h2 class="anchored" data-anchor-id="other-links">Other Links</h2>
<ul>
<li><a href="https://www.anthropic.com/engineering/claude-code-best-practices" class="uri">https://www.anthropic.com/engineering/claude-code-best-practices</a></li>
<li><a href="https://github.com/hesreallyhim/awesome-claude-code" class="uri">https://github.com/hesreallyhim/awesome-claude-code</a></li>
<li><a href="https://www.pulsemcp.com/posts/how-to-use-claude-code-to-wield-coding-agent-clusters" class="uri">https://www.pulsemcp.com/posts/how-to-use-claude-code-to-wield-coding-agent-clusters</a></li>
<li><div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Lh_X32t9_po" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div></li>
<li>Someone pointed me to this person’s tutorials which look decent but haven’t had a chance to watch: <a href="https://www.youtube.com/@indydevdan" class="uri">https://www.youtube.com/@indydevdan</a></li>
<li>2025-07-18 - Anthropic cuts usage limits on max plans: Anthropic tightens usage limits for Claude Code — without telling users | TechCrunch - <a href="https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/" class="uri">https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/</a></li>
</ul>


</section>

 ]]></description>
  <category>ai</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-07-18-starting-to-use-claude-code/</guid>
  <pubDate>Fri, 18 Jul 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>LangChain Interrupt Conference 2025 - 1 Hour Recap</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-05-30-langchain-interrupt-lwu-recap/</link>
  <description><![CDATA[ 




<p>I tried my best to condense the ~16 hours of content from the LangChain Interrupt Conference to less than an hour.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/YBlFn8R5T9o" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<ul>
<li><a href="https://docs.google.com/presentation/d/1RMGq3dCbmQ-JZPeHYLD9XKTRXk9IKHTFUnHbVXAjqHU/edit">Slides</a></li>
<li><a href="https://www.youtube.com/playlist?list=PLnbEdh6BRkSjXMPmvxkmOz0VM3p4jtQ7d">Conference Talks</a></li>
<li><a href="https://lawwu.github.io/transcripts/index_langchain_interrupt_2025_official.html">Transcripts</a></li>
<li><a href="https://lawwu.github.io/posts/2025-05-23-langchain-interrupt-2025-recap/">AI Summaries of each talk</a>]</li>
</ul>



 ]]></description>
  <category>ai</category>
  <category>events</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-05-30-langchain-interrupt-lwu-recap/</guid>
  <pubDate>Fri, 30 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Levels of AI Use</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-05-27-levels-of-ai-use/</link>
  <description><![CDATA[ 




<p>As I’ve talked to different people at work and amongst friends, there is a growing gap between those that use AI (mostly ChatGPT) and those that do not. It got me thinking there are levels to this for both developers (or anyone who writes code as part of their job) and non-developers (those that do not write code).</p>
<p>Whether you use AI frequently or infrequently, there are some important things to consider.</p>
<ol type="1">
<li>AI used well has the potential to accelerate and augment people’s capabilities. I’ve experienced this the last few years. Co-workers who have learned to prompt language models well have generally become more capable and productive employees. And prompting language models is just one skill needed now in this age of AI.</li>
<li>AI usage can lead to increase mental strain though. As your productivity increases (documents written, code written, applications deployed), there are more things to manage. AI is not quite at the point where it can be a true orchestrator of work in the software/tools that people use. Humans are still required here and it can become cognitively taxing switching between contexts.</li>
<li>If you aren’t using AI now, it is a great time to start.
<ul>
<li>A simple thing you can do is try using ChatGPT for half of your Google searches and see what the results are. (Though with Google testing <a href="https://blog.google/products/search/ai-mode-search/">AI Mode</a>, which is similar to ChatGPT’s chat interface, this may eventually be the default for <a href="https://www.google.com/">www.google.com</a>)</li>
<li>Learn to code - Some people have started saying humans do not need to write code anymore because AI can write better code. But I think it is still important to learn this skill. Writing code will help you understand what AI is doing. For example, some of the models in ChatGPT are reasoning models that also have access to a native code generation and execution tool. So if you ask a query where the model thinks it makes sense to write code to answer your question, it will do that. I recently asked a question about <a href="https://chatgpt.com/share/683697b2-5da4-8011-8d43-445172d7876e">how fast I would have run a half-marathon in a pair of supershoes</a>. The model thought for 1 minute 11 seconds. If you expand the reasoning trace, you’ll see it actually wrote code to do some math.</li>
</ul></li>
<li>Using AI can make you mentally lazy. As humans rely more on technology, this leads to <a href="https://www.ie.edu/center-for-health-and-well-being/blog/ais-cognitive-implications-the-decline-of-our-thinking-skills/">cognitive offloading</a> where “where individuals shift memory and problem-solving tasks to technology.” It happened when people started using calculators. It happened when people first starting using GPS. People’s spatial awareness decreased. AI is a much much more general tool than a calculator or a GPS. AI can now write code better than most (?) developers, it has super-human knowledge of the world, it can generate audio, images and video, the capabilities and possibilities are growing each day. As a daily user of AI tools, I sometimes have to remind myself to not off-loading everything to AI otherwise I’m not exercising certain critical thinking or creative areas of my brain.</li>
<li>AI’s voice mode has gotten quite good. You can use your voice to chat with AI now and it will respond in real-time.</li>
</ol>
<p>Here are the levels:</p>
<hr>
<section id="level-0-no-use" class="level2">
<h2 class="anchored" data-anchor-id="level-0-no-use"><strong>Level 0 – No Use</strong></h2>
<blockquote class="blockquote">
<p>“I don’t use AI at all.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: Write and ship code without AI assistance. May be unaware of AI tools or skeptical about their value. Write most code in an IDE or text editor, relying on traditional resources (documentation, Google, Stack Overflow) for help.</li>
<li><strong>Non-developers</strong>: Haven’t tried ChatGPT yet. Or maybe have used it once. Do not use other AI tools (e.g., ChatGPT, Copilot, Notion AI). AI feels distant, abstract, or risky.</li>
</ul>
<hr>
</section>
<section id="level-1-occasional-use" class="level2">
<h2 class="anchored" data-anchor-id="level-1-occasional-use"><strong>Level 1 – Occasional Use</strong></h2>
<blockquote class="blockquote">
<p>“I use AI once in a while when I’m stuck or curious.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: Use AI code completion like GitHub Copilot or ChatGPT to get unstuck occasionally. Paste errors or ask for code snippets.</li>
<li><strong>Non-developers</strong>: Use AI for one-off tasks like drafting emails, summarizing notes, or brainstorming ideas.</li>
</ul>
<hr>
</section>
<section id="level-2-regular-use" class="level2">
<h2 class="anchored" data-anchor-id="level-2-regular-use"><strong>Level 2 – Regular Use</strong></h2>
<blockquote class="blockquote">
<p>“AI is part of my daily toolkit.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: AI helps with writing boilerplate, generating tests, or exploring APIs. Copilot is turned on. They still edit heavily.</li>
<li><strong>Non-developers</strong>: AI helps draft documents, rewrite content, or explore new ideas. May use AI across 2–3 tools. ChatGPT has replaced most of my Google searches.</li>
</ul>
<p>Example: My wife falls into this camp. ChatGPT has largely replaced her Google searches. She uses ChatGPT daily for idea generation for homeschooling, cooking, defining terms (esp.&nbsp;for kids).</p>
<hr>
</section>
<section id="level-3-workflow-integration" class="level2">
<h2 class="anchored" data-anchor-id="level-3-workflow-integration"><strong>Level 3 – Workflow Integration</strong></h2>
<blockquote class="blockquote">
<p>“AI changes <em>how</em> I work.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: AI tools are deeply integrated into IDEs and workflows. Prompts are crafted with intent. Created RAG systems. Using AI-native IDEs like Cursor or Windsurf.</li>
<li><strong>Non-developers</strong>: Automate repeated tasks (e.g., meeting summaries → action items), combine tools (e.g., ChatGPT + Zapier), and create custom GPTs or workflows.</li>
</ul>
<hr>
</section>
<section id="level-4-ai-native-thinking" class="level2">
<h2 class="anchored" data-anchor-id="level-4-ai-native-thinking"><strong>Level 4 – AI-Native Thinking</strong></h2>
<blockquote class="blockquote">
<p>“AI is a co-worker. I design around it.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: Design software and infrastructure assuming AI is part of the team—building AI agents, integrating LLMs, evaluating agents and other AI applications as well as fine-tuning models. Very familiar with LLM capabilities like structured output, reasoning models and multi-modality. Experimented with various agent frameworks, agent architectures and MCP.</li>
<li><strong>Non-developers</strong>: Reimagine job roles around what AI can do: delegate, refine, and accelerate work with agents, workflows, and bespoke GPTs. Created scripts to automate some of their work or small applications using coding agents in an IDE or Replit.</li>
</ul>
<p>Example: Spotify’s CEO Tobias Lutke has changed how his company hires because of AI. He wrote in a <a href="https://x.com/tobi/status/1909231499448401946">memo</a> that employees have to prove they “cannot get what they watn done using AI” before asking for more headcount and resources.</p>
<hr>
</section>
<section id="level-5-ai-first-innovation" class="level2">
<h2 class="anchored" data-anchor-id="level-5-ai-first-innovation"><strong>Level 5 – AI-First Innovation</strong></h2>
<blockquote class="blockquote">
<p>“AI isn’t just part of the work—it changes <em>what’s possible</em>.”</p>
</blockquote>
<ul>
<li><strong>Developers</strong>: Build entirely new paradigms of software with AI at the center. Move beyond LLM wrappers into agent-based systems, multi-agent systems, AI-native architectures, and emergent behavior. Actively experimenting with not just Foundation LLM APIs but real-time audio APIs (audio in and out).</li>
<li><strong>Non-developers</strong>: Rethink roles, products, and business models from the ground up with AI as the foundation. Co-create with AI to scale impact in ways that were previously unimaginable.</li>
</ul>
<p>What level are you?</p>


</section>

 ]]></description>
  <category>ai</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-05-27-levels-of-ai-use/</guid>
  <pubDate>Tue, 27 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>LangChain Interrupt Conference 2025 AI Recap</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-05-23-langchain-interrupt-2025-recap/</link>
  <description><![CDATA[ 




<p><em>This page contains AI-generated summaries of the LangChain Interrupt 2025 conference talks.</em></p>
<p>The code to do this is in this <a href="https://github.com/lawwu/langchain_conference_ai_summaries">repo</a>. I also did a 1 hour recap of the conference <a href="https://www.youtube.com/watch?v=YBlFn8R5T9o&amp;ab_channel=LawrenceWu">here</a>.</p>
<section id="interrupt-2025-keynote" class="level2">
<h2 class="anchored" data-anchor-id="interrupt-2025-keynote">Interrupt 2025 Keynote</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/DrygcOI-kG8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_DrygcOI-kG8.html" class="uri">https://lawwu.github.io/transcripts/transcript_DrygcOI-kG8.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of Harrison Chase’s keynote at Interrupt 2025, focusing on the key points and main takeaways:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>LangChain’s Origin &amp; Mission:</strong> Born as an open-source project to help developers build AI applications using LLMs, LangChain aims to make intelligent agents ubiquitous by providing the necessary tooling.</li>
<li><strong>The Agent Engineer:</strong> A new profile of builder is emerging, the “agent engineer,” combining skills in prompting, engineering, product sense, and machine learning. LangChain wants to support these agent engineers.</li>
<li><strong>Agents are Here:</strong> Agents are being built and deployed, seeing production use and traction. Companies have been building agents to transform customer support, AI search, co-pilots, and more.</li>
<li><strong>LangChain as Integrations Hub:</strong> LangChain has become a stable ecosystem for interacting with various model providers, giving developers flexibility in model selection.</li>
</ul>
<p><strong>Three Beliefs About the Present of Agents:</strong></p>
<ol type="1">
<li><strong>Agents rely on many different models:</strong> LangChain has become the go-to library for model integrations (70 million monthly downloads), exceeding the OpenAI SDK in Python downloads, indicating developer preference for model optionality.</li>
<li><strong>Reliable agents start with the right context:</strong> LangGraph offers a low-level, unopinionated framework for building agents with supreme control over context engineering, crucial for prompting. Recommending that complex agent orchestration things be built on top of LangGraph.</li>
<li><strong>Building agents is a team sport:</strong> LangSmith is designed as a platform for developers, product people, and ML engineers to collaborate on building agents. It integrates tracing, evals, and prompt engineering to foster teamwork.</li>
</ol>
<p><strong>Three Beliefs About the Future of Agents:</strong></p>
<ol type="1">
<li><strong>AI observability is different than traditional observability:</strong> AI observability is built for the agent engineer persona which needs to bring in ML, product, and prompt engineering concepts. A new series of metrics around agent insights is being launched in Langsmith for run counts of tools, latencies, and errors.</li>
<li><strong>Everyone will be an agent builder:</strong> LangChain aims to empower individuals from various backgrounds to build agents.
<ul>
<li><strong>Langraft Pre-builds:</strong> Common agent architectures (single agents, agent swarms, supervisor agents) will enable developers to easily get started with these common architectures.</li>
<li><strong>Langraft Studio V2:</strong> No more desktop apps! Includes LLM calls in a playground, builds up data sets, and modifies prompts. Pull down production traces from LangSmith into LangGraph Studio so that you can start to modify the agent.</li>
<li><strong>Open Source Open Agent Platform:</strong> A no-code platform powered by LangGraph using agent templates for easy agent creation, including a tool server, RAG as a service, and an agent registry.</li>
</ul></li>
<li><strong>Deployment of agents is the next hurdle:</strong> Langraph platform is now generally available to help developers tackle the deployment challenges.</li>
</ol>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Agent engineering is a multidisciplinary field.</strong></li>
<li><strong>LangChain is evolving to support the entire agent lifecycle</strong>, from initial prototyping to production deployment and monitoring.</li>
<li><strong>Collaboration and accessibility are key</strong> to wider adoption of AI agents.</li>
<li><strong>The future of agents is long-running, bursty, and stateful.</strong></li>
<li><strong>AI Observability is different than traditional observability.</strong></li>
<li><strong>LangChain is releasing Langraph Pre-builds, Langraft Studio V2, and Open Source Open Agent Platform to tackle these challenges.</strong></li>
</ul>
<hr>
</section>
<section id="alice-2-building-and-scaling-an-ai-agent" class="level2">
<h2 class="anchored" data-anchor-id="alice-2-building-and-scaling-an-ai-agent">Alice 2: Building and Scaling an AI Agent</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/fegwPmaAPQk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_fegwPmaAPQk.html" class="uri">https://lawwu.github.io/transcripts/transcript_fegwPmaAPQk.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the transcript with key points and takeaways from the 11x presentation about building and scaling their AI SDR agent, Alice:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Background:</strong> 11x is a company building digital workers, including Alice (AI SDR) and Julian (AI voice agent). The company rebuilt Alice from scratch in a short three-month period.</li>
<li><strong>Motivation for Rebuild:</strong> Alice One was successful but lacked key “digital worker” characteristics: too much manual input, basic lead research, inability to handle replies automatically, and no self-learning. The speaker notes that the release of products such as GPT-4, Cloud, and Replit agent caused them to rethink and rebuild their agent</li>
<li><strong>New Vision for Alice:</strong> The new Alice was centered on seven agentic capabilities: chat-based interaction, knowledge base training, AI-driven lead sourcing (quality-focused), deep lead research, personalized emails, automated handling of inbound messages, and self-learning.</li>
<li><strong>Rapid Development:</strong> The rebuild was accomplished in just three months through a focused approach, utilizing a vanilla tech stack, and leveraging vendor partnerships (including Langchain).</li>
<li><strong>Agent Architecture Challenge:</strong> The core challenge was finding the right architecture for guiding users through campaign creation. They experimented with React, Workflow, and Multi-Agent architectures.
<ul>
<li><strong>React:</strong> Simple but struggled with complex tool usage, leading to infinite loops and mediocre outputs.</li>
<li><strong>Workflow:</strong> Solved tool issues and produced better outputs but was inflexible, tightly coupled to the front-end, and didn’t support jumping around in the flow.</li>
<li><strong>Multi-Agent:</strong> The final solution involved a supervisor agent routing tasks to specialized sub-agents (researcher, positioning report generator, LinkedIn message writer, email writer). This offered both flexibility and performance.</li>
</ul></li>
<li><strong>Tech Stack:</strong> The company used a variety of tools and vendors, most notably Langchain.</li>
</ul>
<p><strong>Main Takeaways &amp; Reflections on Building Agents:</strong></p>
<ul>
<li><strong>Simplicity is Key:</strong> Overly complex structures can be counterproductive long-term.</li>
<li><strong>Model Releases Can Change Everything:</strong> New models can significantly improve agent performance.</li>
<li><strong>Mental Model Matters:</strong> Thinking of the agent as a co-worker or team of co-workers is more effective than thinking of it as a flow or graph.</li>
<li><strong>Break Down Big Tasks:</strong> Divide complex tasks into smaller, manageable components.</li>
<li><strong>Tools Over Skills:</strong> Prioritize providing the agent with the right tools rather than trying to build inherent skills.</li>
<li><strong>Don’t Forget Prompt Engineering:</strong> Iterating on prompts can unlock better agent performance.</li>
<li><strong>Results:</strong> Alice 2 is live and generating significant leads, messages, and replies, with reply rates comparable to human SDRs.</li>
<li><strong>Future Plans:</strong> Integrating Alice and Julian across multiple channels, implementing self-learning, and exploring new technologies like computer vision, memory, and reinforcement learning.</li>
</ul>
<p><strong>Call to Action:</strong> 11x is actively hiring, encouraging those interested in building digital workers to reach out.</p>
<hr>
</section>
<section id="building-reliable-agents-lessons-in-building-an-ide" class="level2">
<h2 class="anchored" data-anchor-id="building-reliable-agents-lessons-in-building-an-ide">Building Reliable Agents: Lessons in Building an IDE</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/H-1QaLPnGsg" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_H-1QaLPnGsg.html" class="uri">https://lawwu.github.io/transcripts/transcript_H-1QaLPnGsg.html</a></p>
<p>AI Summary:</p>
<p>This transcript discusses the challenges of building reliable data processing agents using LLMs, focusing on the difficulties users face when iterating on prompts and pipelines.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Problem:</strong> Building reliable LLM pipelines for data processing (e.g., extracting information from documents) is hard, and people struggle with prompt engineering.</li>
<li><strong>Challenges:</strong>
<ul>
<li><strong>Data Understanding Gap:</strong> Users often don’t know the right questions to ask or understand the nuances and failure modes within their data.</li>
<li><strong>Intent Specification Gap:</strong> Translating identified failure modes into pipeline improvements (prompt engineering, task decomposition, etc.) is complex and difficult.</li>
</ul></li>
<li><strong>Research Focus:</strong> The research aims to close the gap between the user, the data, and the LLM pipeline. There’s a lack of tooling to help users understand their data and specify their intent effectively.</li>
<li><strong>Proposed Solutions:</strong>
<ul>
<li><strong>Data Understanding:</strong> Tools to automatically extract and cluster failure modes, allowing users to annotate and organize them to create datasets for evaluations.</li>
<li><strong>Intent Specification:</strong> An interface that allows users to provide notes on desired improvements, which are then automatically translated into prompt improvements, with interactive feedback and version control.</li>
</ul></li>
<li><strong>Observations:</strong>
<ul>
<li>Evals are fuzzy and constantly evolving, with new failure modes being discovered continuously.</li>
<li>Failure modes often reside in a long tail of diverse cases.</li>
</ul></li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Iterate in Stages:</strong> Break down the iteration process into distinct stages:
<ol type="1">
<li><strong>Understand Your Data:</strong> Focus on understanding the data and identifying failure modes without worrying about accuracy.</li>
<li><strong>Specify Prompts:</strong> Ensure prompts are clear, unambiguous, and well-specified.</li>
<li><strong>Optimize Accuracy:</strong> Apply known accuracy optimization strategies only after the first two stages are addressed.</li>
</ol></li>
<li><strong>Evals are Never Done First:</strong> Evaluation is an ongoing process where new subsets of documents and new failure modes are always being added.</li>
<li><strong>Long Tail of Failure Modes:</strong> There are often tens or twenties of different failure modes that need to be checked for.</li>
</ul>
<p>In essence, the talk highlights the importance of understanding the data and clearly defining the desired outcome before focusing on prompt engineering and optimization. It suggests that tooling and methodologies that support these initial stages can significantly improve the reliability of LLM-powered data processing pipelines.</p>
<hr>
</section>
<section id="building-reliable-agents-evaluation-challenges" class="level2">
<h2 class="anchored" data-anchor-id="building-reliable-agents-evaluation-challenges">Building Reliable Agents: Evaluation Challenges</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/paaOevEFNlo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_paaOevEFNlo.html" class="uri">https://lawwu.github.io/transcripts/transcript_paaOevEFNlo.html</a></p>
<p>AI Summary:</p>
<p>The transcript is a presentation by Tan Bang from Nubank, discussing the challenges and solutions they’ve developed for building reliable AI agents for their 120 million users, particularly in customer service and money transfer applications. Nubank, being a large and rapidly growing bank in Brazil, Mexico, and Colombia, emphasizes the importance of accuracy, trust, and personalization in their AI interactions.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Nubank’s AI Focus:</strong> Building AI private bankers and agents to improve customer financial experiences, focusing on chatbots and money transfer applications.</li>
<li><strong>Scale and Impact:</strong> Processing 8.5 million contacts monthly, with 60% initially handled by LLMs, demonstrating the scale of AI integration.</li>
<li><strong>Use Case: Money Transfer Agent:</strong> Successful implementation of an agentic system for money transfers via voice, image, and chat, reducing transfer time and improving customer satisfaction.</li>
<li><strong>LLM Ecosystem:</strong> Nubank has a four-layer LLM ecosystem: Core Engine, Testing and Evals, Tools, and Developer Experience, working closely with LangChain and LangSmith.</li>
<li><strong>LangGraph:</strong> Faster iterations and standardization of approaches to building agentic systems.</li>
<li><strong>Evaluation Challenges:</strong> Addressing language variations (Portuguese, Spanish dialects), brand reputation (guardrails against jailbreaking), and the critical need for accuracy due to dealing with users’ money.</li>
<li><strong>Customer Service vs.&nbsp;Money Transfer Evaluation:</strong> Tailoring evaluation metrics based on the application, emphasizing empathy and tone in customer service, and accuracy in money transfers.</li>
<li><strong>Offline and Online Evaluation:</strong> Balancing offline evaluations (with human labelers) and online evaluations (continuous improvement loop with tracing, logging, and alerting) for faster development.</li>
<li><strong>LLM as a Judge:</strong> Developing LLM judges to automate labeling and evaluation, achieving performance comparable to human labelers to improve quality at scale.</li>
<li><strong>Iterative Improvement:</strong> Demonstrating significant gains (F1 score) of LLM judge through prompt engineering, fine-tuning, and model selection (GPT-4).</li>
<li><strong>Culture of A/B Testing:</strong> Making data driven decisions and validating performance with rigorous A/B testing.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Evaluation is Crucial:</strong> Rigorous evaluation is essential for building reliable AI agents, especially in sensitive areas like finance.</li>
<li><strong>Nuanced Metrics:</strong> Different applications require tailored evaluation metrics beyond simple accuracy (e.g., empathy in customer service).</li>
<li><strong>Human-in-the-Loop:</strong> Human labelers are important for evaluating LLMs.</li>
<li><strong>Embrace Iteration:</strong> Rapid iteration and experimentation are key to improving AI agent performance, facilitated by tools like Langsmith and LangGraph.</li>
<li><strong>LLMs as Judges:</strong> LLMs can effectively be leveraged as judges for scalable and cheaper evaluations.</li>
<li><strong>Democratization of Data:</strong> Providing centralized logs and repositories with graphical interfaces allows business users to contribute to development.</li>
<li><strong>No Magic Bullet:</strong> Building effective AI agents requires hard work, dedication to evaluation, and a deep understanding of user needs.</li>
</ul>
<hr>
</section>
<section id="multi-agent-frontiers-making-devin" class="level2">
<h2 class="anchored" data-anchor-id="multi-agent-frontiers-making-devin">Multi-Agent Frontiers: Making Devin</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/KfXq9s96tPU" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_KfXq9s96tPU.html" class="uri">https://lawwu.github.io/transcripts/transcript_KfXq9s96tPU.html</a></p>
<p>AI Summary:</p>
<p>This transcript is a presentation about Devin, an AI software engineer developed by Cognition, and how it’s built. Here’s a summary of the key points:</p>
<p><strong>What is Devin?</strong></p>
<ul>
<li>Devin is positioned as an <strong>AI teammate</strong>, not just a copilot, designed to work within existing codebases, focusing on delegating entire tasks.</li>
<li>It is a <strong>cloud-based AI agent</strong>, enabling parallelism, asynchronous work, and team-wide knowledge sharing and learning.</li>
<li>Devin aims to go directly from ticket to pull request, integrating with tools like Slack, Jira, and Linear.</li>
</ul>
<p><strong>Key Technical Aspects &amp; How Devin is Built:</strong></p>
<ol type="1">
<li><strong>Context is King:</strong>
<ul>
<li>Understanding existing codebases is crucial.</li>
<li>Devin needs to emulate desired code styles and avoid poor-quality sections.</li>
<li>Organizational knowledge and proprietary frameworks are critical considerations.</li>
</ul></li>
<li><strong>Deep Wiki:</strong>
<ul>
<li>A real-time, interactive wiki for codebases, providing documentation, diagrams, and a Q&amp;A interface.</li>
<li>Deep Wiki is generated by analyzing the code and surrounding meta data such as comments, documentation and git commit history.</li>
<li>Originally an internal tool for Devin, now publicly available (deepwiki.com) for open-source repos and integrated with Devin for private repos.</li>
</ul></li>
<li><strong>Devin Search:</strong>
<ul>
<li>A code search tool that leverages both micro (individual files) and macro (wiki-derived) context.</li>
<li>Employs preprocessing and retrieval-augmented generation (RAG) but includes more advanced filtering and ranking.</li>
</ul></li>
<li><strong>Customized Post-Training (Kevin/CUDA Kernels):</strong>
<ul>
<li>Demonstrated with “Kevin,” a model fine-tuned for writing CUDA kernels (GPU code).</li>
<li>Employs high-compute reinforcement learning (RL) to optimize performance.</li>
<li>Uses an automated reward function based on code correctness and speed compared to a reference implementation.</li>
<li>Multi-turn training with discounted rewards for trajectories that lead to correct solutions.</li>
</ul></li>
<li><strong>Overcoming Reward Hacking:</strong>
<ul>
<li>Addressed how models can “cheat” to maximize rewards, like using try-except blocks or redefining classes.</li>
<li>Emphasized the importance of carefully defining the environment and reward functions to prevent undesired behaviors.</li>
</ul></li>
</ol>
<p><strong>Key Takeaways:</strong></p>
<ul>
<li><strong>Narrow Domain Specialization:</strong> Deep RL can significantly outperform general foundation models in specialized coding tasks within specific codebases.</li>
<li><strong>Importance of Automated Verification:</strong> Automatic code verification (compilation, testing) is critical for scaling AI-driven development, making it easier to create code that performs as intended.</li>
<li><strong>Future of AI Developers:</strong> The future envisions highly specialized AI agents customized to individual codebases, offering the equivalent of vast experience in a particular environment.</li>
<li><strong>Devin’s Learning Model:</strong> Devin learns from team interactions, incorporating knowledge into the organization, not just for individual users.</li>
</ul>
<p>In essence, the presentation highlights Cognition’s approach to building a truly autonomous AI software engineer by focusing on deep codebase understanding, continuous learning through RL, and integration into existing development workflows.</p>
<hr>
</section>
<section id="from-pilot-to-platform-agentic-developer-products" class="level2">
<h2 class="anchored" data-anchor-id="from-pilot-to-platform-agentic-developer-products">From Pilot to Platform: Agentic Developer Products</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/Bugs0dVcNI8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_Bugs0dVcNI8.html" class="uri">https://lawwu.github.io/transcripts/transcript_Bugs0dVcNI8.html</a></p>
<p>AI Summary:</p>
<p>The presentation “From Pilot to Platform: Agentic Developer Products with LangGraph” by Matas Ristanis and Saurabh Sherhati discusses how Uber is leveraging AI, specifically LangGraph, to build internal developer tools.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Problem:</strong> Uber’s developer platform team supports 5,000 developers working with a massive codebase and aims to improve their workflow and productivity.</li>
<li><strong>Strategy:</strong> Uber’s AI DevTools strategy revolves around:
<ul>
<li><strong>Targeted Products:</strong> Focused on improving developer workflows like test writing and code review.</li>
<li><strong>Cross-Cutting Primitives:</strong> Building foundational AI technologies and abstractions for reusability.</li>
<li><strong>Intentional Tech Transfer:</strong> Identifying reusable components and frameworks (like LangFX, their wrapper around LangGraph/LangChain) from initial product development.</li>
</ul></li>
<li><strong>Validator:</strong> An IDE-integrated LangGraph agent that identifies and flags best practice violations and security issues in code, offering pre-computed fixes or integration with an agentic assistant. It combines LLM-based sub-agents with deterministic static linters.</li>
<li><strong>AutoCover:</strong> A tool to automatically generate high-quality tests (building, passing, coverage-raising, validated and mutation tested) for developers. It utilizes domain expert agents composed in a LangGraph structure, including Validator. By supercharging the graph, it achieves significant performance improvements over other agentic coding tools.</li>
<li><strong>Other Products:</strong> The presentation briefly showcases other tools built using the same principles:
<ul>
<li><strong>Uber Assistant Builder:</strong> An internal “GPT store” for creating custom chatbots with Uber-specific knowledge.</li>
<li><strong>Picasso/Genie:</strong> A conversational AI for Uber’s workflow management platform.</li>
<li><strong>uReview:</strong> A code review tool that flags issues and suggests fixes before code merges.</li>
</ul></li>
<li><strong>Technical Learnings:</strong>
<ul>
<li><strong>Domain Expert Agents:</strong> Building specialized and knowledgeable agents yields better results (context awareness, reduced hallucinations).</li>
<li><strong>Composing Agents:</strong> Combining agents with deterministic sub-agents improves reliability.</li>
<li><strong>Agent Reusability:</strong> Solving bounded problems with agents and reusing them across multiple applications scales development efforts.</li>
</ul></li>
<li><strong>Strategic Learnings:</strong>
<ul>
<li><strong>Encapsulation Boosts Collaboration:</strong> Well-defined abstractions enable horizontal scaling and collaboration between teams with different expertise.</li>
<li><strong>Graphs Model Interactions:</strong> Graphs mirror developer workflows, improving efficiency and identifying bottlenecks.</li>
</ul></li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li>LangGraph can be effectively used to build sophisticated and reusable AI-powered developer tools.</li>
<li>A focus on domain expertise and well-defined abstractions are crucial for building successful AI agents.</li>
<li>Reusing agents across different applications and promoting collaboration between teams can significantly scale AI development efforts within an organization.</li>
<li>Addressing inefficiencies in existing systems can improve both AI-driven and traditional developer workflows.</li>
</ul>
<hr>
</section>
<section id="building-replit-agent-v2" class="level2">
<h2 class="anchored" data-anchor-id="building-replit-agent-v2">Building Replit Agent v2</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/h_oUYqkRybM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_h_oUYqkRybM.html" class="uri">https://lawwu.github.io/transcripts/transcript_h_oUYqkRybM.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the key points and takeaways from the discussion about Replit Agent v2:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Autonomy is the core improvement in v2:</strong> Replit Agent v2 boasts significantly increased autonomy, capable of running for 10-15 minutes (and more in the future) doing useful work without human intervention, unlike v1 which only ran autonomously for a few minutes.</li>
<li><strong>Evaluations and Observability are Crucial:</strong> Early investment in evaluations and robust observability are essential for developing advanced agents. LangSmith is heavily utilized for observability.</li>
<li><strong>Balancing Autonomy and Human-in-the-Loop:</strong> There’s a tension between agent autonomy and the need for human intervention. Replit balances this by providing notifications (via a mobile app) and a chat interface to allow users to stop or modify the agent’s work while it’s running.</li>
<li><strong>User Base and Applications:</strong> Replit has a free tier and is approaching 1 million app creations per month. Users range from those testing agent capabilities to those building business tools and personalized applications. A key differentiator is that users spend hundreds of hours on single projects, building internal tools or personalized apps, often with minimal traditional coding.</li>
<li><strong>Confidence in Autonomy Comes from Testing:</strong> Confidence in increasing autonomy came from extensive internal testing and positive feedback during early access programs.</li>
<li><strong>Model Usage:</strong> Replit heavily uses Sonnet models (especially 3.7) and other models for accessory functions where latency can be traded for performance. They are very opinionated about model selection and do not allow users to switch models. Using multiple models in one run is common.</li>
<li><strong>Cost vs.&nbsp;Latency vs.&nbsp;Performance:</strong> Replit prioritizes performance and cost over latency, focusing on getting the task done correctly, especially for non-technical users.</li>
<li><strong>Decreasing Manual Code Modification:</strong> Replit is actively trying to reduce the number of users who manually modify the code generated by the agent.</li>
<li><strong>Collaboration:</strong> Collaboration with agents is still a challenge due to complexities in merging changes proposed by multiple agents.</li>
<li><strong>Communication Patterns:</strong> Users are notified through the Replit mobile app when the agent needs feedback.</li>
<li><strong>Planning Experience:</strong> Replit is changing the planning experience to accommodate both users who prefer chatbot-like interaction and those who prefer a more structured approach like submitting a PRD (Product Requirements Document).</li>
<li><strong>Debugging Agents is Hard:</strong> Debugging agents is harder than debugging distributed systems, often requiring reading large amounts of input and output to understand decision-making.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li>Replit Agent v2 represents a significant step forward in agent autonomy, enabling users to build more complex applications with less direct intervention.</li>
<li>Investing in robust evaluation and observability tools is critical for developing and maintaining advanced agents.</li>
<li>The Replit team is continuously working on improving the user experience, balancing autonomy with the need for human control and feedback.</li>
<li>The focus is shifting towards enabling non-technical users to build sophisticated applications, particularly internal tools and personalized software.</li>
</ul>
<hr>
</section>
<section id="multi-agent-frontiers-building-ask-d.a.v.i.d." class="level2">
<h2 class="anchored" data-anchor-id="multi-agent-frontiers-building-ask-d.a.v.i.d.">Multi-Agent Frontiers: Building Ask D.A.V.I.D.</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/yMalr0jiOAc" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_yMalr0jiOAc.html" class="uri">https://lawwu.github.io/transcripts/transcript_yMalr0jiOAc.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the transcript, highlighting the key points and main takeaways from the “Building Ask D.A.V.I.D.” presentation:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>The Problem:</strong> The JPMorgan Private Bank’s investment research team manages thousands of investment products with extensive data, leading to numerous client questions. Answering these questions is a manual, time-consuming process that limits scalability and insight delivery.</li>
<li><strong>The Solution: Ask D.A.V.I.D.:</strong> An AI-powered, domain-specific QA agent designed to automate the investment research process, providing curated answers, insights, and analytics quickly. Stands for “Data, Analytics, Visualization, Insights, and Decision-making system.”</li>
<li><strong>Multi-Agent System:</strong> Ask D.A.V.I.D. uses a multi-agent architecture:
<ul>
<li><strong>Supervisor Agent:</strong> Acts as a “router,” understanding user intentions and delegating tasks to sub-agents. Uses short-term and long-term memory and knows when to involve a human.</li>
<li><strong>Structured Data Agent:</strong> Translates natural language into SQL queries or API calls to retrieve and summarize structured data.</li>
<li><strong>Document Search Agent:</strong> Employs Retrieval-Augmented Generation (RAG) to derive information from unstructured data like emails and meeting notes.</li>
<li><strong>Analytics Agent:</strong> Leverages proprietary models and APIs for insights and visualizations, using either direct API calls or text-to-code generation.</li>
</ul></li>
<li><strong>Workflow:</strong> The system uses distinct flows for general questions and questions about specific funds, each with a supervisor agent and specialized sub-agents. Personalization and reflection nodes refine and validate answers.</li>
<li><strong>Example:</strong> A client asks why a fund was terminated. The system identifies the fund, uses the doc search agent to find the reason (performance issues), personalizes the answer based on the user’s role (advisor vs.&nbsp;due diligence specialist), and uses an LLM to ensure the answer makes sense.</li>
<li><strong>Evaluation-Driven Development:</strong> Continuous evaluation is crucial for GenAI projects.
<ul>
<li>Independently evaluate sub-agents.</li>
<li>Pick the right metrics based on agent design (e.g., conciseness for summarization).</li>
<li>Start evaluation early, even without ground truth, and use LLMs as judges with human review.</li>
</ul></li>
</ul>
<p><strong>Main Takeaways (The 3 Key Lessons):</strong></p>
<ol type="1">
<li><strong>Iterate Fast:</strong> Start simple and refactor frequently. Build incrementally, adding complexity as you validate each component.</li>
<li><strong>Evaluate Early:</strong> Implement continuous evaluation to track progress, identify weak points, and build confidence in accuracy.</li>
<li><strong>Keep Humans in the Loop:</strong> Human SME (Subject Matter Expert) involvement is essential, especially for high-stakes financial applications, to ensure accuracy and handle cases where the AI isn’t confident. Aim for human-in-the-loop, not human-out-of-the-loop.</li>
</ol>
<hr>
</section>
<section id="breakthrough-agents-building-reliable-agentic-systems" class="level2">
<h2 class="anchored" data-anchor-id="breakthrough-agents-building-reliable-agentic-systems">Breakthrough Agents: Building Reliable Agentic Systems</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/1PRcceHpJjM" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_1PRcceHpJjM.html" class="uri">https://lawwu.github.io/transcripts/transcript_1PRcceHpJjM.html</a></p>
<p>AI Summary:</p>
<p>This transcript is from a presentation by Eno, co-founder and CTO of Factory, about building reliable agentic systems for software development. Factory believes the future of software development is agent-driven, transitioning from human-driven to AI-delegated tasks.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>The Shift to Agent-Driven Development:</strong> The core idea is moving from AI-assisted coding in traditional IDEs to delegating entire tasks to AI agents for significant productivity gains (5-20x).</li>
<li><strong>Factory’s Platform:</strong> Factory is building a platform to manage and scale these AI agents, integrating various engineering tools (GitHub, Jira, observability tools, knowledge bases, internet).</li>
<li><strong>Defining Agentic Systems:</strong> An agentic system is defined by three characteristics:
<ul>
<li><strong>Planning:</strong> Creating plans with single or multiple steps.</li>
<li><strong>Decision-Making:</strong> Making data-driven decisions, referred to as reasoning.</li>
<li><strong>Environmental Grounding:</strong> Reading and writing information to the environment, reacting, and adapting.</li>
</ul></li>
<li><strong>Human Role:</strong> Humans are still crucial, focusing on the “outer loop” (requirements, architecture), while AI agents handle the “inner loop” (coding, testing, code review). It’s about delegation with control, allowing humans to steer when needed.</li>
<li><strong>Improving Agent Reliability:</strong>
<ul>
<li><strong>Planning:</strong> Decomposition of tasks, model predictive control (continuous updating), and explicit plan templating.</li>
<li><strong>Decision Making:</strong> Provide agents with decision-making criteria and context of their environment.</li>
<li><strong>Environmental Grounding:</strong> Building AI computer interfaces, controlling the tools agents use, and processing information effectively. The way you process information given to the agent is a make or break point, and the entire internet was basically built for humans, so that needs to be addressed.</li>
</ul></li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Focus on Delegation:</strong> Aim to delegate significant portions of engineering tasks to AI agents for substantial productivity improvements.</li>
<li><strong>Invest in Infrastructure:</strong> Building agentic systems requires a dedicated platform with integration capabilities, rather than incremental additions to existing IDEs.</li>
<li><strong>Prioritize Reliability:</strong> Focus on planning, decision-making, and environmental grounding to build reliable agents.</li>
<li><strong>Design for Human-AI Collaboration:</strong> Create systems that allow humans to delegate tasks but also maintain control and provide guidance when needed.</li>
<li><strong>Future is Now:</strong> Consider whether your organization is delegating at least 50% of tasks to AI. If not, it’s time to consider the strategic shift.</li>
</ul>
<hr>
</section>
<section id="from-pilot-to-platform-agents-at-scale-with-langgraph" class="level2">
<h2 class="anchored" data-anchor-id="from-pilot-to-platform-agents-at-scale-with-langgraph">From Pilot to Platform: Agents at Scale with LangGraph</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/NmblVxyBhi8" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_NmblVxyBhi8.html" class="uri">https://lawwu.github.io/transcripts/transcript_NmblVxyBhi8.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the transcript, focusing on key points and takeaways:</p>
<p><strong>Main Focus:</strong></p>
<p>The presentation discusses how LinkedIn scaled its adoption of AI agents, both in terms of processing power and organizational integration, highlighting the journey from initial pilot projects to a platform-level approach.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>LinkedIn Hiring Assistant:</strong> Showcased as LinkedIn’s first production agent, automating recruiter tasks (candidate sourcing). This agent follows the ambient agent pattern, operating in the background and notifying users upon completion.</li>
<li><strong>Python Standardization:</strong> LinkedIn shifted from primarily using Java to Python for GenAI development. This was driven by the need to leverage open-source libraries and keep pace with the rapid advancements in the AI field. Java was initially used, but the limitations in experimenting with Python’s AI ecosystem led to the change.</li>
<li><strong>Service Framework:</strong> LinkedIn built a Python-based framework using gRPC, LangChain, and LangGraph to streamline the development of production-ready GenAI services. Over 20 teams and 30 services are leveraging the framework.</li>
<li><strong>LangChain &amp; LangGraph Adoption:</strong> These libraries were chosen for their ease of use and sensible interfaces, allowing for modeling of internal infrastructure and rapid prototyping. Java engineers were able to easily adopt these tools.</li>
<li><strong>Agent Platform Architecture:</strong> A new distributed architecture was created to support agentic communication, addressing challenges like long-running asynchronous flows and parallel execution. This includes:
<ul>
<li><strong>Messaging System:</strong> Agents communicate via an extended messaging service (agent-to-agent and user-to-agent).</li>
<li><strong>Agentic Memory:</strong> Layered memory system (working, long-term, collective) to provide context and history to agents.</li>
<li><strong>Skills:</strong> Skills are broader than function calling. They are centralized and registered to be exposed to agents. Skills can be other agents. Agents invoke skills synchronously or asynchronously.</li>
</ul></li>
<li><strong>Observability:</strong> Custom observability solutions are crucial for managing and debugging agentic workflows.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Embrace Python for GenAI:</strong> Prioritize Python to fully leverage the open-source AI ecosystem and accelerate innovation.</li>
<li><strong>Invest in Developer Productivity:</strong> Build frameworks and standardize patterns to simplify GenAI development and encourage wider adoption.</li>
<li><strong>Design for Asynchronous Workflows:</strong> Recognize that agents often require long-running processes and design systems that can handle them effectively. Messaging systems become crucial.</li>
<li><strong>Centralize and Share Capabilities:</strong> Skills registries promotes code reuse and team collaboration.</li>
<li><strong>Observability is Essential:</strong> Implement robust monitoring and evaluation tools to understand and improve agent performance in production.</li>
<li><strong>Don’t Neglect Production Considerations:</strong> Even with cutting-edge AI, remember standard software engineering principles (availability, reliability).</li>
</ul>
<hr>
</section>
<section id="breakthrough-agents-learnings-from-building-ai-research-agents" class="level2">
<h2 class="anchored" data-anchor-id="breakthrough-agents-learnings-from-building-ai-research-agents">Breakthrough Agents: Learnings from Building AI Research Agents</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/pKk-LfhujwI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_pKk-LfhujwI.html" class="uri">https://lawwu.github.io/transcripts/transcript_pKk-LfhujwI.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the key points and takeaways from the “Breakthrough Agents: Learnings from Building AI Research Agents” transcript:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Unify’s Core Belief:</strong> Growth should be a science, and the best products win. Go-to-market strategy is essentially a search problem to find the right customers.</li>
<li><strong>AI Research Agents:</strong> LLMs enable automating research traditionally done by sales teams, offering repeatability, observability, and scalability.</li>
<li><strong>Agent Input:</strong> Unify’s agents require two inputs from customers:
<ul>
<li>Specific questions about companies or people with defined output types (text, enum, boolean).</li>
<li>Guidance on how to conduct the research (like instructions to a high schooler).</li>
</ul></li>
<li><strong>Agent Application:</strong> Agents research thousands of companies to answer questions and facilitate targeted sales outreach. Examples include researching company downtime for incident response tool sales.</li>
<li><strong>Token Usage:</strong> Significant token usage (36 billion in April, growing since) indicates large-scale agent usage.</li>
<li><strong>Early Agent Development (V1):</strong>
<ul>
<li>Two initial agent frameworks (Sambot Mark1 and ConorAgent) were built using the ReAct framework (reasoning and acting).</li>
<li>Core tools included internet search, website search, and website scraping.</li>
<li>Sam used GPT-4.0 for faster plan generation, while Connor used 01 Preview (a stronger reasoning model) for more thorough plans.</li>
</ul></li>
<li><strong>Initial Evaluation:</strong>
<ul>
<li>Manual trace analysis revealed 01 Preview generated more thorough and specific plans.</li>
<li>Accuracy-based evaluations were introduced (percentage of correctly answered questions) using hand-labeled datasets.</li>
<li>ConorAgent outperformed Sambot in most categories.</li>
</ul></li>
<li><strong>Areas for Improvement:</strong> Three key areas were identified to improve the agents: changing the graph of the architecture, changing models and prompts, and adding more tools.</li>
<li><strong>Model and Prompt Changes:</strong>
<ul>
<li>Optimizing for cost and performance led to replacing 01 with 4.1 for agentic planning, significantly reducing costs (from ~35 cents to ~10 cents per run) with similar performance.</li>
<li>Date formatting issues highlighted the importance of prompt engineering.</li>
<li>Input schemas for tools were updated to force the tool calling agent to think more about what it was calling.</li>
</ul></li>
<li><strong>Building More Tools:</strong> Four new tools were added: deep internet research, browser access, searching HTML, and dataset access.</li>
<li><strong>Deep Internet Research:</strong> Addresses the limitations of standard internet search by mimicking human research behavior. It involves filtering sources, opening multiple tabs, and iterating search queries. The Pydantic model was updated to include arguments like category, live crawl, and domain constraints. This improves the quality of ingested content and reduces misinterpretations.</li>
<li><strong>Browser Access:</strong> Enables agents to interact with online data sources and datasets that require queries, interactive search (e.g., Google Maps), and content not easily scraped. Implemented as a sub-agent using Computer Vision Preview to decompose tasks into browser trajectories.</li>
<li><strong>Learnings from New Tools:</strong> Deep search significantly reduced misinterpretation of internet search results. Browser access unlocked completely new use cases.</li>
<li><strong>Current Champion Agent:</strong> “Kunal Browser Agent” is now in production.</li>
<li><strong>Next Steps:</strong> Focus on investing more time in evaluations to highlight issues and make the process more repeatable.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Agent Planning Matters:</strong> The quality and thoroughness of the initial plan generated by the agent significantly impacts downstream actions and accuracy. Stronger reasoning models (like 01 Preview, and now 4.1) are crucial for this.</li>
<li><strong>Evaluations are Necessary but Insufficient:</strong> Accuracy-based evaluations are a good starting point but need to be supplemented with manual trace analysis (“vibe checks”) to identify edge cases and subtle issues.</li>
<li><strong>Node-Based Evals</strong>: Models tend to spike in different use cases, so evaluate per node.</li>
<li><strong>Prompt Engineering is Critical:</strong> Seemingly minor details like date formatting can significantly impact model performance. Thoughtful prompt engineering and Pydantic model adjustments are essential.</li>
<li><strong>Mimic Human Research:</strong> Agents should be designed to mimic how humans conduct research, including iterative search, source filtering, and content analysis.</li>
<li><strong>Iterative Improvement:</strong> Building effective AI research agents is an iterative process involving constant experimentation, evaluation, and refinement of models, prompts, and tools.</li>
<li><strong>Tool Selection is Important:</strong> Computer Vision Preview was selected as a tool over other open source alternatives because of its ability to handle more complex browsing tasks.</li>
</ul>
<hr>
</section>
<section id="multi-agent-frontiers-transforming-customer-experience-with-cisco" class="level2">
<h2 class="anchored" data-anchor-id="multi-agent-frontiers-transforming-customer-experience-with-cisco">Multi-Agent Frontiers: Transforming Customer Experience with Cisco</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/gPhyPRtIMn0" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_gPhyPRtIMn0.html" class="uri">https://lawwu.github.io/transcripts/transcript_gPhyPRtIMn0.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the transcript, highlighting key points and takeaways from Cisco’s presentation on transforming customer experience with multi-agent AI:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Cisco’s Focus:</strong> Maximizing customer value on their investments through land, adopt, expand, and renew framework, emphasizing process, people, and technology.</li>
<li><strong>Vision:</strong> Elevate Customer Experience (CX) to Agentic CX, providing personalized, predictive, and proactive experiences using multi-agent AI.</li>
<li><strong>Multi-Agent Approach:</strong> Combines human and machine agents, GenAI, and traditional ML for a comprehensive service across various user interfaces (video, chat, phone, tools).</li>
<li><strong>Use Case Driven:</strong> Prioritizes use cases that deliver immediate customer value, improve operational security and reliability, and provide lifecycle visibility. A defined criteria is important to make sure that the use cases are not just based on “cool” technology but delivers tangible business value.</li>
<li><strong>Flexible Deployment:</strong> Supports on-premises, cloud, and hybrid deployment models.</li>
<li><strong>Technology Stack:</strong> Utilizes Mistral-Large, Sonnet, and shartgpt, powered by Langchain, with custom AI models (ML for predictions, fine-tuned LLMs for accuracy).</li>
<li><strong>Real-world Applications:</strong> Renews agent with predictive insights, virtual tech engineers for support automation (resolving 60% of cases fully automated). Also, sentiment analysis across the lifecycle.</li>
</ul>
<p><strong>Key Takeaways and Learnings:</strong></p>
<ul>
<li><strong>Define Use Cases and Metrics First:</strong> Don’t jump on the latest AI trend without a clear purpose and measurable goals. Define use cases that fit the business needs and can be measured for success.</li>
<li><strong>Experimentation and Production Teams:</strong> Separate teams for experimentation/prototyping and production, allowing the former to fail fast and the latter to focus on stability and performance. Have a dedicated team for evaluation with golden data sets to ensure unbiased assessment.</li>
<li><strong>Accuracy Challenges:</strong> Achieving high accuracy for enterprise use cases, especially those involving SQL databases, is difficult. Normalizing data and avoiding LLMs for complex SQL joins is crucial.</li>
<li><strong>Collaboration is Key:</strong> Inter-agent communication and collaboration is critical, going beyond existing protocols like MCP. Proposes “Agency,” an open-source architecture for agentic AI that includes a semantic layer, authentication, and agent directory.</li>
<li><strong>Workflow-centric approach:</strong> LLMs are great with language but not with workflows. Tools like LangGraph platform are better to follow deterministic workflows.</li>
<li><strong>Context is important</strong>: Going beyond MCP context to provide better hyper-personalization.</li>
<li><strong>AI-Augmented CX, Not Replacing Human Touch:</strong> Optimizing for people and maximizing returns to the business by adopting AI.</li>
</ul>
<p><strong>In essence, Cisco is leveraging multi-agent AI, facilitated by Langchain, to create a more personalized, efficient, and proactive customer experience. They emphasize a strategic, use-case-driven approach, focusing on real-world applications and acknowledging the challenges and complexities of integrating AI into existing enterprise systems.</strong></p>
<hr>
</section>
<section id="building-reliable-agents-raising-the-bar" class="level2">
<h2 class="anchored" data-anchor-id="building-reliable-agents-raising-the-bar">Building Reliable Agents: Raising the Bar</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/kuXtW03cZEA" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_kuXtW03cZEA.html" class="uri">https://lawwu.github.io/transcripts/transcript_kuXtW03cZEA.html</a></p>
<p>AI Summary:</p>
<p>This transcript is a presentation about how Harvey, an AI company specializing in legal and professional services, builds and evaluates its AI products. Here’s a summary of the key points:</p>
<ul>
<li><strong>Harvey Overview:</strong> Harvey offers AI-powered tools for legal tasks, including document summarization, drafting, large-scale document analysis, and custom workflows. Their vision is to enable users to do all their work in Harvey, accessible wherever they work.</li>
<li><strong>Quality Challenges in Legal AI:</strong>
<ul>
<li>Lawyers work with complex, lengthy documents with many references.</li>
<li>Outputs must be accurate and nuanced, as mistakes have significant consequences.</li>
<li>Quality is subjective; even factually correct answers can vary in preference due to nuance and detail.</li>
<li>Sensitive customer data makes obtaining datasets and feedback difficult.</li>
</ul></li>
<li><strong>Product Development Principles:</strong>
<ul>
<li><strong>Applied AI:</strong> Combine state-of-the-art AI with best-in-class UI to solve real-world problems.</li>
<li><strong>Lawyer in the Loop:</strong> Involve lawyers throughout the product development process (use case identification, data collection, evaluation, UI design, testing, and go-to-market).</li>
<li><strong>Prototype over PRD:</strong> Prioritize rapid prototyping and iteration over extensive documentation.</li>
</ul></li>
<li><strong>Evaluation Methods:</strong>
<ul>
<li><strong>Human Preference Judgments:</strong> Collect human feedback on model outputs, considered the highest quality signal. Use side-by-side comparisons and ratings.</li>
<li><strong>Model-Based Auto Evaluations (LLM as Judge):</strong> Create automated evaluations using LLMs, breaking down complex tasks into categories with rubrics crafted by legal experts.</li>
<li><strong>Breaking Down Complex Problems:</strong> For workflows and agents, break down the process into steps to evaluate each component separately (e.g., query rewriting, document retrieval, answer generation in RAG).</li>
</ul></li>
<li><strong>Example Launch (GPT 4.1):</strong> Demonstrates the evaluation process, including initial testing with the company’s “Big Law Bench” benchmark, followed by human evaluation, additional product-specific testing, and internal feedback.</li>
<li><strong>Learnings:</strong>
<ul>
<li><strong>Sharpen Your Axe:</strong> Invest in strong tooling, processes, and documentation to improve evaluation efficiency.</li>
<li><strong>Evals Matter, But Taste Matters Too:</strong> Balance rigorous evaluations with human judgment, qualitative feedback, and user experience.</li>
<li><strong>The Most Important Data Doesn’t Exist Yet:</strong> The next breakthrough in agentic systems will come from capturing “process data” - the undocumented knowledge of how complex tasks are performed within legal firms. This means focusing on how things actually get done.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="unlocking-agent-creation-agentic-architecture-lessons" class="level2">
<h2 class="anchored" data-anchor-id="unlocking-agent-creation-agentic-architecture-lessons">Unlocking Agent Creation: Agentic Architecture Lessons</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/uNBIaANTJJw" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_uNBIaANTJJw.html" class="uri">https://lawwu.github.io/transcripts/transcript_uNBIaANTJJw.html</a></p>
<p>AI Summary:</p>
<p>This transcript is a presentation by Ben Kuss from Box about their experience in building agentic architectures for data extraction. Here’s a summary of the key points and main takeaways:</p>
<ul>
<li><p><strong>Context:</strong> Box, an unstructured data platform, initially implemented AI for content tasks like Q&amp;A, search, and data extraction. They focused on data extraction as a use case to highlight their journey towards agentic architectures.</p></li>
<li><p><strong>Problem:</strong> Initial “basic AI” approach for data extraction (document -&gt; fields -&gt; preprocessing/OCR -&gt; LLM -&gt; extracted data) worked initially but hit limitations when customers provided complex or varied documents:</p>
<ul>
<li>Large documents exceeding context windows.</li>
<li>Poor OCR quality (cross-outs, languages).</li>
<li>Requests for a high volume of data fields per document.</li>
<li>Lack of confidence scores from generative AI.</li>
<li>Difficult to scale and adapt to new document types.</li>
</ul></li>
<li><p><strong>Solution: Adopted a Multi-Agent Architecture:</strong></p>
<ul>
<li>Re-architected from scratch using an agentic approach, separating the problem into a series of sub-agents.</li>
<li>Created specialized agents with specific routines.</li>
<li>Each sub-agent solves specific problems (preprocessing, OCR, field grouping, data extraction, quality feedback).</li>
<li>Quality feedback loop allows the AI to try different techniques for accuracy.</li>
<li>Dynamic selection of tools and methods (e.g., using different models, page images in addition to OCR).</li>
</ul></li>
<li><p><strong>Benefits of Agentic Architecture:</strong></p>
<ul>
<li>Solved initial problems and improved accuracy.</li>
<li>Easy to update and evolve the system for new document types.</li>
<li>Clean abstraction for engineers, simplifying development and maintenance.</li>
<li>Facilitated specialized agents for different document types.</li>
<li>Enabled quicker response to customer issues.</li>
</ul></li>
<li><p><strong>Unexpected Benefits:</strong></p>
<ul>
<li>Engineers started thinking more about customer needs.</li>
<li>Improved understanding of how customers use Box as a tool in their own agentic systems.</li>
<li>Contributed to building an AI-first engineering organization.</li>
</ul></li>
<li><p><strong>Key Takeaway/Advice:</strong> Build agentic systems early when implementing intelligent features. This approach provides a better abstraction, is easier to evolve, and encourages a customer-centric engineering mindset.</p></li>
</ul>
<hr>
</section>
<section id="how-monday.com-built-their-digital-workforce" class="level2">
<h2 class="anchored" data-anchor-id="how-monday.com-built-their-digital-workforce">How Monday.com Built Their Digital Workforce</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/P8ewpJrZVwo" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_P8ewpJrZVwo.html" class="uri">https://lawwu.github.io/transcripts/transcript_P8ewpJrZVwo.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of Asaf’s presentation on how Monday.com is building their digital workforce with LangGraph, highlighting key points and takeaways:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Monday.com’s Scale &amp; Opportunity:</strong> Processes 1 billion tasks per year, representing a massive opportunity for AI-powered agents. They’ve seen rapid growth (100% MoM) in AI feature usage.</li>
<li><strong>Digital Workforce Vision:</strong> Agents working within the Monday.com ecosystem to handle various tasks for SMBs and enterprises.</li>
<li><strong>Trust &amp; User Experience are Paramount:</strong> The biggest barrier to AI adoption isn’t technology, but user trust. Focus on UX is crucial.</li>
<li><strong>Autonomy &amp; Control:</strong> Users want control over agents’ actions. Giving users control increases adoption.</li>
<li><strong>Seamless Integration:</strong> Integrate AI agents into existing workflows and UIs instead of creating entirely new experiences. Assign agents to tasks like assigning people.</li>
<li><strong>Preview &amp; Validation:</strong> Implement previews (UI in the Loop) so users can review agent outputs before they are pushed to production, ensuring confidence and preventing unexpected changes, which increased adoption.</li>
<li><strong>Explainability is Crucial:</strong> Explainability helps users understand <em>why</em> the AI made certain decisions, enabling them to improve their experience with AI over time by adjusting inputs.</li>
<li><strong>LangGraph as the Foundation:</strong> Monday.com built its agent ecosystem on LangGraph and LangSmith, citing its flexibility, built-in features (interrupts, checkpoints, memory), and scalability (millions of requests per month).</li>
<li><strong>Architecture:</strong> LangGraph at the center, surrounded by internal AI blocks, an evaluation framework, and an AI gateway for input/output control.</li>
<li><strong>Monday Expert Example:</strong> Conversational agent with a supervisor managing data retrieval, board actions, and answer composition agents. It has an “undo” feature.</li>
<li><strong>Lessons Learned (Conversational Agents):</strong>
<ul>
<li>Assume you can’t handle 99% of interactions. Implement fallbacks.</li>
<li>Evaluations are your IP as models change rapidly</li>
<li>Human-in-the-loop is critical to achieve product quality.</li>
<li>Build guardrails <em>outside</em> the LLM.</li>
<li>Balance the number of agents in multi-agent systems to avoid compound hallucination.</li>
</ul></li>
<li><strong>Future of Work: Orchestration:</strong> Aim for a finite set of specialized agents that can be dynamically orchestrated to handle infinite tasks, mimicking human work patterns.</li>
<li><strong>Marketplace:</strong> Opening up their agent marketplace.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li>Building a successful AI-powered digital workforce requires a strong focus on user trust, seamless integration into existing workflows, and providing users with control and explainability.</li>
<li>LangGraph provides a solid foundation for building and scaling agent ecosystems, offering the necessary flexibility and built-in features.</li>
<li>Continuous evaluation, human-in-the-loop feedback, and external guardrails are crucial for improving agent performance and ensuring safety.</li>
<li>The future of work involves dynamically orchestrating specialized agents to handle a wide range of tasks, mirroring how humans collaborate.</li>
</ul>
<hr>
</section>
<section id="from-llms-to-agents-the-next-leap" class="level2">
<h2 class="anchored" data-anchor-id="from-llms-to-agents-the-next-leap">From LLMs to Agents: The Next Leap</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/_XWJdCZM8Ag" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript__XWJdCZM8Ag.html" class="uri">https://lawwu.github.io/transcripts/transcript__XWJdCZM8Ag.html</a></p>
<p>AI Summary:</p>
<p>This is a summary of a fireside chat with Adam D’Angelo, co-founder and CEO of Quora, focusing on Poe and the future of AI.</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Poe’s Inspiration and Vision:</strong> D’Angelo and Quora recognized early on that interacting with large language models would be best through a chat-like interface. Poe aims to be a universal interface for diverse AI models and agents, similar to how web browsers enabled the internet’s growth.</li>
<li><strong>Consumer Use Cases:</strong> Consumers use AI on Poe for various tasks, including writing assistance, question answering, role-playing, homework help, job assistance, media creation, and marketing. Poe’s central value is providing access to many AI products under a single subscription.</li>
<li><strong>Popular Models:</strong> Reasoning models have seen significant growth in usage. These include models that are especially strong in writing code.</li>
<li><strong>Modalities:</strong> Text models dominate usage, but there is excitement around new image models, though they are not yet as practical or economically valuable as text models.</li>
<li><strong>Model Preference:</strong> Poe users often care about the specific model they use, especially when aiming for the best results in tasks like creative writing. They may test different models to find the best one for their needs.</li>
<li><strong>Bot Creation on Poe:</strong> Users can create bots via prompting (prompt bots) or through server bots.</li>
<li><strong>Agent Builders:</strong> Prompt bots are created by people who are empathetic with the model and persistent in trying different cases. Server bots are created by more sophisticated developers and AI model developers.</li>
<li><strong>Monetization:</strong> Bot creators can monetize their bots on Poe, with some earning significant revenue (millions of dollars per year for companies, hundreds of thousands for individuals).</li>
<li><strong>Agents:</strong> Most agents on Poe are currently read-only, focusing on generating artifacts rather than taking real-world actions. Poe aims to enable agents with real-world actions in the future.</li>
<li><strong>Most Promising Areas for Developers:</strong> Building agents is the most promising area, specifically building things more sophisticated than a simple prompt, but not as sophisticated as training a new model or fine-tuning.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li>Poe is positioning itself as a key platform in the AI ecosystem, connecting users with diverse models and enabling creators to build and monetize AI applications.</li>
<li>The field is rapidly evolving, with new models and capabilities emerging frequently, requiring constant adaptation.</li>
<li>The future of AI will involve increasingly powerful models, particularly in areas like code generation, which will lead to an explosion of software development.</li>
<li>D’Angelo is particularly excited about the future of code generation applications, and how tools within Poe like App Creator will improve as the code generation abilities of models continue to grow.</li>
</ul>
<hr>
</section>
<section id="state-of-agents-with-andrew-ng" class="level2">
<h2 class="anchored" data-anchor-id="state-of-agents-with-andrew-ng">State of Agents with Andrew Ng</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/4pYzYmSdSH4" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_4pYzYmSdSH4.html" class="uri">https://lawwu.github.io/transcripts/transcript_4pYzYmSdSH4.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the key points and main takeaways from Andrew Ng’s fireside chat:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Agentic-ness Spectrum:</strong> Focus on the degree of “agentic-ness” (autonomy) in a system rather than arguing whether it is “truly” an agent. This helps avoid unproductive debates and encourages building systems with varying levels of autonomy.</li>
<li><strong>Business Opportunities in Simpler Workflows:</strong> Many business opportunities exist in automating fairly linear workflows with occasional branches (e.g., data entry, compliance checks). The challenge lies in breaking down processes into micro-tasks and knowing which steps to improve.</li>
<li><strong>Essential Skills for Agent Builders:</strong>
<ul>
<li>Integrate data effectively and use tools like LandGraph.</li>
<li>Prompting and processing data through multiple steps.</li>
<li>Implement a robust evaluation (evals) framework to assess system performance and pinpoint areas for improvement (individual steps).</li>
</ul></li>
<li><strong>The “Lego Brick” Analogy:</strong> AI tools are like Lego bricks; the more diverse the tools (evals, RAG, guardrails, memory techniques), the more complex and effective systems you can build. Lack of familiarity with specific tools can significantly slow down development.</li>
<li><strong>Evals are Underrated:</strong> People often delay implementing systematic evals. Start with simple evals to address specific regressions and incrementally improve them.</li>
<li><strong>Voice Stack Potential:</strong> Voice applications are underrated, with significant enterprise interest. Voice interactions can reduce user friction compared to text prompts. Key considerations for voice include latency and user experience tweaks (e.g., pre-responses, background noise).</li>
<li><strong>AI-Assisted Coding:</strong> Companies should embrace AI-assisted coding to significantly boost developer productivity. Everyone should learn to code to better instruct computers and understand error cases.</li>
<li><strong>Importance of MCP:</strong> MCP is a fantastic way to try to standardize the interface to a lot of tools or API calls as well as data sources and can significantly streamline data integration for AI systems and should significantly reduce the amount of time spent working on plumbing. It allows one to avoid having to do N times M integrations with N models and M data sources.</li>
<li><strong>Agent to Agent is very early:</strong> It is difficult to get code to work and the idea of having to make code work with someone elses agent feels like a two miracle requirement.</li>
<li><strong>Vibe Coding:</strong> Vibe coding is essentially using AI-assisted coding to code and while it is an effective and real phenomenon, the name is misleading.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li><strong>Practicality over Perfection:</strong> Don’t get caught up in theoretical debates. Focus on building practical systems with the appropriate level of agentic-ness for the task.</li>
<li><strong>Master the Fundamentals:</strong> Data integration, prompting, processing, and systematic evals are crucial for building successful agentic systems.</li>
<li><strong>Embrace the Toolset:</strong> Familiarize yourself with a wide range of AI tools and be ready to adapt as the landscape evolves.</li>
<li><strong>Voice is Coming:</strong> Pay attention to voice applications; they offer unique interaction advantages.</li>
<li><strong>AI-Assisted Coding is a Must:</strong> Encourage and enable the use of AI coding assistants to boost developer productivity.</li>
</ul>
<hr>
</section>
<section id="building-reliable-agents-agent-evaluations" class="level2">
<h2 class="anchored" data-anchor-id="building-reliable-agents-agent-evaluations">Building Reliable Agents: Agent Evaluations</h2>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/DsjkO2vB618" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<p>Transcript: <a href="https://lawwu.github.io/transcripts/transcript_DsjkO2vB618.html" class="uri">https://lawwu.github.io/transcripts/transcript_DsjkO2vB618.html</a></p>
<p>AI Summary:</p>
<p>Here’s a summary of the transcript, highlighting key points and main takeaways from the presentation on Agent Evaluations:</p>
<p><strong>Key Points:</strong></p>
<ul>
<li><strong>Quality is the Biggest Blocker:</strong> A survey revealed that the biggest hurdle in deploying agents to production is ensuring quality.</li>
<li><strong>Eval-Driven Development:</strong> Using evaluations (evals) throughout the development process is crucial for bridging the gap between prototype and production.</li>
<li><strong>Evals as a Continuous Journey:</strong> Emphasized that evals should be a continuous process throughout the entire lifecycle of an agent, not a one-time activity.</li>
</ul>
<p><strong>Three Types of Evals:</strong></p>
<ol type="1">
<li><strong>Offline Evals:</strong>
<ul>
<li>Performed before production.</li>
<li>Uses a static data set to measure performance.</li>
<li>Allows comparison of different models/prompts.</li>
</ul></li>
<li><strong>Online Evals:</strong>
<ul>
<li>Conducted on a subset of production data in real-time.</li>
<li>Tracks performance with real user queries.</li>
</ul></li>
<li><strong>In-the-Loop Evals:</strong>
<ul>
<li>Occur during the agent’s runtime.</li>
<li>Aims to correct the agent’s behavior on the fly, blocking bad responses.</li>
<li>Most beneficial when tolerance for mistakes is low or latency isn’t critical.</li>
</ul></li>
</ol>
<p><strong>Components of Evals:</strong></p>
<ul>
<li><strong>Data:</strong> The information used for evaluation (data sets, production data, etc.).</li>
<li><strong>Evaluators:</strong> The methods used to score performance (code, LLMs, human annotation).
<ul>
<li><strong>Ground Truth/Reference Evals:</strong> Compare against a known correct answer.</li>
<li><strong>Reference-Free Evals:</strong> Used when a ground truth is unavailable.</li>
</ul></li>
</ul>
<p><strong>How Langtrain Helps:</strong></p>
<ul>
<li><strong>Observability:</strong> Great evals start with great observability.</li>
<li><strong>Tracing in Langsmith:</strong> Tracks inputs, outputs, and steps, facilitating online evals.</li>
<li><strong>Easy Dataset Creation:</strong> Langsmith provides tools to easily add data to sets for offline evals.</li>
<li><strong>Open Source Evaluators:</strong> Providing a set of open-source evaluators for common use cases (code, RAG, extraction, tool calling).</li>
<li><strong>Customizable Evals:</strong> Allowing configuration for specific use cases, including LLM-as-a-judge and agent trajectory evaluations.</li>
<li><strong>Chat Simulations:</strong> Launching utilities to run and score evaluators in conversational settings.</li>
<li><strong>Align Eval and Eval Calibration (Private Preview):</strong> New features to help with LLM-as-a-judge techniques, addressing the challenges of prompt engineering and trust.</li>
</ul>
<p><strong>Main Takeaways:</strong></p>
<ul>
<li>Evals are an ongoing process that should be integrated throughout the agent’s lifecycle.</li>
<li>Data and evaluators are the two fundamental components of any evaluation type.</li>
<li>Langtrain provides tools and resources to simplify data set creation, run evals, and build custom evaluators.</li>
<li>LLM-as-a-judge evaluators are powerful but require careful setup and calibration.</li>
</ul>


</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-05-23-langchain-interrupt-2025-recap/</guid>
  <pubDate>Fri, 23 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Andrew Ng &amp; Harrison Chase Fireside Chat</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-05-13-andrew-ng-harrison-chase-fireside-chat/</link>
  <description><![CDATA[ 




<p>The questions and answers extracted from the fireside chat between Harrison Chase (LangChain) and Andrew Ng (AI Fund) at LangChain Interrupt 2025.</p>
<hr>
<section id="q1-what-is-agenticness-and-has-your-thinking-changed" class="level2">
<h2 class="anchored" data-anchor-id="q1-what-is-agenticness-and-has-your-thinking-changed">Q1: What is “agenticness,” and has your thinking changed?</h2>
<p><strong>Andrew Ng:</strong><br>
The debate over whether something “is an agent” is less productive than discussing <em>degrees of autonomy</em>. It’s more useful to see systems on a spectrum—from simple automation to full autonomy—rather than binary classification. Many business workflows are linear and agentic to a low degree but still valuable.</p>
<hr>
</section>
<section id="q2-what-skills-are-most-important-for-building-agent-systems" class="level2">
<h2 class="anchored" data-anchor-id="q2-what-skills-are-most-important-for-building-agent-systems">Q2: What skills are most important for building agent systems?</h2>
<p><strong>Andrew Ng:</strong><br>
- Break down complex tasks into modular steps<br>
- Define the right KPIs (including evals)<br>
- Interpret traces, debug step-by-step<br>
- Develop “tactile knowledge” by building, testing, and iterating<br>
- Use many tools to strengthen decision-making intuition</p>
<hr>
</section>
<section id="q3-is-that-tactile-knowledge-mostly-about-llms" class="level2">
<h2 class="anchored" data-anchor-id="q3-is-that-tactile-knowledge-mostly-about-llms">Q3: Is that tactile knowledge mostly about LLMs?</h2>
<p><strong>Andrew Ng:</strong><br>
It extends beyond LLMs. Think of tools like Lego bricks—the more diverse your pieces, the more flexible your build. You need squiggly, odd-shaped blocks sometimes, not just standard ones. Practicing with a wide toolset helps build strong product instincts.</p>
<hr>
</section>
<section id="q4-what-lego-bricks-are-underrated" class="level2">
<h2 class="anchored" data-anchor-id="q4-what-lego-bricks-are-underrated">Q4: What “Lego bricks” are underrated?</h2>
<p><strong>Andrew Ng:</strong><br>
<strong>Evals.</strong><br>
People think they need to be comprehensive and perfect. Start with something fast and imperfect—5 examples and a simple check. Use it to catch regressions. You’ll naturally improve it over time.</p>
<hr>
</section>
<section id="q5-any-underrated-application-areas" class="level2">
<h2 class="anchored" data-anchor-id="q5-any-underrated-application-areas">Q5: Any underrated application areas?</h2>
<p><strong>Andrew Ng:</strong><br>
<strong>Voice stack applications.</strong><br>
They’re low-friction for users but underexplored. Latency expectations make them hard (users expect 1–2s responses), but agents + voice stack pipelines are more controllable than end-to-end speech models.</p>
<hr>
</section>
<section id="q6-is-building-voice-agents-similar-to-text-based-ones" class="level2">
<h2 class="anchored" data-anchor-id="q6-is-building-voice-agents-similar-to-text-based-ones">Q6: Is building voice agents similar to text-based ones?</h2>
<p><strong>Andrew Ng:</strong><br>
Skills are transferable, but differences matter: - Voice has tighter latency constraints - Pre-response fillers (“Hmm…”) help mask lag - Background noise helps users tolerate delays - Voice interactions are more forgiving and expressive than typed ones</p>
<hr>
</section>
<section id="q7-thoughts-on-mcp-model-component-protocol" class="level2">
<h2 class="anchored" data-anchor-id="q7-thoughts-on-mcp-model-component-protocol">Q7: Thoughts on MCP (Model Component Protocol)?</h2>
<p><strong>Andrew Ng:</strong><br>
MCP is a promising step toward standardized tool calling and integration.<br>
Today’s structure is flat, but future versions need hierarchy and composition.<br>
MCP could help unify models, tools, and data across ecosystems.</p>
<hr>
</section>
<section id="q8-what-about-agent-to-agent-protocols" class="level2">
<h2 class="anchored" data-anchor-id="q8-what-about-agent-to-agent-protocols">Q8: What about agent-to-agent protocols?</h2>
<p><strong>Andrew Ng:</strong><br>
Still early. Multi-agent systems work within single teams, but cross-team agent collaboration isn’t there yet. We’re a few steps away from successful real-world examples.</p>
<hr>
</section>
<section id="q9-do-you-like-the-term-vibe-coding" class="level2">
<h2 class="anchored" data-anchor-id="q9-do-you-like-the-term-vibe-coding">Q9: Do you like the term “vibe coding”?</h2>
<p><strong>Andrew Ng:</strong><br>
Not really.<br>
The name is misleading—it sounds effortless, but it’s cognitively intense.<br>
Coding is becoming more accessible, not obsolete.<br>
Understanding how code works is still essential for prompting and debugging.</p>
<hr>
</section>
<section id="q10-advice-for-ai-startup-founders" class="level2">
<h2 class="anchored" data-anchor-id="q10-advice-for-ai-startup-founders">Q10: Advice for AI startup founders?</h2>
<p><strong>Andrew Ng:</strong><br>
- <strong>#1 predictor of success: SPEED</strong><br>
- <strong>#2: Technical depth</strong><br>
Business knowledge is widespread, but deep tech knowledge and instincts are rare and differentiating.</p>
<hr>
</section>
<section id="full-transcript" class="level2">
<h2 class="anchored" data-anchor-id="full-transcript">Full Transcript</h2>
<p>Transcribed by whisper-small</p>
<p>[INAUDIBLE] This is a track that we see more and more as a lot of the building blocks are starting to get figured out. I’m really excited for this next section. So we’ll be doing a fireside chat with Andrew and Andrew. Probably doesn’t need any introduction to most of our stuff here. I’m guessing a lot of people are thinking as soon as classes begin to work, Sarah will learn deep learning. But I have to admit that this is a big part of the building thing of the story. So I met Andrew a little over two years ago at a conference. We started talking about LinkedIn and he graciously invited us to do a course on LinkedIn. He’s learning, I think, in my son’s best of a second or third one that they ever did. And I know a lot of people here would probably watch that course or I started on LinkedIn because of that course. So Andrew has been a huge part of the LinkedIn journey and I’m super excited to welcome him on stage for a fireside chat. So let’s welcome him to it. [Applause] [Music] [Inaudible] [Inaudible] You’ve obviously touched and thought about so many things in this industry. But one of their takes that I cite a lot and probably people have talked about is your take on kind of like talking about the agendicness of an application as opposed to whether something is an agent. You know as we’re here now at an agent conference, maybe we should rename it to an adjunct conference, but would you mind clarifying that? And I think it was like a year and a half, two years ago that you said that and so I’m curious if things have changed in your mind since then. I remember I mentioned, how was it when I spoke at a conference over a year ago and at that time I think both of us were trying to convince a lot of people that agents are a fling machine. And that was before maybe I think it was this summer last year, a bunch of law underscored the agent in terms of starting to save that sticker everywhere it was. But to her, especially, I mean about a year and a half ago I saw that long people are arguing this is an agent, this is not a particular thing. My presence is a child of law, this is not an agent. And I felt that it was not at the argument that we would succeed. And I think that as a community we just say that there are decreases in something that is an agent. So then we just say that if you want to know an agent system, you can move with autonomy or a lot of autonomy, there’s a high ability to spend time arguing. This is truly an agent. That’s just how it seems an agent system to a different decrease in autonomy. And I think that actually hopefully producing a ton of people, at least it’s been argued that something is an agent. This is called an all-agent thing. Where on that spectrum of kind of like a little autonomy to a lot of autonomy do you see people building for this system? So on the team, the team uses many of these problems, right, with complex problems and so on. I’m also seeing tons of these opportunities that frankly are fairly in danger for a food system, they’re just vocational cyber-assures. So a lot of businesses are opportunities where you’re right now with people looking to form a website, doing a website, checking something. They would be able to see if it’s a compliance issue or if there are some issues, some certain stuff too. It’s kind of like take something, copy paste it into a website, do it in a different way. So in business processes they’re actually a lot of fairly free work. Those are linear with very small business-paginal branches. Usually you could look into a failure with a rejected smartphone though. So I see a lot of work too. But one of my challenges I see businesses have is it’s still pretty difficult to look at some stuff that’s being done in business and figure out how to turn it into a new, gender-work mode. So for this degree of granularity, we should try to bring down the state into a micro-touch and then out to people in the financial prototype. It doesn’t work well enough. Originally, SEVS team worked hard to improve performance. I think that whole bag of skills on how to look at a bunch of stuff that people are doing, break into sequential steps, where the small number of branches hardly put in place in the VALS, all that, that skillset is still hard to work with. And then of course in the national conference agency, I think you heard much about the very complex and most stuff that’s very valid as well. But I see much more in terms of number of opportunities that are now valid. There’s a lot of simple things that I think are still being done as well. Let’s talk about some of those skills. So you’ve been doing deep learning and a lot of courses are in pursuit of helping people kind of build a general. So what are some of the skills that you think each and every one of those all across the spectrum should kind of like master and get started with? Well, it’s a good question. I wish I could answer that. I think a lot about this actually is that I think one of the challenges of having a business process run through your law firm, which would be compliance, people, and the job, whatever the steps. How do you put the business in the background, type integration, how to see if the CEP helps us on that too, to adjust the data, and then how do you process and model steps to build this into a system? And one thing I see about this, putting in place the right key values for your work, to not only understand the performance of your process, but to trace the individual steps, to put in less than one step that is broken, less than one step that is broken to work on. I find that a lot of the teams probably would walk in the nation just using changing key values very effectively. You can sit there and talk about your own things. I see most teams probably slowly take over the place of key values, systematic values in this item. But I find that having the right mistakes, slowly taking two days to college, is still really difficult. The school teams, the teams are still learning how to deal with the off and build-down line-out of these very recent, like a few months, trying to improve one group or another. The most, as he would say, I don’t think this can ever be made to work, so just don’t just find the different variables as well. I wish I had been more efficient to get this almost tactile knowledge. Often you’re there, you know, look at the output, look at the trace, look at the last output, and just sort of make a decision, right, in minutes or hours on the two-to-mix, and that’s still very difficult. And is this kind of like tactile knowledge mostly around LLMs and their limitations, or more around like just the product, bringing those things and that skill of taking a job and breaking it down, that’s something that’s still getting to us. I think it’s all we need, actually. So I feel like over the last couple of years, the AI2 companies have created an amazing set of tools that this includes tools like, you know, that graph also helped you. I guess like, how do you think about the chat box, of many, many different ways of approaching family, and what else, how do you believe that was helping with the audience. But I feel like there’s this, you know, one strong link, a range of various I think tools. But what I’m trying to have in my head is, if all you have are, you know, purple makeup breaks, right, you can’t build out a GCC stuff. And I think of these tools as being the kinds of makeup breaks, right, that the more tools you have, it’s as if you don’t just have purple makeup breaks, but the red one, the black one, the yellow one, the blue one. And as you get more different colors and shades of makeup breaks, you can very quickly assemble them into really cool things. And so I think a lot of these tools, they want those random products, different types of makeup breaks. And when you’re trying to build something, you know, sometimes you need that very squiggly, weird-shaped makeup break, and some of you want to go with a makeup bucket, and just get the job done. But if you’ve never built e-dots at a certain time, then, you know, then you could actually end up spending three or two months doing something that someone else has done that before, because they all, well, we should just build e-dots this way, just to know how to manage it more. And just go through that process and get it done much faster. So one of the unfortunate things about AI is that it’s not just one tool that in my coding, I just use a whole bunch of different stuff, right, a lot of master, and I’ve stopped myself from doing enough tools to set that up. And I think how that practice with different tools also helps a lot of the chasm decision making. And one of the things, they’ve also changed, so for example, just all of a sudden, having longer, longer context, longer best practices, or rag, from, you know, a year and a half ago, or whatever, much less than today. You know, and ever, Harrison was pretty early, he took off the same cycle, played with a early man, changed rag frameworks, the crystal civilization and all that. As Elm Contest Reviews got longer, now we’ve just done the long stuff into our columns. As Elm’s practice got way, but the hyper-fronted team has gotten way easier. It’s a huge range of hyper-fronted that we’re, you know, just fine. So as Elm keeps practicing, the instincts will be holy, you know, two years ago, but they won’t be helping rather than you want to. You mentioned a lot of things that I want to talk about. So, okay, what are some of the level breaks that are maybe underrated right now that you would recommend that people aren’t talking about? Like, e-balls, I think, we have had, we have three people talking about e-balls, and I think that’s top of people’s mind. But what are some things that most people maybe haven’t thought of or haven’t heard of yet that you would recommend that we’re moving into? Good question. I don’t know. I’m sure, even though people talk about e-balls, there’s some ways that people don’t do it. I think it’s because people often have, I saw a post on e-balls right this long, people think of writing e-balls as this huge thing you have to do, right? I think that e-balls is something I’m going to fill together really quickly, you know, in 20 minutes, and it’s not that good, but it starts to complement my human eye-ball e-balls. And so what often happens is that our system has this one problem, right, do you want to get an e-bression? I thought I made it work, and it breaks, I’m sure our average of $1,000 has gotten a $1,000. Then the code is a very simple e-mail, maybe with, you know, five different examples, and some very simple administration to just check for this one regression, right, to this one thing. And then I’m not swapping out human e-mails for a multimeter e-mails, and I’m still looking all through my cell, but when I change something out from just e-mails to just take this word and something, psycho-pattern thing about it, and then what happens is, just like the way we write English, maybe, once you have some slightly helpful but clearly very broken imperfect e-mail, then you’re sad, you know what, I can improve my e-mail to make it better, and I can improve the e-mail to make it better. So just as when we build a lot of applications, we build some very quick and dirty thing that doesn’t work, and we improve e-mail better. From all of the way I go e-mails, I go really all-only-mails, they’re very home, and then when you look at what it does, you go, you know, it’s just e-mails broken, I can fix it, and you improve my e-mail to make it better. So that’s one thing. Actually, one thing that people have talked about, and I think is so automated, is the voice stack. This one thing is that I’m actually very excited about voice applications, a lot of my friends are very excited about voice applications. I see a bunch of logic interfaces, very excited about voice applications, very logic, very logic interfaces. For some reason, while there are some developers in this community to voice the amount of developer attention on voice stack applications, there is software, it’s not really a good thing, but that’s one thing that feels so much smaller than the large enterprise of the important ICS, which is what’s happening on the market. And not all of this is the real-time voice-in-house, it’s not all speech-to-speech-native, what we’re working on, all of this. I find those models are very hard to control, but we use more of an agent-to-e-voice stack for the code, which is great, which we find much more controllable. So, in the end, I’ve been working with a ton of teams on voice stack stuff that some of which hopefully did not seem to be a big problem. And then, other things that are automated, one of the ones that make this not automated, and one of those that should do it, I think many of you have seen that developers that use AI systems in our company is so much faster than developers that don’t. I’ve been, it’s been interesting to see how many companies, CIOs and CTOs still have policies that don’t let the geniuses use AI systems in their company. I think maybe sometimes they’re good reasons, but I think we have to work with them, because I think my teams in our hour just hate to ever have to code again with AI systems in their company, so I think some of this is just something different. I think underrated is the idea that I think everyone should learn to code. One fun fact about AI fun, everyone in the iPhone, including the person that runs out front is perceptionist, and my CFO, and my attorney, and the general counsel, everyone in the iPhone actually knows how to code. It’s not that one day to solve it, it’s not that they respect their job functions, maybe as a member of the code, but they’re able to tell the computer what they wanted to do, and so it’s actually driving the whole productivity across all of these job functions that are not solved in AI. Talking about AI, what tools are you using for that first time? So, we’re working on something that will not get announced. Exciting. So, maybe I do use cursor, red server, and some other things. Alright. Talking about voice, if people here want to get into voice and they’re familiar with building kind of like agents with LLMs, how similar is it? Are there a lot of ideas that are transferable, or what to do, what will they have to learn? So, in terms of the applications where I think voice is important, to increase certain interactions that are not much more important, in terms of the application perspective, input text problems are kind of intimidating. For other applications, we’re going to use the same type of machine, because it’s a local text problem, very much a text problem. That’s very intimidating for users. And one of the problems with that is people can use backspace, and so people are just slowly learning to respond via text. Whereas, the voice, time rules for when you’re just thinking, talking, you could change your mind, and you could say, “Oh, I changed my mind to get that early thing that I wanted, which is pretty good to do.” But I find that the amount of applications for the user are friction to just giving them to use in this little way. So, you know, tell me what you think, and then they respond to voice. So, in terms of voice, one of the biggest differences in terms of agent and client is the expectancy, is if someone says something, and I don’t really want to respond, you know, in some point or second, right? And that’s a fact that in those seconds is great, but really, I’m going to use something in a second. And with a lot of agent work flows that were run for many seconds. So, when you do that, then I want to grow avatar to build an avatar, and that is on my vision, tell the avatar if you want. I mean, this show version had kind of, I think, nine seconds of this, and it’s just an ad user experience. So, it’s something, you know, nine seconds of silence that might have to respond. But some of the building things went from a kind of pre-response. So, just as if you ask a question, I go, “Huh, that’s interesting.” [laughter] So, how to basically do that to hide the latency, and it actually seems to work great. And there are all these other little tricks as well. So, if you’re building a voice console service to chatbot, it turns out that when you play background noise at a console contact center, it’s a dead silence. People are much more sensitive of that, of that latency. So, I find that there are all of these things that are different in a pure text based algorithm. But in applications where a voice based modality doesn’t use to be comfortable and just not talking, I think it’s sometimes really good to use this to use a friction. So, I’m going to give you some information on that. I think when we talk, we don’t feel like we need to deliver perfection as much as we’re afraid. So, somehow, you see a bridge just starting to tell your ideas and change them on, and then we’re going to fail. And that lets us get the information from them that we need to help you use it to the point. [inaudible] Hi. [laughter] One of the new things that’s out there you mentioned recently is MCP. How are you seeing that transform of how people are building apps, what types of apps are building or what’s happening in the ecosystem? Yeah, I think it’s really exciting. Just this morning, we released a new enthralment, I’m sure, was an MCP. I actually saw a lot of stuff, you know, on the internet on MCP that I found quite confusing. So, what’s going on there is that, you know, let’s put a really good short pause on MCP that explains security. I think MCP is fantastic. I think it’s very clear, properly, that that open app adopted it. Also, I think it’s based on the importance of this. I think the MCP’s standard won’t continue to evolve. So, for example, I think many of you know what MCP is, right? It’s much easier for agents primarily, but frankly, I think other types of software took over the two types of data. When I’m using OBS myself or when I’m building applications, frankly, for all of us, we spend so much time on the platform, right? So, I think, for those of you from Washington, Pryce, as well, the AI, especially, you know, using OBS, are pretty darn intelligent to evolve stuff when doing the right context. So, I found that I spent my time working and applying on the data integration to get the context of the OBS to make it feel like it’s something that offers a pretty sensible market spread for the context. So, MCP, I think, is a fantastic way to try to standardize interface to other tools. You can call us as well, say, as well as this. It feels like, it feels a little bit like, wow, as long as the MCP serves, you finally internet do your work, right? And then the authentication systems are kind of, you know, even for the very large companies, you know, the MCP service of the company, the nuclear authentication token, token worlds, and these bias along that way on. I think the MCP protocol itself is also really, right now, MCP gives a long list of the resources in the role. You know, eventually, I think we’ll be something more hierarchical and destructive. So, imagine you want to build something, I don’t know, I know that there will be an MCP interface to a land graph, but land graph is still the API calls, you just kind of have like a long list of everything under the sun for agents to sort out. So, I think MCP is a really good task at first step. Definitely encourage you to learn about it. It won’t make your life easier. Probably, you’ll find a good MCP service in the communications service, in the communications operations. I think what we’re important is this idea of, you know, any models for agents and data sources, they show up in any type of effort to do all the integration and plus them. I think MCP is a fantastic first step. It will need to be all like a fantastic first step to what the data integration is. Another type of protocol that seems less likely than MCP is the agent-to-agent system. And I remember when we were in Harvard a year or so ago, I think you were talking about multi-agent systems, which this kind of enabled. So, how do you see some of the multi-agent or agent-to-agent stuff of the protocol? So, I think, you know, agent and AI are still so early. Both of us, right, we struggle, we didn’t make our code work. And so, making my code, my agent work with someone else’s agent, it feels like a two-miracle. [laughter] So, I see that one team is building multi-agent systems. That often works because people have a bunch of agents, they can be themselves and their protocols, that works. But right now, at least at this moment in time, maybe I’m off. The number of examples I’m seeing of when, you know, one team’s agent and correction agent successfully made agents, it’s totally different teams’ agent and correction agents. I think we’re a little bit early to that. I’m sure we’ll get there, but I’m not personally seeing, you know, real success, pure success stories of that. Yeah, I don’t think that’s true. No, I think it’s super early. I think if MCP is early, I think the agent stuff is super early. Another thing that’s kind of like top of what’s mine right now is it’s kind of vibe coding. And all that, I touched on it a little bit earlier with how people are using these AI coding systems. But how do you think about vibe coding? Is that a different skill than before or what kind of a mis-disaster? Yeah, so I think many of us code, we’re barely looking at the code, right? I think it’s a fantastic thing to do. I think it’s unfortunate that that code, “vine coding” is misleading a lot of people. I think it just goes by, you know, just like that. And frankly, when I’m coding for a day, you know, with vinyl or whatever, I forget code systems, I’m frankly exhausted by the end of the day, so I’m thinking it’s an Android device. And so I think the name is unfortunate, but the phenomenon is real and it’s been taking part in this great. So, I mean, over the last year, a few people have been advising others to come up to code on the basis that they have more to be coding. I think we’ll back this on the worst career advice that we’ve ever done. Because over the last many decades, as coding is getting easier, more people started to code. So it turns out, you know, when we went from punch-cost to key-cost, that’s how it went, very well. But it turns out, actually, thousands of variable algorithms went probably from a sending language to a literally code wall. There were people arguing back then, “Yeah, code wall is so easy, we don’t need programs anymore.” And I’ll say, it’s getting easier, more people are going to code. And so, we’ve been coding systems, more people should code. But I think, and it turns out, one of the most important schools in the future for developers and developers, is the ability to tell a code to exactly what you want, so they want to do it for you. And I think understanding at some level, which I’ll be talking about, understanding at some level how a computer works, lets you prompt on a stronger future, so they’re much more accessible. Which is why I still try to advise everyone to learn one program, and I try to hide them by something. And then, I think some of you know this, but I personally about, you know, a much stronger height than developer, I did say JavaScript, right? But with AI system coding, I now write a lot more JavaScript in types of code than I ever used to. But even with debugging, you know, JavaScript code, that something else, really understanding what are the error cases, what does that mean, that it’s pretty difficult to write on JavaScript. If you don’t like the name “by” coding, do you have a better name for “by”? Oh, that’s a good question. I shouldn’t think about that. We’ll get back to you on that. One of the things that you announced recently is a new fund for AI funds, so if you grab some of that, for people in the audience who are really thinking of starting a startup, what advice would you give them? So, in front of the just studios, we build companies, and we have to consider the investment companies that we co-founded. So, I think in terms of running back on AI funds lessons learned, I would say that the number one predictor of a startup success is split. I know it’s looking value, but I see it all the people that I’ve never seen yet, the speed through which a skilled team can execute, and if you’ve never seen it before, I know many of you have seen it. It’s just so much faster than anything that slow businesses can hardly do. And I think the number two predictor also very important is tech-con knowledge. It turns out that we look at the schools in the new sector to some things like how we market, how we sell, how we price. All that is important, but that knowledge has to be constantly more widespread. The knowledge that’s really rare is how this technology actually works, because technology evolves so quickly. So, I have deep respect for good market. How good pricing is hard, how good marketing is hard, position is hard, but that knowledge is more diffused. And the most rare reason is somewhat, they’re being understood how the technology works. So, what I found really is that there are community tech-con people that have good instincts, understand, do this, don’t do that, just as good ties as that. And then I think along with the business stuff, that the knowledge is very important to the transition needs here to figure out. Alright, that’s great advice for starting something. We are going to wrap this up. We’re going to go to a break now, but before we do, please join me in giving Andrew a big hand. [Applause] Our next session is in 15 minutes. [Indistinct conversation] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music] [Music]</p>


</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-05-13-andrew-ng-harrison-chase-fireside-chat/</guid>
  <pubDate>Wed, 14 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>LangChain Interrupt Conference - Day 1</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-05-13-langchain-interrupt-day-1/</link>
  <description><![CDATA[ 




<p>I had the privilege of attending LangChain’s first conference. The first day was a hands-on workshop going through the creation of an agent (an email assistant) from scratch. It went through many of the components of building an agent:</p>
<ul>
<li>Overview of LangGraph</li>
<li>Writing the Agent</li>
<li>Evaluation / Testing</li>
<li>Human Feedback</li>
<li>Memory</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-05-13-langchain-interrupt-day-1/email_assistant_diagram.png" class="img-fluid figure-img"></p>
<figcaption>Email Assistant Diagram</figcaption>
</figure>
</div>
<section id="code" class="level2">
<h2 class="anchored" data-anchor-id="code">Code</h2>
<ul>
<li>Python: <a href="https://github.com/langchain-ai/agents-from-scratch">https://github.com/langchain-ai/agents-from-scratch</a></li>
<li>Typescript: <a href="https://github.com/langchain-ai/agents-from-scratch-ts">https://github.com/langchain-ai/agents-from-scratch-ts</a> (this is the first time I’ve seen Typescript Jupyter notebooks)</li>
</ul>
</section>
<section id="notebook-1-langgraph-101" class="level2">
<h2 class="anchored" data-anchor-id="notebook-1-langgraph-101">Notebook 1: LangGraph 101</h2>
<p>Notebook: <a href="https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/langgraph_101.ipynb">langgraph_101.ipynb</a></p>
<p>Lance Martin gave an overview of LangGraph that was largely review. It was a good reminder that “tool calling is just structured output.”</p>
<p>LangGraph code to create the agent:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Literal</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MessagesState</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> email_assistant.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> show_graph</span>
<span id="cb1-4"></span>
<span id="cb1-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> call_llm(state: MessagesState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> MessagesState:</span>
<span id="cb1-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Run LLM"""</span></span>
<span id="cb1-7"></span>
<span id="cb1-8">    output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model_with_tools.invoke(state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>])</span>
<span id="cb1-9">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [output]}</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># actually what happens when a tool call is made</span></span>
<span id="cb1-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> run_tool(state: MessagesState):</span>
<span id="cb1-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Performs the tool call"""</span></span>
<span id="cb1-14"></span>
<span id="cb1-15">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb1-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tool_call <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].tool_calls:</span>
<span id="cb1-17">        observation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> write_email.invoke(tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>])</span>
<span id="cb1-18">        result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: observation, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb1-19">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: result}</span>
<span id="cb1-20"></span>
<span id="cb1-21"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> should_continue(state: MessagesState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span>, END]:</span>
<span id="cb1-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Route to tool handler, or end if Done tool called"""</span></span>
<span id="cb1-23">    </span>
<span id="cb1-24">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the last message</span></span>
<span id="cb1-25">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="cb1-26">    last_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> messages[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb1-27">    </span>
<span id="cb1-28">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If the last message is a tool call, check if it's a Done tool call</span></span>
<span id="cb1-29">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> last_message.tool_calls:</span>
<span id="cb1-30">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span></span>
<span id="cb1-31">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Otherwise, we stop (reply to the user)</span></span>
<span id="cb1-32">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> END</span>
<span id="cb1-33"></span>
<span id="cb1-34">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(MessagesState)</span>
<span id="cb1-35">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"call_llm"</span>, call_llm)</span>
<span id="cb1-36">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span>, run_tool)</span>
<span id="cb1-37">workflow.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"call_llm"</span>)</span>
<span id="cb1-38">workflow.add_conditional_edges(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"call_llm"</span>, should_continue, {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span>, END: END})</span>
<span id="cb1-39">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"run_tool"</span>, END)</span>
<span id="cb1-40"></span>
<span id="cb1-41"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Run the workflow</span></span>
<span id="cb1-42">app <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span></code></pre></div></div>
</section>
<section id="notebook-2-building-the-agent" class="level2">
<h2 class="anchored" data-anchor-id="notebook-2-building-the-agent">Notebook 2: Building the Agent</h2>
<p>Notebook: <a href="https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/agent.ipynb">agent.ipynb</a></p>
<p>Example Code for the Router in LangGraph</p>
<ul>
<li><code>Command</code> does control flow AND state up dates in one</li>
<li>In the example below: <code>return Command(goto=goto, update=update)</code></li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> RouterSchema(BaseModel):</span>
<span id="cb2-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Analyze the unread email and route it according to its content."""</span></span>
<span id="cb2-3"></span>
<span id="cb2-4">    reasoning: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb2-5">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Step-by-step reasoning behind the classification."</span></span>
<span id="cb2-6">    )</span>
<span id="cb2-7">    classification: Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"respond"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"notify"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(</span>
<span id="cb2-8">        description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The classification of an email: 'ignore' for irrelevant emails, "</span></span>
<span id="cb2-9">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"'notify' for important information that doesn't need a response, "</span></span>
<span id="cb2-10">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"'respond' for emails that need a reply"</span>,</span>
<span id="cb2-11">    )</span>
<span id="cb2-12"></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Initialize the LLM for use with router / structured output</span></span>
<span id="cb2-14">llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> init_chat_model(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai:gpt-4.1"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>)</span>
<span id="cb2-15">llm_router <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.with_structured_output(RouterSchema) </span>
<span id="cb2-16"></span>
<span id="cb2-17"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> triage_router(state: State) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_agent"</span>, END]]:</span>
<span id="cb2-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Analyze email content to decide if we should respond, notify, or ignore."""</span></span>
<span id="cb2-19">    </span>
<span id="cb2-20">    author, to, subject, email_thread <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_email(state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"email_input"</span>])</span>
<span id="cb2-21">    system_prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> triage_system_prompt.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(</span>
<span id="cb2-22">        background<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>default_background,</span>
<span id="cb2-23">        triage_instructions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>default_triage_instructions</span>
<span id="cb2-24">    )</span>
<span id="cb2-25"></span>
<span id="cb2-26">    user_prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> triage_user_prompt.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(</span>
<span id="cb2-27">        author<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>author, to<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>to, subject<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>subject, email_thread<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>email_thread</span>
<span id="cb2-28">    )</span>
<span id="cb2-29"></span>
<span id="cb2-30">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm_router.invoke(</span>
<span id="cb2-31">        [</span>
<span id="cb2-32">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: system_prompt},</span>
<span id="cb2-33">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: user_prompt},</span>
<span id="cb2-34">        ]</span>
<span id="cb2-35">    )</span>
<span id="cb2-36">    </span>
<span id="cb2-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> result.classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"respond"</span>:</span>
<span id="cb2-38">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"📧 Classification: RESPOND - This email requires a response"</span>)</span>
<span id="cb2-39">        goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_agent"</span></span>
<span id="cb2-40">        update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb2-41">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [</span>
<span id="cb2-42">                {</span>
<span id="cb2-43">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb2-44">                    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Respond to the email: </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>format_email_markdown(subject, author, to, email_thread)<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb2-45">                }</span>
<span id="cb2-46">            ],</span>
<span id="cb2-47">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classification_decision"</span>: result.classification,</span>
<span id="cb2-48">        }</span>
<span id="cb2-49">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> result.classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>:</span>
<span id="cb2-50">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"🚫 Classification: IGNORE - This email can be safely ignored"</span>)</span>
<span id="cb2-51">        goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb2-52">        update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>  {</span>
<span id="cb2-53">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classification_decision"</span>: result.classification,</span>
<span id="cb2-54">        }</span>
<span id="cb2-55">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> result.classification <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"notify"</span>:</span>
<span id="cb2-56">        <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"🔔 Classification: NOTIFY - This email contains important information"</span>)</span>
<span id="cb2-57">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># For now, we go to </span><span class="re">END</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">. But we will add to this later!</span></span>
<span id="cb2-58">        goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb2-59">        update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb2-60">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"classification_decision"</span>: result.classification,</span>
<span id="cb2-61">        }</span>
<span id="cb2-62">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb2-63">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid classification: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>result<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>classification<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb2-64">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>goto, update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>update)</span></code></pre></div></div>
<p>You can add agents in nodes in LangGraph:</p>
<ul>
<li>xray show true shows it</li>
<li>If a LangGraph agent is deployed in LangGraph platform, I think I can also use this as a Remote Graph</li>
</ul>
</section>
<section id="notebook-3-evaluating-the-agent" class="level2">
<h2 class="anchored" data-anchor-id="notebook-3-evaluating-the-agent">Notebook 3: Evaluating the Agent</h2>
<p>Notebook: <a href="https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/evaluation.ipynb">evaluation</a></p>
<ul>
<li>When thinking of evaluations, if an expected input does not have a static expected output, you can define “Response Criteria” which a LLM as Judge could take in.</li>
<li>Below is an example with “Response Criteria”</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>Users<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>lawrence.wu<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>github<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">/</span>agents<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span>scratch</span>
<span id="cb3-2"></span>
<span id="cb3-3">Email Input: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'author'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Alice Smith &lt;alice.smith@company.com&gt;'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'to'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Lance Martin &lt;lance@company.com&gt;'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'subject'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Quick question about API documentation'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'email_thread'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Hi Lance,</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">I was reviewing the API documentation for the new authentication service and noticed a few endpoints seem to be missing from the specs. Could you help clarify if this was intentional or if we should update the docs?</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Specifically, I'm looking at:</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- /auth/refresh</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- /auth/validate</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Thanks!</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Alice"</span>}</span>
<span id="cb3-4">Expected Triage Output: respond</span>
<span id="cb3-5">Expected Tool Calls: [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'write_email'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'done'</span>]</span>
<span id="cb3-6">Response Criteria: </span>
<span id="cb3-7">• Send email <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">with</span> write_email tool call to acknowledge the question <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">and</span> confirm it will be investigated  </span></code></pre></div></div>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">all_messages_str <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> format_messages_string(response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'messages'</span>])</span>
<span id="cb4-2">eval_result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> criteria_eval_structured_llm.invoke([</span>
<span id="cb4-3">        {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>,</span>
<span id="cb4-4">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: RESPONSE_CRITERIA_SYSTEM_PROMPT},</span>
<span id="cb4-5">        {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb4-6">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"""</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Response criteria: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>success_criteria<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Assistant's response: </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>all_messages_str<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> </span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;"> Evaluate whether the assistant's response meets the criteria and provide justification for your evaluation."""</span>}</span>
<span id="cb4-7">    ])</span>
<span id="cb4-8">eval_result</span></code></pre></div></div>
<p>new interrupt node</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> triage_interrupt_handler(state: State) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_agent"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__end__"</span>]]:</span>
<span id="cb5-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Handles interrupts from the triage step."""</span></span>
<span id="cb5-3">    </span>
<span id="cb5-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parse the email input</span></span>
<span id="cb5-5">    author, to, subject, email_thread <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_email(state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"email_input"</span>])</span>
<span id="cb5-6"></span>
<span id="cb5-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create email markdown for Agent Inbox in case of notification  </span></span>
<span id="cb5-8">    email_markdown <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> format_email_markdown(subject, author, to, email_thread)</span>
<span id="cb5-9"></span>
<span id="cb5-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create messages</span></span>
<span id="cb5-11">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb5-12">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Email to notify user about: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>email_markdown<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb5-13">                }]</span>
<span id="cb5-14"></span>
<span id="cb5-15"></span>
<span id="cb5-16">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create interrupt that is shown to the user</span></span>
<span id="cb5-17">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This request schema is what Agent Inbox expects</span></span>
<span id="cb5-18">    request <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-19">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"action_request"</span>: {</span>
<span id="cb5-20">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"action"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Email Assistant: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'classification_decision'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>,</span>
<span id="cb5-21">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>: {}</span>
<span id="cb5-22">        },</span>
<span id="cb5-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config"</span>: {</span>
<span id="cb5-24">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_ignore"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,  </span>
<span id="cb5-25">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_respond"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, </span>
<span id="cb5-26">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_edit"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>, </span>
<span id="cb5-27">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_accept"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,  </span>
<span id="cb5-28">        },</span>
<span id="cb5-29">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Email to show in Agent Inbox</span></span>
<span id="cb5-30">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"description"</span>: email_markdown,</span>
<span id="cb5-31">    }</span>
<span id="cb5-32"></span>
<span id="cb5-33">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Agent Inbox responds with a list of dicts with a single key `type` that can be `accept`, `edit`, `ignore`, or `response`.  </span></span>
<span id="cb5-34">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> interrupt([request])[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb5-35"></span>
<span id="cb5-36">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If user provides feedback, go to response agent and use feedback to respond to email   </span></span>
<span id="cb5-37">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response"</span>:</span>
<span id="cb5-38">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add feedback to messages </span></span>
<span id="cb5-39">        user_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>]</span>
<span id="cb5-40">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Used by the response agent</span></span>
<span id="cb5-41">        messages.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>,</span>
<span id="cb5-42">                        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"User wants to reply to the email. Use this feedback to respond: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_input<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb5-43">                        })</span>
<span id="cb5-44">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Go to response agent</span></span>
<span id="cb5-45">        goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_agent"</span></span>
<span id="cb5-46"></span>
<span id="cb5-47">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If user ignores email, go to </span><span class="re">END</span></span>
<span id="cb5-48">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>:</span>
<span id="cb5-49">        goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb5-50"></span>
<span id="cb5-51">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Catch all other responses</span></span>
<span id="cb5-52">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb5-53">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid response: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>response<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb5-54"></span>
<span id="cb5-55">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the state </span></span>
<span id="cb5-56">    update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb5-57">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: messages,</span>
<span id="cb5-58">    }</span>
<span id="cb5-59"></span>
<span id="cb5-60">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>goto, update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>update)</span></code></pre></div></div>
<p>Actually thinking through all of the different use cases and how it affects the workflow of the agent is important. Pretty complicated even just for a simple email assistant.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-05-13-langchain-interrupt-day-1/response_agent_outcomes.png" class="img-fluid figure-img"></p>
<figcaption>Response Agent Outcomes</figcaption>
</figure>
</div>
<p>Interrupt handler, define the config for each node</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> interrupt_handler(state: State) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Command[Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm_call"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"__end__"</span>]]:</span>
<span id="cb6-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Creates an interrupt for human review of tool calls"""</span></span>
<span id="cb6-3">    </span>
<span id="cb6-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store messages</span></span>
<span id="cb6-5">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb6-6"></span>
<span id="cb6-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Go to the LLM call node next</span></span>
<span id="cb6-8">    goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm_call"</span></span>
<span id="cb6-9"></span>
<span id="cb6-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Iterate over the tool calls in the last message</span></span>
<span id="cb6-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tool_call <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>].tool_calls:</span>
<span id="cb6-12">        </span>
<span id="cb6-13">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Allowed tools for HITL</span></span>
<span id="cb6-14">        hitl_tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"write_email"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"schedule_meeting"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Question"</span>]</span>
<span id="cb6-15">        </span>
<span id="cb6-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If tool is not in our HITL list, execute it directly without interruption</span></span>
<span id="cb6-17">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> hitl_tools:</span>
<span id="cb6-18"></span>
<span id="cb6-19">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute search_memory and other tools without interruption</span></span>
<span id="cb6-20">            tool <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tools_by_name[tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>]]</span>
<span id="cb6-21">            observation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tool.invoke(tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>])</span>
<span id="cb6-22">            result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: observation, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-23">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">continue</span></span>
<span id="cb6-24">            </span>
<span id="cb6-25">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get original email from email_input in state</span></span>
<span id="cb6-26">        email_input <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"email_input"</span>]</span>
<span id="cb6-27">        author, to, subject, email_thread <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> parse_email(email_input)</span>
<span id="cb6-28">        original_email_markdown <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> format_email_markdown(subject, author, to, email_thread)</span>
<span id="cb6-29">        </span>
<span id="cb6-30">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Format tool call for display and prepend the original email</span></span>
<span id="cb6-31">        tool_display <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> format_for_display(state, tool_call)</span>
<span id="cb6-32">        description <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> original_email_markdown <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> tool_display</span>
<span id="cb6-33"></span>
<span id="cb6-34">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Configure what actions are allowed in Agent Inbox</span></span>
<span id="cb6-35">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"write_email"</span>:</span>
<span id="cb6-36">            config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-37">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_ignore"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-38">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_respond"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-39">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_edit"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-40">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_accept"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-41">            }</span>
<span id="cb6-42">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"schedule_meeting"</span>:</span>
<span id="cb6-43">            config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-44">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_ignore"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-45">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_respond"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-46">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_edit"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-47">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_accept"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-48">            }</span>
<span id="cb6-49">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Question"</span>:</span>
<span id="cb6-50">            config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-51">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_ignore"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-52">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_respond"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,</span>
<span id="cb6-53">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_edit"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb6-54">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"allow_accept"</span>: <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb6-55">            }</span>
<span id="cb6-56">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-57">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid tool call: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb6-58"></span>
<span id="cb6-59">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create the interrupt request</span></span>
<span id="cb6-60">        request <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-61">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"action_request"</span>: {</span>
<span id="cb6-62">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"action"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>],</span>
<span id="cb6-63">                <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>]</span>
<span id="cb6-64">            },</span>
<span id="cb6-65">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"config"</span>: config,</span>
<span id="cb6-66">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"description"</span>: description,</span>
<span id="cb6-67">        }</span>
<span id="cb6-68"></span>
<span id="cb6-69">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Send to Agent Inbox and wait for response</span></span>
<span id="cb6-70">        response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> interrupt([request])[<span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>]</span>
<span id="cb6-71"></span>
<span id="cb6-72">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Handle the responses </span></span>
<span id="cb6-73">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"accept"</span>:</span>
<span id="cb6-74"></span>
<span id="cb6-75">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the tool with original args</span></span>
<span id="cb6-76">            tool <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tools_by_name[tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>]]</span>
<span id="cb6-77">            observation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tool.invoke(tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>])</span>
<span id="cb6-78">            result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: observation, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-79">                        </span>
<span id="cb6-80">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"edit"</span>:</span>
<span id="cb6-81"></span>
<span id="cb6-82">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Tool selection </span></span>
<span id="cb6-83">            tool <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tools_by_name[tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>]]</span>
<span id="cb6-84">            </span>
<span id="cb6-85">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get edited args from Agent Inbox</span></span>
<span id="cb6-86">            edited_args <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>]</span>
<span id="cb6-87"></span>
<span id="cb6-88">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the AI message's tool call with edited content (reference to the message in the state)</span></span>
<span id="cb6-89">            ai_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the most recent message from the state</span></span>
<span id="cb6-90">            current_id <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>] <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Store the ID of the tool call being edited</span></span>
<span id="cb6-91">            </span>
<span id="cb6-92">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new list of tool calls by filtering out the one being edited and adding the updated version</span></span>
<span id="cb6-93">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This avoids modifying the original list directly (immutable approach)</span></span>
<span id="cb6-94">            updated_tool_calls <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [tc <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tc <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> ai_message.tool_calls <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tc[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">!=</span> current_id] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [</span>
<span id="cb6-95">                {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>], <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>: edited_args, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>: current_id}</span>
<span id="cb6-96">            ]</span>
<span id="cb6-97"></span>
<span id="cb6-98">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a new copy of the message with updated tool calls rather than modifying the original</span></span>
<span id="cb6-99">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># This ensures state immutability and prevents side effects in other parts of the code</span></span>
<span id="cb6-100">            result.append(ai_message.model_copy(update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_calls"</span>: updated_tool_calls}))</span>
<span id="cb6-101"></span>
<span id="cb6-102">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the write_email tool call with the edited content from Agent Inbox</span></span>
<span id="cb6-103">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"write_email"</span>:</span>
<span id="cb6-104">                </span>
<span id="cb6-105">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the tool with edited args</span></span>
<span id="cb6-106">                observation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tool.invoke(edited_args)</span>
<span id="cb6-107">                </span>
<span id="cb6-108">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add only the tool response message</span></span>
<span id="cb6-109">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: observation, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: current_id})</span>
<span id="cb6-110">            </span>
<span id="cb6-111">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the schedule_meeting tool call with the edited content from Agent Inbox</span></span>
<span id="cb6-112">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"schedule_meeting"</span>:</span>
<span id="cb6-113">                </span>
<span id="cb6-114">                </span>
<span id="cb6-115">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Execute the tool with edited args</span></span>
<span id="cb6-116">                observation <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> tool.invoke(edited_args)</span>
<span id="cb6-117">                </span>
<span id="cb6-118">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add only the tool response message</span></span>
<span id="cb6-119">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: observation, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: current_id})</span>
<span id="cb6-120">            </span>
<span id="cb6-121">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Catch all other tool calls</span></span>
<span id="cb6-122">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-123">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid tool call: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb6-124"></span>
<span id="cb6-125">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"ignore"</span>:</span>
<span id="cb6-126">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"write_email"</span>:</span>
<span id="cb6-127">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and tell the agent how to proceed</span></span>
<span id="cb6-128">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User ignored this email draft. Ignore this email and end the workflow."</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-129">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Go to </span><span class="re">END</span></span>
<span id="cb6-130">                goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb6-131">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"schedule_meeting"</span>:</span>
<span id="cb6-132">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and tell the agent how to proceed</span></span>
<span id="cb6-133">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User ignored this calendar meeting draft. Ignore this email and end the workflow."</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-134">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Go to </span><span class="re">END</span></span>
<span id="cb6-135">                goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb6-136">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Question"</span>:</span>
<span id="cb6-137">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and tell the agent how to proceed</span></span>
<span id="cb6-138">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User ignored this question. Ignore this email and end the workflow."</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-139">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Go to </span><span class="re">END</span></span>
<span id="cb6-140">                goto <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> END</span>
<span id="cb6-141">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-142">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid tool call: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb6-143">            </span>
<span id="cb6-144">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"type"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response"</span>:</span>
<span id="cb6-145">            <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># User provided feedback</span></span>
<span id="cb6-146">            user_feedback <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> response[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"args"</span>]</span>
<span id="cb6-147">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"write_email"</span>:</span>
<span id="cb6-148">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and add a message with the user feedback to incorporate into the email</span></span>
<span id="cb6-149">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"User gave feedback, which can we incorporate into the email. Feedback: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_feedback<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-150">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"schedule_meeting"</span>:</span>
<span id="cb6-151">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and add a message with the user feedback to incorporate into the email</span></span>
<span id="cb6-152">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"User gave feedback, which can we incorporate into the meeting request. Feedback: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_feedback<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-153">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">elif</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Question"</span>:</span>
<span id="cb6-154">                <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Don't execute the tool, and add a message with the user feedback to incorporate into the email</span></span>
<span id="cb6-155">                result.append({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"User answered the question, which can we can use for any follow up actions. Feedback: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>user_feedback<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"tool_call_id"</span>: tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"id"</span>]})</span>
<span id="cb6-156">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-157">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid tool call: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'name'</span>]<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb6-158"></span>
<span id="cb6-159">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Catch all other responses</span></span>
<span id="cb6-160">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb6-161">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">ValueError</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Invalid response: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>response<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb6-162">            </span>
<span id="cb6-163">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the state </span></span>
<span id="cb6-164">    update <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb6-165">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: result,</span>
<span id="cb6-166">    }</span>
<span id="cb6-167"></span>
<span id="cb6-168">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> Command(goto<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>goto, update<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>update)</span></code></pre></div></div>
<p>Then the graph looks like this now:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> email_assistant.utils <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> show_graph</span>
<span id="cb7-2"></span>
<span id="cb7-3"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Conditional edge function</span></span>
<span id="cb7-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> should_continue(state: State) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> Literal[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"interrupt_handler"</span>, END]:</span>
<span id="cb7-5">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Route to tool handler, or end if Done tool called"""</span></span>
<span id="cb7-6">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="cb7-7">    last_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> messages[<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>]</span>
<span id="cb7-8">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> last_message.tool_calls:</span>
<span id="cb7-9">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> tool_call <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> last_message.tool_calls: </span>
<span id="cb7-10">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> tool_call[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Done"</span>:</span>
<span id="cb7-11">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> END</span>
<span id="cb7-12">            <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb7-13">                <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"interrupt_handler"</span></span>
<span id="cb7-14"></span>
<span id="cb7-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build workflow</span></span>
<span id="cb7-16">agent_builder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(State)</span>
<span id="cb7-17"></span>
<span id="cb7-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add nodes</span></span>
<span id="cb7-19">agent_builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm_call"</span>, llm_call)</span>
<span id="cb7-20">agent_builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"interrupt_handler"</span>, interrupt_handler)</span>
<span id="cb7-21"></span>
<span id="cb7-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add edges</span></span>
<span id="cb7-23">agent_builder.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm_call"</span>)</span>
<span id="cb7-24">agent_builder.add_conditional_edges(</span>
<span id="cb7-25">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"llm_call"</span>,</span>
<span id="cb7-26">    should_continue,</span>
<span id="cb7-27">    {</span>
<span id="cb7-28">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"interrupt_handler"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"interrupt_handler"</span>,</span>
<span id="cb7-29">        END: END,</span>
<span id="cb7-30">    },</span>
<span id="cb7-31">)</span>
<span id="cb7-32"></span>
<span id="cb7-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Compile the agent</span></span>
<span id="cb7-34">response_agent <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> agent_builder.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="cb7-35"></span>
<span id="cb7-36"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build overall workflow</span></span>
<span id="cb7-37">overall_workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb7-38">    StateGraph(State, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>StateInput)</span>
<span id="cb7-39">    .add_node(triage_router)</span>
<span id="cb7-40">    .add_node(triage_interrupt_handler)</span>
<span id="cb7-41">    .add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"response_agent"</span>, response_agent)</span>
<span id="cb7-42">    .add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"triage_router"</span>)</span>
<span id="cb7-43">    </span>
<span id="cb7-44">)</span>
<span id="cb7-45"></span>
<span id="cb7-46">email_assistant <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> overall_workflow.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="cb7-47">show_graph(email_assistant, xray<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span></code></pre></div></div>
</section>
<section id="notebook-4-human-in-the-loop" class="level2">
<h2 class="anchored" data-anchor-id="notebook-4-human-in-the-loop">Notebook 4: Human-in-the-loop</h2>
<p>Notebook: <a href="https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/hitl.ipynb">hitl.ipynb</a></p>
<p>This was a very interesting demo showcasing how a LangGraph agent that has an interrupt, can send that interrupt to a UI, in this case <a href="https://github.com/langchain-ai/agent-inbox">Agent Inbox</a>. A human can give that feedback in the Agent Inbox UI and the LangGraph graph will take that feedback and continue processing.</p>
</section>
<section id="notebook-5-memory" class="level2">
<h2 class="anchored" data-anchor-id="notebook-5-memory">Notebook 5: Memory</h2>
<p>Notebook: <a href="https://github.com/langchain-ai/agents-from-scratch/blob/main/notebooks/memory.ipynb">memory.ipynb</a></p>
<p>Update memory instructions - some of this was taken from the gpt-4.1 prompting guide</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1">MEMORY_UPDATE_INSTRUCTIONS <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-2"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"># Role and Objective</span></span>
<span id="cb8-3"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">You are a memory profile manager for an email assistant agent that selectively updates user preferences based on feedback messages from human-in-the-loop interactions with the email assistant.</span></span>
<span id="cb8-4"></span>
<span id="cb8-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"># Instructions</span></span>
<span id="cb8-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- NEVER overwrite the entire memory profile</span></span>
<span id="cb8-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- ONLY make targeted additions of new information</span></span>
<span id="cb8-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- ONLY update specific facts that are directly contradicted by feedback messages</span></span>
<span id="cb8-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- PRESERVE all other existing information in the profile</span></span>
<span id="cb8-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- Format the profile consistently with the original style</span></span>
<span id="cb8-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- Generate the profile as a string</span></span>
<span id="cb8-12"></span>
<span id="cb8-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"># Reasoning Steps</span></span>
<span id="cb8-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">1. Analyze the current memory profile structure and content</span></span>
<span id="cb8-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">2. Review feedback messages from human-in-the-loop interactions</span></span>
<span id="cb8-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">3. Extract relevant user preferences from these feedback messages (such as edits to emails/calendar invites, explicit feedback on assistant performance, user decisions to ignore certain emails)</span></span>
<span id="cb8-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">4. Compare new information against existing profile</span></span>
<span id="cb8-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">5. Identify only specific facts to add or update</span></span>
<span id="cb8-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">6. Preserve all other existing information</span></span>
<span id="cb8-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">7. Output the complete updated profile</span></span>
<span id="cb8-21"></span>
<span id="cb8-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"># Example</span></span>
<span id="cb8-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;memory_profile&gt;</span></span>
<span id="cb8-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">RESPOND:</span></span>
<span id="cb8-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- wife</span></span>
<span id="cb8-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- specific questions</span></span>
<span id="cb8-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- system admin notifications</span></span>
<span id="cb8-28"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">NOTIFY: </span></span>
<span id="cb8-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- meeting invites</span></span>
<span id="cb8-30"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">IGNORE:</span></span>
<span id="cb8-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- marketing emails</span></span>
<span id="cb8-32"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- company-wide announcements</span></span>
<span id="cb8-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- messages meant for other teams</span></span>
<span id="cb8-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/memory_profile&gt;</span></span>
<span id="cb8-35"></span>
<span id="cb8-36"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;user_messages&gt;</span></span>
<span id="cb8-37"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"The assistant shouldn't have responded to that system admin notification."</span></span>
<span id="cb8-38"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/user_messages&gt;</span></span>
<span id="cb8-39"></span>
<span id="cb8-40"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;updated_profile&gt;</span></span>
<span id="cb8-41"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">RESPOND:</span></span>
<span id="cb8-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- wife</span></span>
<span id="cb8-43"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- specific questions</span></span>
<span id="cb8-44"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">NOTIFY: </span></span>
<span id="cb8-45"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- meeting invites</span></span>
<span id="cb8-46"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- system admin notifications</span></span>
<span id="cb8-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">IGNORE:</span></span>
<span id="cb8-48"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- marketing emails</span></span>
<span id="cb8-49"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- company-wide announcements</span></span>
<span id="cb8-50"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- messages meant for other teams</span></span>
<span id="cb8-51"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/updated_profile&gt;</span></span>
<span id="cb8-52"></span>
<span id="cb8-53"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;"># Process current profile for </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{namespace}</span></span>
<span id="cb8-54"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;memory_profile&gt;</span></span>
<span id="cb8-55"><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{current_profile}</span></span>
<span id="cb8-56"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">&lt;/memory_profile&gt;</span></span>
<span id="cb8-57"></span>
<span id="cb8-58"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Think step by step about what specific feedback is being provided and what specific information should be added or updated in the profile while preserving everything else."""</span></span>
<span id="cb8-59"></span>
<span id="cb8-60">MEMORY_UPDATE_INSTRUCTIONS_REINFORCEMENT <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-61"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">Remember:</span></span>
<span id="cb8-62"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- NEVER overwrite the entire profile</span></span>
<span id="cb8-63"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- ONLY make targeted additions or changes based on explicit feedback</span></span>
<span id="cb8-64"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- PRESERVE all existing information not directly contradicted</span></span>
<span id="cb8-65"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">- Output the complete updated profile as a string</span></span>
<span id="cb8-66"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span></code></pre></div></div>
<p>Update Memory function, notably - this uses structured output to do the updating</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> UserPreferences(BaseModel):</span>
<span id="cb9-2">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""User preferences."""</span></span>
<span id="cb9-3">    preferences: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb9-4">    justification: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb9-5"></span>
<span id="cb9-6"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> update_memory(store, namespace, messages):</span>
<span id="cb9-7">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Update memory profile in the store.</span></span>
<span id="cb9-8"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    </span></span>
<span id="cb9-9"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    Args:</span></span>
<span id="cb9-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        store: LangGraph BaseStore instance to update memory</span></span>
<span id="cb9-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        namespace: Tuple defining the memory namespace, e.g. ("email_assistant", "triage_preferences")</span></span>
<span id="cb9-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">        messages: List of messages to update the memory with</span></span>
<span id="cb9-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">    """</span></span>
<span id="cb9-14"></span>
<span id="cb9-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get the existing memory</span></span>
<span id="cb9-16">    user_preferences <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> store.get(namespace, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user_preferences"</span>)</span>
<span id="cb9-17"></span>
<span id="cb9-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Update the memory</span></span>
<span id="cb9-19">    llm <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> init_chat_model(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"openai:gpt-4.1"</span>, temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="fl" style="color: #AD0000;
background-color: null;
font-style: inherit;">0.0</span>).with_structured_output(UserPreferences)</span>
<span id="cb9-20">    result <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> llm.invoke(</span>
<span id="cb9-21">        [</span>
<span id="cb9-22">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: MEMORY_UPDATE_INSTRUCTIONS.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">format</span>(current_profile<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>user_preferences.value, namespace<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>namespace)},</span>
<span id="cb9-23">            {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"role"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"content"</span>: <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Think carefully and update the memory profile based upon these user messages:"</span>}</span>
<span id="cb9-24">        ] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> messages</span>
<span id="cb9-25">    )</span>
<span id="cb9-26">    </span>
<span id="cb9-27">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Save the updated memory to the store</span></span>
<span id="cb9-28">    store.put(namespace, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user_preferences"</span>, result.preferences)</span></code></pre></div></div>
<p>The triage function needs to be updated according to WHEN to update the user preferences</p>
<ul>
<li>Gave feedback to reply to this email –&gt; update the preferences accordingly</li>
<li>Ignore email even when it was classified as notify –&gt; update the preferences accordingly</li>
<li>If the user edits the email written by the AI –&gt; update the writing email preferences</li>
</ul>


</section>

 ]]></description>
  <category>ai</category>
  <category>events</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-05-13-langchain-interrupt-day-1/</guid>
  <pubDate>Wed, 14 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Summary of Karpathy’s Deep Dive into LLMs like ChatGPT</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-02-24-karpathy-deep-dive-llms/</link>
  <description><![CDATA[ 




<p>I’ve been experimeting with writing CLI utilities to fetch and summarize YouTube videos. This is primarily for personal use. <del>May open source the CLI in the future</del>. The CLI is called <a href="https://github.com/lawwu/yt-transcript">yt-transcript</a>. The model I used was <code>gpt-4o-mini</code>. The summary of Andrej Karpathy’s Deep Dive into LLMs video is below:</p>
<section id="deep-dive-into-llms-like-chatgpt" class="level1">
<h1>Deep Dive into LLMs like ChatGPT</h1>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/7xTGNNLPyMI" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
<section id="summary" class="level2">
<h2 class="anchored" data-anchor-id="summary">Summary</h2>
<section id="introduction-00000" class="level3">
<h3 class="anchored" data-anchor-id="introduction-00000"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=0">introduction</a> (0:00:00)</h3>
<p>In this video, Andrej Karpathy aims to provide a comprehensive introduction to large language models like ChatGPT, making it accessible for a general audience. He plans to explore how these models work, what users should input, and the nature of the responses generated. Karpathy will discuss the building process of such models while also addressing their strengths, weaknesses, and cognitive psychological implications.</p>
</section>
<section id="pretraining-data-internet-00100" class="level3">
<h3 class="anchored" data-anchor-id="pretraining-data-internet-00100"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=60">pretraining data (internet)</a> (0:01:00)</h3>
<p>The pre-training stage for large language models (LLMs) involves downloading and processing vast amounts of text data from the internet, primarily sourced from datasets like Common Crawl. This process includes multiple filtering stages to ensure high-quality and diverse content, such as removing undesirable URLs, extracting text from raw HTML, and filtering for language and personally identifiable information (PII). The resulting curated dataset, like the Fine Web dataset, typically amounts to around 44 terabytes of text, forming the foundation for training neural networks to understand and generate human-like text.</p>
</section>
<section id="tokenization-00747" class="level3">
<h3 class="anchored" data-anchor-id="tokenization-00747"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=467">tokenization</a> (0:07:47)</h3>
<p>In the tokenization process for neural networks like ChatGPT, text is represented as a one-dimensional sequence of symbols. To optimize this representation, raw text is encoded into a finite set of symbols, with techniques like byte pair encoding reducing sequence length while increasing vocabulary size. This allows models, such as GPT-4, to utilize around 100,000 unique tokens. Tokenization transforms text into these symbols, enabling efficient processing by the model.</p>
</section>
<section id="neural-network-io-01427" class="level3">
<h3 class="anchored" data-anchor-id="neural-network-io-01427"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=867">neural network I/O</a> (0:14:27)</h3>
<p>The section discusses the process of transforming a large dataset of text into tokens, highlighting that it consists of about 15 trillion tokens represented as unique IDs. It explains how neural networks are trained to predict the next token in a sequence using context windows of variable lengths, typically ranging up to 8,000 tokens. The neural network outputs probabilities for the next token, which are initially random, and through a mathematical updating process, these probabilities are adjusted to better match the actual sequences in the training data. This training occurs in parallel across multiple windows and tokens to ensure consistent predictions aligned with the statistical patterns of the dataset.</p>
</section>
<section id="neural-network-internals-02011" class="level3">
<h3 class="anchored" data-anchor-id="neural-network-internals-02011"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=1211">neural network internals</a> (0:20:11)</h3>
<p>This section delves into the internals of neural networks, particularly focusing on Transformers, which process sequences of tokens using billions of parameters. Initially, these parameters are set randomly and are adjusted through training to improve prediction accuracy based on training data. The mathematical expressions used in these networks, while complex in scale, involve simple operations like multiplication and addition to transform inputs into outputs. The section emphasizes that understanding the general structure and function of these networks is more important than the intricate mathematical details.</p>
</section>
<section id="inference-02601" class="level3">
<h3 class="anchored" data-anchor-id="inference-02601"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=1561">inference</a> (0:26:01)</h3>
<p>Inference is the process of generating new data from a trained neural network by predicting the next token based on a probability distribution derived from the model’s internalized patterns. This involves sampling tokens sequentially, which can sometimes reproduce sequences from the training data but often results in unique combinations. The process is stochastic, meaning the generated output varies with each inference due to the random nature of token sampling. Once a model is trained, it operates solely on inference, using fixed parameters to complete token sequences during interactions, such as in ChatGPT.</p>
</section>
<section id="gpt-2-training-and-inference-03109" class="level3">
<h3 class="anchored" data-anchor-id="gpt-2-training-and-inference-03109"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=1869">GPT-2: training and inference</a> (0:31:09)</h3>
<p>The section discusses GPT-2, the second iteration of OpenAI’s generative pre-trained transformer models, highlighting its significance as a precursor to modern language models like GPT-4. GPT-2, launched in 2019, featured 1.6 billion parameters and was trained on approximately 100 billion tokens, a relatively small dataset by today’s standards. The costs and efficiency of training such models have significantly improved due to advancements in hardware and better data processing techniques. The training process involves updating the model’s parameters to reduce loss and improve token prediction, which requires powerful GPUs running in cloud data centers.</p>
</section>
<section id="llama-3.1-base-model-inference-04252" class="level3">
<h3 class="anchored" data-anchor-id="llama-3.1-base-model-inference-04252"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=2572">Llama 3.1 base model inference</a> (0:42:52)</h3>
<p>The section discusses the concept of base models in language learning models (LLMs), specifically focusing on Llama 3.1, a 405 billion parameter model trained on extensive data. Base models serve as token simulators and are not inherently useful for interactive tasks, as they generate text based on statistical patterns from training data. The section also highlights the importance of prompt design in eliciting useful responses from base models and demonstrates how clever prompting can simulate an assistant-like behavior, even without the full capabilities of a trained assistant model.</p>
</section>
<section id="pretraining-to-post-training-05923" class="level3">
<h3 class="anchored" data-anchor-id="pretraining-to-post-training-05923"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=3563">pretraining to post-training</a> (0:59:23)</h3>
<p>In this section, the video discusses the two main stages of training language models for assistant applications, focusing on pre-training and post-training. Pre-training involves creating a base model by predicting token sequences from internet documents, resulting in a simulator that generates text similar to online content. The subsequent post-training stage, which is less computationally intensive, is crucial for refining the model to provide accurate answers to user questions, transforming it from a document generator into a functional assistant.</p>
</section>
<section id="post-training-data-conversations-10106" class="level3">
<h3 class="anchored" data-anchor-id="post-training-data-conversations-10106"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=3666">post-training data (conversations)</a> (1:01:06)</h3>
<p>This section discusses the post-training phase of language models, focusing on how they learn to handle multi-turn conversations through datasets created by human labelers. The assistant’s responses are shaped by examples of ideal interactions, which are compiled and used to fine-tune the model. The process involves converting conversations into token sequences for training, allowing the model to generate responses based on statistical patterns learned from the data. Ultimately, the assistant’s behavior mimics that of skilled human labelers, providing responses aligned with the training data rather than representing a distinct AI intelligence.</p>
</section>
<section id="hallucinations-tool-use-knowledgeworking-memory-12032" class="level3">
<h3 class="anchored" data-anchor-id="hallucinations-tool-use-knowledgeworking-memory-12032"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=4832">hallucinations, tool use, knowledge/working memory</a> (1:20:32)</h3>
<p>The video discusses the cognitive effects of training large language models (LLMs) like ChatGPT, focusing on issues such as hallucinations, where models fabricate information due to their statistical nature. To mitigate these hallucinations, one approach is to include training data that teaches models when to express uncertainty. Additionally, models can be equipped with tools, such as web search, allowing them to access current information and improve their responses, akin to refreshing working memory. This dual strategy enhances factual accuracy and reduces the occurrence of false claims by enabling LLMs to either admit ignorance or seek information when needed.</p>
</section>
<section id="knowledge-of-self-14146" class="level3">
<h3 class="anchored" data-anchor-id="knowledge-of-self-14146"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=6106">knowledge of self</a> (1:41:46)</h3>
<p>The section discusses the concept of “knowledge of self” in large language models (LLMs) like ChatGPT, emphasizing that these models lack a persistent identity or self-awareness. When asked about their origins, LLMs generate answers based on statistical patterns from their training data, often leading to fabricated responses. Developers can influence how models respond to such questions by including hardcoded prompts or system messages during fine-tuning, but fundamentally, the models do not possess a true sense of self as humans do.</p>
</section>
<section id="models-need-tokens-to-think-14656" class="level3">
<h3 class="anchored" data-anchor-id="models-need-tokens-to-think-14656"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=6416">models need tokens to think</a> (1:46:56)</h3>
<p>In this section, Andrej Karpathy emphasizes the importance of structuring prompts for language models (LLMs) to effectively distribute computational tasks across multiple tokens. He illustrates this with examples of simple math problems, highlighting that models perform better when they can generate intermediate results rather than attempting to compute answers in a single token. He also advises using code as a tool for complex tasks, as it provides more reliable results than relying on the model’s mental arithmetic, especially for tasks like counting, which LLMs struggle with.</p>
</section>
<section id="tokenization-revisited-models-struggle-with-spelling-20111" class="level3">
<h3 class="anchored" data-anchor-id="tokenization-revisited-models-struggle-with-spelling-20111"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=7271">tokenization revisited: models struggle with spelling</a> (2:01:11)</h3>
<p>The video discusses the limitations of language models like ChatGPT, particularly regarding spelling tasks due to their reliance on tokenization rather than individual characters. This leads to difficulties in performing simple character-level tasks, such as extracting every third character from a string. The models also struggle with counting, as illustrated by their past inaccuracies in determining the number of ’R’s in the word “strawberry.” Overall, the section highlights the cognitive deficits of these models and the challenges posed by their token-based processing.</p>
</section>
<section id="jagged-intelligence-20453" class="level3">
<h3 class="anchored" data-anchor-id="jagged-intelligence-20453"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=7493">jagged intelligence</a> (2:04:53)</h3>
<p>In this section, the speaker discusses the inconsistencies and unexpected shortcomings of large language models (LLMs) like ChatGPT, particularly their struggle with simple questions despite excelling at complex problems. An example is given where the model incorrectly evaluates the numerical comparison of 9.11 and 9.9, highlighting a puzzling cognitive distraction linked to Bible verse markers. The speaker emphasizes that while LLMs are powerful tools, they are not fully reliable and should be used cautiously rather than as definitive sources of truth.</p>
</section>
<section id="supervised-finetuning-to-reinforcement-learning-20728" class="level3">
<h3 class="anchored" data-anchor-id="supervised-finetuning-to-reinforcement-learning-20728"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=7648">supervised finetuning to reinforcement learning</a> (2:07:28)</h3>
<p>This section discusses the training stages of large language models, emphasizing the transition from pre-training on internet documents to supervised fine-tuning with curated human conversations. It highlights the importance of creating a diverse dataset of prompts and ideal responses through human curation and the use of language models. The discussion then shifts to the final stage of training, reinforcement learning, which is likened to the learning process in school, where models practice problem-solving using background knowledge and expert imitation to refine their skills.</p>
</section>
<section id="reinforcement-learning-21442" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning-21442"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=8082">reinforcement learning</a> (2:14:42)</h3>
<p>The section discusses the challenges of annotating solutions for large language models (LLMs) like ChatGPT, emphasizing the differences in cognition between humans and LLMs. It highlights how human labelers may struggle to determine the best token sequences for problem-solving, leading to inefficiencies. The reinforcement learning (RL) process is introduced as a method for LLMs to explore and refine their own solutions through trial and error, ultimately allowing the model to learn effective token sequences independently rather than relying solely on human-generated examples. This iterative learning process is likened to how children practice and learn problem-solving.</p>
</section>
<section id="deepseek-r1-22747" class="level3">
<h3 class="anchored" data-anchor-id="deepseek-r1-22747"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=8867">DeepSeek-R1</a> (2:27:47)</h3>
<p>The video discusses the evolution of large language models (LLMs), emphasizing the significance of reinforcement learning (RL) in fine-tuning compared to the more established stages of pre-training and supervised fine-tuning. The recent DeepSeek R1 paper highlights how RL can enhance a model’s reasoning capabilities, enabling it to solve mathematical problems more accurately by employing cognitive strategies like re-evaluating steps and exploring different perspectives. This emergent thinking process leads to longer, more detailed responses, showcasing the model’s ability to discover effective problem-solving techniques independently. The video also compares the performance of DeepSeek’s reasoning model to other LLMs, noting that while many mainstream models primarily utilize supervised fine-tuning, there are emerging options that incorporate RL for advanced reasoning tasks.</p>
</section>
<section id="alphago-24207" class="level3">
<h3 class="anchored" data-anchor-id="alphago-24207"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=9727">AlphaGo</a> (2:42:07)</h3>
<p>The section discusses the power of reinforcement learning demonstrated by DeepMind’s AlphaGo, which learned to play Go better than human experts by playing against itself and discovering unique strategies, such as the famous “move 37.” Unlike supervised learning, which only imitates human performance, reinforcement learning allows the system to explore a wider range of solutions and potentially develop new strategies beyond human comprehension. The implications for large language models (LLMs) are significant, suggesting that with diverse problems and environments, LLMs could similarly discover novel reasoning methods or even new languages that enhance their problem-solving capabilities.</p>
</section>
<section id="reinforcement-learning-from-human-feedback-rlhf-24826" class="level3">
<h3 class="anchored" data-anchor-id="reinforcement-learning-from-human-feedback-rlhf-24826"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=10106">reinforcement learning from human feedback (RLHF)</a> (2:48:26)</h3>
<p>The section discusses reinforcement learning from human feedback (RLHF) and its application in unverifiable domains, such as creative writing, where scoring solutions is challenging. Instead of relying on extensive human evaluations, RLHF uses a reward model trained to simulate human preferences, allowing for efficient reinforcement learning without requiring infinite human input. While RLHF improves model performance, it has limitations, including the risk of the model gaming the reward system, making it less reliable than traditional reinforcement learning methods. Ultimately, RLHF is seen as a useful but imperfect enhancement to model training.</p>
</section>
<section id="preview-of-things-to-come-30939" class="level3">
<h3 class="anchored" data-anchor-id="preview-of-things-to-come-30939"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=11379">preview of things to come</a> (3:09:39)</h3>
<p>Future language models (LLMs) like ChatGPT are expected to become multimodal, capable of processing text, audio, and images natively, enabling more natural interactions. They will evolve into agents that can perform long-running tasks with human supervision, improving their ability to manage complex jobs over time. Additionally, these models will become more pervasive, integrating seamlessly into various tools and potentially taking actions on users’ behalf. Ongoing research is needed to enhance their learning capabilities, particularly for handling extensive context windows in multimodal tasks.</p>
</section>
<section id="keeping-track-of-llms-31515" class="level3">
<h3 class="anchored" data-anchor-id="keeping-track-of-llms-31515"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=11715">keeping track of LLMs</a> (3:15:15)</h3>
<p>In this section, Andrej Karpathy shares three key resources for staying updated on LLMs. He highlights El Marina, an LLM leaderboard that ranks models based on human comparisons, noting that some models, like Deep Seek and Llama, offer open weights. He also recommends the AI News newsletter for its comprehensive coverage of AI developments and suggests following trusted individuals on X (formerly Twitter) for real-time updates. Karpathy emphasizes the importance of testing different models to find the best fit for specific tasks.</p>
</section>
<section id="where-to-find-llms-31834" class="level3">
<h3 class="anchored" data-anchor-id="where-to-find-llms-31834"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=11914">where to find LLMs</a> (3:18:34)</h3>
<p>The video discusses where to find and use various large language models (LLMs). Proprietary models can be accessed via their respective provider websites, such as OpenAI and Google. For open-weight models, platforms like Together.AI allow users to interact with various models, while base models can often be found on Hyperbolic. Additionally, smaller distilled models can be run locally on personal computers using applications like LM Studio, despite its interface challenges.</p>
</section>
<section id="grand-summary-32146" class="level3">
<h3 class="anchored" data-anchor-id="grand-summary-32146"><a href="https://youtube.com/watch?v=7xTGNNLPyMI&amp;t=12106">grand summary</a> (3:21:46)</h3>
<p>The video discusses the inner workings of language models like ChatGPT, explaining how user queries are processed as token sequences and how the models generate responses. It highlights the two main stages of training: pre-training for knowledge acquisition and supervised fine-tuning for developing response behavior through human data curation. Additionally, the video touches on the differences between standard models and those using reinforcement learning, suggesting that while the latter shows promise for problem-solving, they still have limitations and should be used as tools with caution. Overall, the narrator expresses excitement about the potential of these models while emphasizing the importance of verifying their outputs.</p>


</section>
</section>
</section>

 ]]></description>
  <category>ai</category>
  <category>summary</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-02-24-karpathy-deep-dive-llms/</guid>
  <pubDate>Mon, 24 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Second Half-Marathon in the Books</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2025-02-02-second-half-marathon/</link>
  <description><![CDATA[ 




<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-02-02-second-half-marathon/finish_pic.jpg" class="img-fluid figure-img" style="width:50.0%"></p>
<figcaption>Finish Line Picture!</figcaption>
</figure>
</div>
<p>Second half-marathon complete (<a href="https://www.strava.com/activities/13521918538">Strava</a>)! Goals for this race at Surf City 2025 was just to 1) not get injured and 2) beat my first HM time of 1:49. Felt like the conditions were perfect in terms of the weather, how the body felt and having other runners to run with at certain points. Thankful to have achieved both those goals! By God’s grace was able to PR and run 1:42.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2025-02-02-second-half-marathon/strava_hm.png" class="img-fluid figure-img"></p>
<figcaption>Surf City HM - Strava</figcaption>
</figure>
</div>
<p>Strategy was to go 8:00-8:05 for the first 10 miles. But I started following people who were going around 7:50-7:55. Felt strong and just raced the last 5k. The ending was a little sketchy because the 5k walkers were in our path so lot of weaving in and out.</p>
<p>I did prefer the Long Beach Half. Better course (closer to the water) and better organized.</p>
<p>My chip time <a href="https://results2.xacte.com/#/e/2571/searchable/7288">didn’t register</a> :(</p>
<section id="marathon-build-details" class="level2">
<h2 class="anchored" data-anchor-id="marathon-build-details">Marathon Build Details</h2>
<p>This build started 10/17/24 and ended 2/2/2024 at Surf City:</p>
<ul>
<li>16 weeks</li>
<li>484 total miles</li>
<li>28.6 miles on average per week</li>
<li>80.2 total hours</li>
<li>4.84 hours per week</li>
<li>97 runs</li>
<li>1 race, 13 long, 26 workouts, 58 easy</li>
<li>Conversational pace improvement - 9:42/mi to 9:09/mi</li>
</ul>
</section>
<section id="thoughts-on-runna" class="level2">
<h2 class="anchored" data-anchor-id="thoughts-on-runna">Thoughts on Runna</h2>
<p>I used Runna for the 16 week training plan and I really liked it. It pushed me pretty hard. There were many workouts I didn’t think I’d be able to do. Runna also adapted the paces according to how I performed during the speed work. I thought their estimates fluctuated too quickly. The VDOT estimated paces were more in-line. For example the 5k time-trial I did in December gave a VDOT estimated HM time of 1:44 which was really close. The training plan had a variety of runs (for easy, workouts and long) that kept things interesting. Although now that I’ve gone through this full plan once, I likely can use ChatGPT to create plans for myself now. Runna recently allowed syncing workouts using the native Apple Workouts app which was really nice.</p>


</section>

 ]]></description>
  <category>running</category>
  <guid>https://lawwu.github.io/blog.html/posts/2025-02-02-second-half-marathon/</guid>
  <pubDate>Sun, 02 Feb 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Running Lessons</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/</link>
  <description><![CDATA[ 




<p>I never considered myself a runner. I actually never enjoyed the activity of running. I usually didn’t look forward to it. I would occassionally still do it because I knew it was good for me. I also usually did enjoy how I felt afterwards, feeling like I put in some work, got my heart pumping and it was generally healthy. Over the past 5 months though, I’ve come to really enjoy running. I’ll share some of the things I’ve learned along the way about running and life.</p>
<section id="why-i-started-running" class="level2">
<h2 class="anchored" data-anchor-id="why-i-started-running">Why I Started Running</h2>
<p>On May 4th, I went for a 2 mile run. Little did I know that be the first run of many more runs over the next 5 months.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/first_run.png" class="img-fluid figure-img" width="500"></p>
<figcaption>First Run in May 2024</figcaption>
</figure>
</div>
<p>As noted in the image above, I was motivated to run after reading the book <a href="https://amzn.to/3zVzvqC">Outlive by Peter Attia</a>. In his chapter on exercise, he talks about cardiovascular health and strength training as two key necessary things you need to do to stay healthy. That’s not anything I haven’t heard before. But what triggered something in me was this graph in the book. The metric plotted is VO2 max which measures how much oxygen your body can use during intense exercise.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/vo2_max.png" class="img-fluid figure-img" width="500"></p>
<figcaption>VO2 Max Declines with Age</figcaption>
</figure>
</div>
<p>One of the main arguments he makes in the book is if you want to do normal activities in your 60s, 70s, and 80s+, you need to train for that. Everyone’s VO2 max will decline over as they get older. However, the average person starts with a lower VO2 max than someone with above average fitness. And you need a certain amount of VO2 max (aka fitness) to do basic things like walk up hill, lift/carry heavy objects or run. I do want to do normal activities when God-willing my kids get older and I have grandchildren. I do want to be able to lift and carry my grandchildren and run after them. Imagining that future really did flip a switch in me where I became very motivated to take my health more seriously and so I went on that 2 mile run.</p>
<p>I chose running as my exercise of choice because I found it to be the best-bang-for-your-buck form of exercise. I could go out for a couple mile run and be done in 20-30 minutes. A 20-30 bike ride didn’t really feel like much exercise. I didn’t enjoy swimming. I also had to give up basketball because of injuries. Praise God I could still run so I wanted to take advantage of that.</p>
</section>
<section id="consistently-running" class="level2">
<h2 class="anchored" data-anchor-id="consistently-running">Consistently Running</h2>
<p>I slowly built up mileage over the coming weeks, 5 miles that first week to eventually 10 per week and then 15. You can see how infrequently I ran in the proceeding months. There are some sparse weeks there!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/weekly_miles_first_month.png" class="img-fluid figure-img" width="450"></p>
<figcaption>Weekly Miles - First Month</figcaption>
</figure>
</div>
<p>In late June, I decided to sign up for a 10k race because a friend told me about one. A couple friends and I signed up for it (thanks for running with me Andy &amp; Shannon!). I thought running a race would be a good experience. And it was! There was a lot of adrenaline from the crowd and my kids even got to run the 1 mile “race” which they were excited about. I set a PR of 58:00 at this 10k (9:20 mins/mile).</p>
<p>During this time, I knew some of my friends were already planning on doing the Long Beach Half-Marathon in October. When they were talking about a few months back, my thought was “No way.” But after running more consistently, I was on the fence in June. I said I was 50/50 in our group chat. The day after running the 10k, I went for it and signed up for the half.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/signed_up.png" class="img-fluid figure-img" width="450"></p>
<figcaption>Signed Up!</figcaption>
</figure>
</div>
<p>I started Nike Run Club’s 14 week half-marathon plan since the timing was perfect and I had heard good things about their Guided Runs. Well, fast forward 5 months and on Oct 6, I ran the Long Beach Half-Marathon in 1:49:15 (8:20 mins/mile). It was a joy doing this with some brothers and sisters from church and seeing a bunch of friends trying to get healthier and make fitness a regular part of their lives.</p>
<p>People had recommended setting 3 goals: a bare minimum goal, a reachable goal and a stretch goal. So I did.</p>
<ul>
<li><p>Bare Minimum Goal: Don’t get hurt</p></li>
<li><p>Reachable Goal: Finish the race</p></li>
<li><p>Stretch Goal: Sub 2 hours</p></li>
</ul>
<p>After training for something for 3+ months and meeting my stretch goal, it’s hard to explain how happy I was crossing this finish line.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/lb_hm_finish_line.JPG" class="img-fluid figure-img"></p>
<figcaption>Long Beach Half-Marathon finish line</figcaption>
</figure>
</div>
<p>Seeing my wife and kids at the finish line cheering me on was so awesome!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/lb_hm_finish.jpg" class="img-fluid figure-img" width="2000"></p>
<figcaption>Long Beach Half-Marathon finish</figcaption>
</figure>
</div>
<p>I also downloaded some of the GPX data from Strava for some of my friends and I and animated it using <a href="https://gpx-animator.app/">GPX Animator</a>.</p>
<div class="quarto-video ratio ratio-16x9"><iframe data-external="1" src="https://www.youtube.com/embed/_Ntj5AeAQSk" title="" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></div>
</section>
<section id="things-ive-learned-about-running" class="level2">
<h2 class="anchored" data-anchor-id="things-ive-learned-about-running">Things I’ve Learned about Running</h2>
<section id="types-of-runs" class="level3">
<h3 class="anchored" data-anchor-id="types-of-runs">Types of Runs</h3>
<p>Easy Running: Most runs should be “easy.” And by most, this is 80% of your total miles! Coming from basketball I was used to running fast, quick bursts. So when I would go for “runs” I would be going at a moderate to fast pace. I would quickly tire because my aerobic fitness was not very good and it just wouldn’t be pleasant. Reading a little about running and other endurance spots, you quickly learn a common recommendation “run easy” and “run at a conversational pace” and “run in Zone 2” to build your “aerobic base.” I didn’t fully understand what all of this meant yet but I just took their advice and started running easy. It did feel abnormally slow because I wasn’t used it. One of the main benefits is you can run for longer at this slower pace, it’s more enjoyable and it’s scientifically proven to train your mitochondria (<a href="https://chatgpt.com/share/670cae86-c538-8011-b200-5a292ae6ca52">I think?</a>). Stephen Seiler has a <a href="https://www.youtube.com/watch?v=MALsI0mJ09I&amp;ab_channel=TEDxTalks">TED talk</a> where he explains the above idea in about 15 minutes. One of the slides shows the percentage of time spent in different training zones. You can see even for professional athletes, they spend 80% of their time in this “Low/Easy Intensity” area.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/stephen_seiler_training_sessions.png" class="img-fluid figure-img" width="700"></p>
<figcaption>% of training sessions</figcaption>
</figure>
</div>
<p>The other 20% of the running should be speed work. I used the Nike Run Club (NRC) app’s <a href="https://www.nike.com/running/half-marathon-training-plan">half-marathon training plan</a>. Every week there were two recovery runs (1 15 minute run basically introducing the runs that week, another longer recovery run), two speed runs and 1 long run. The speed runs varied from intervals, tempo, to fartleks. I got to learn what all of these different runs were. The NRC app was particularly helpful for these runs because it guides you - when to start and stop a given interval and what type of effort to give at each interval (4-5 easy warmup, 6 for a 10k pace, 7-8 for a 5k pace, 8-9 for a mile pace and 10 for all out of ‘celebration’ pace).</p>
<p>You run out of energy at around 90 minutes. I remember one of my first long runs (Strava link) where I went past 60 minutes, I didn’t have any water or nutrition on me. It felt really terrible at around 80 minutes. I think my heart rate even peaked.</p>
</section>
<section id="gear" class="level3">
<h3 class="anchored" data-anchor-id="gear">Gear</h3>
<ul>
<li><p>Shoes:</p>
<ul>
<li>First pair with <a href="https://amzn.to/3A0BIkz">Brooks Ghost</a>. I got Ghost 15s but only Ghost 16s are available now. My friend sent me this comic that was pretty accurate why I picked them:</li>
</ul></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/brooks_ghost_comic.png" class="img-fluid figure-img" width="500"></p>
<figcaption>Brooks Ghost Comic</figcaption>
</figure>
</div>
<ul>
<li><p>Second pair was a <a href="https://amzn.to/4eU2LwU">Asics Novablast 4</a>.</p></li>
<li><p>I also started a 6 month membership to <a href="https://www.roadrunnersports.com/vip/rewards">Road Runner Sports</a> for $1.99. This allows you to buy shoes, run with them and return them if you do not like them. I wound up doing this a couple times for shoes that felt okay in store but for various reasons I didn’t like when going on an actual run. Not sure I’ll keep this membership after the trial though.</p></li>
<li><p>Shorts:</p>
<ul>
<li><p><a href="https://amzn.to/3zNfwdJ">Northyard 5-inch shorts</a> - Bought a few of the cheapest / well-reviewed shorts on Amazon.</p></li>
<li><p><a href="https://amzn.to/3BFeHEm">BALEAF Running Shirt</a> - Similar search, bought a few.</p></li>
</ul></li>
<li><p>Running Belt:</p>
<ul>
<li><a href="https://amzn.to/4f05swK">Spibelt</a> - Running belt to hold phone, keys.</li>
</ul></li>
<li><p>Hydration Vest:</p>
<ul>
<li><a href="https://amzn.to/4h0NiNd">Salomon ADV Skin 12</a> - For longer runs, this vest was very useful to carry water, gels, phone. I got a medium.</li>
</ul></li>
<li><p>Nutrition:</p>
<ul>
<li><p><a href="https://amzn.to/4h0NiNd">Huma Chia Energy Gels</a> - For longer runs, I ate these. I haven’t tried other gels yet but I liked how these tasted and just stuck with them.</p></li>
<li><p><a href="https://amzn.to/4dFv0hC">BODYARMOR Flash IV Electrolyte</a> - Also for longer runs. This is a 6 pack from Amazon ($1/pack) which is honestly a little egregious for salt. In theory you can make your own. I bought this <a href="https://www.costco.com/BODYARMOR-Flash-I.V.-Hydration-Booster,-30-Individual-Serving-Stick-Packs,-Variety-Pack.product.1838221.html">30 pack</a> from Costco that was a little cheaper.</p></li>
</ul></li>
<li><p>GPS Watch: Apple Watch - I already had an Apple Watch so I just used it to track my runs using the native Fitness App.</p>
<ul>
<li>When starting an activity, there’s usually a count down, you can double tap to start it immediately</li>
<li>When running, you can double tap the screen to start a new segment. This is useful when you are doing interval runs.</li>
</ul></li>
<li><p>iOS Apps:</p>
<ul>
<li>Fitness: Apple’s native fitness app. Can see detailed information on your workout. This gets really granular because GPS watches these days measure cadence, stride length and vertical oscillation.</li>
<li>Health: Seeing heart health data like Cardio Fitness (VO2 Max) and resting heart rate trend in better directions was so motivating!</li>
<li>HealthFit: I used this to import all of my previous Apple Fitness data into Strava</li>
<li>WorkOutDoors: More customizable fitness app. For example you can configure interval runs, total times for each interval, target paces for each interval and the app will warn you when you are outside of your target pace (too fast and too slow). This app makes your Apple Watch behave more like a Garmin.</li>
<li>Strava: Fun and somewhat motivating to see how friends are staying active. Being a sucker for data, I enjoy seeing Strava’s global heatmaps by activity type and also the user created segments and receiving random rewards like “You set your best 2nd mile time!” Side note: I find it pretty amazing that Strava has built a business on monetizing fitness data that users are giving them.</li>
</ul></li>
</ul>
<p>These are the Strava weekly heatmaps. It’s cool thinking about all the people that went running and/or biking the last week to make this heatmap.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/heatmap_ride.png" class="img-fluid figure-img" width="700"></p>
<figcaption>Heatmap - Ride</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/heatmap_run.png" class="img-fluid figure-img" width="700"></p>
<figcaption>Heatmap - Run</figcaption>
</figure>
</div>
</section>
<section id="racing" class="level3">
<h3 class="anchored" data-anchor-id="racing">Racing</h3>
<ul>
<li>Race strategy: Treat the first 75% of the race like a “warmup” for the last 25% of the race. Once you get to the last quarter, you can see how much you have left in the tank.</li>
<li>It’s must harder to go from the beginning of a training block to the starting line of a race than going from the starting line of a race to the finish line. So many things can go wrong over a 14-16 week training block, you can get sick, injured, or your kids can get sick. All kinds of things can come up.</li>
</ul>
</section>
</section>
<section id="things-ive-learned-in-general-and-about-myself" class="level2">
<h2 class="anchored" data-anchor-id="things-ive-learned-in-general-and-about-myself">Things I’ve Learned in General and about Myself</h2>
<ul>
<li>People Can Change: Running a marathon (or half) was never on my bucket list. I never thought I could even run this distance let alone do it and enjoy it and enjoy the whole training process. I grew up playing basketball which requires a totally different set of muscles. You need short bursts and fast twitch muscles. I still have yet to meet a basketball player who likes long distance running.</li>
<li>The human body has an amazing ability to be trained</li>
<li>Running regularly has given more time to think, pray and listen to audiobooks. It’s also given me more energy throughout the day.</li>
<li>The running community is generally positive. Nowadays it’s pretty easy to form groups around a share interest. I’ve found the running communities to be quite encouraging. It doesn’t matter what pace you are running.</li>
</ul>
</section>
<section id="things-ive-learned-about-christian-life" class="level2">
<h2 class="anchored" data-anchor-id="things-ive-learned-about-christian-life">Things I’ve Learned about Christian Life</h2>
<p>The Bible uses many running illustrations that have become more vivid as I’ve started running more consistently:</p>
<ul>
<li><strong>Do you not know that in a race all the runners run, but only one receives the prize? So run that you may obtain it.</strong> Every athlete exercises self-control in all things. They do it to receive a perishable wreath, but we an imperishable. <strong>So I do not run aimlessly</strong>; I do not box as one beating the air. But I discipline my body and keep it under control, lest after preaching to others I myself should be disqualified. (1 Corinthians 9:24-27)</li>
<li>I have fought the good fight, <strong>I have finished the race</strong>, I have kept the faith. (2 Timothy 4:7)</li>
<li>Therefore, since we are surrounded by so great a cloud of witnesses, let us also lay aside every weight, and sin which clings so closely, and <strong>let us run with endurance the race that is set before us, looking to Jesus</strong>, the founder and perfecter of our faith, who for the joy that was set before him endured the cross, despising the shame, and is seated at the right hand of the throne of God. (Hebrews 12:1-2)</li>
</ul>
<p>From 1 Corinthians 9:24-27, we draw some parallels between physical running and spiritual running (basically Christian life):</p>
<table class="caption-top table">
<colgroup>
<col style="width: 25%">
<col style="width: 37%">
<col style="width: 37%">
</colgroup>
<thead>
<tr class="header">
<th>Aspect</th>
<th>Physical Running</th>
<th>Spiritual Running</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Purpose</td>
<td>To win a perishable prize (e.g., a medal, wreath)</td>
<td>To receive an imperishable prize (eternal life, spiritual reward, crown of glory, commendation from God)</td>
</tr>
<tr class="even">
<td>Training</td>
<td>Requires self-control and discipline in physical training</td>
<td>Requires self-control and discipline in spiritual growth and character</td>
</tr>
<tr class="odd">
<td>Goal</td>
<td>To finish the race and win, physical fitness and health</td>
<td>To live life of praise and glorifying God, aiming for eternal rewards</td>
</tr>
<tr class="even">
<td>Focus</td>
<td>Winning the race, obtaining a temporary prize</td>
<td>Living with purpose, avoiding aimlessness, and striving for spiritual growth</td>
</tr>
<tr class="odd">
<td>Effort</td>
<td>Demands physical discipline and perseverance</td>
<td>Demands spiritual discipline, avoiding complacency, and personal holiness</td>
</tr>
<tr class="even">
<td>Motivation</td>
<td>Earthly recognition and achievement</td>
<td>Eternal recognition and spiritual fulfillment</td>
</tr>
<tr class="odd">
<td>Outcome</td>
<td>A perishable, temporary reward</td>
<td>An imperishable, everlasting reward</td>
</tr>
<tr class="even">
<td>Consequence of Failure</td>
<td>Losing the race, disqualification</td>
<td>Spiritual disqualification, falling short of spiritual goals</td>
</tr>
</tbody>
</table>
<ul>
<li><strong>Don’t compare yourself to others</strong>: I’ve also seen how easy it is to compare yourself to others in running and in Christian life. It’s easy to compare your pace or weekly mileage to others and say, “I wish I ran that fast.” But everyone is different. Everyone has had differing amounts of training up to that point. Everyone’s body is different. People have different goals. I’ve found it’s better to just be inspired by what others are able to do. Then if you want to compare, compare with your previous self. How long was I able to run at a conversational pace 1 month ago? 3 months ago? In Christian life it’s also easy to compare how fast/well one is running and compare yourself to others. But similarly, everyone is on a different spiritual journey with differing spiritual backgrounds. If you want to compare, compare with your previous self. How much have I grown in things like the fruit of the Spirit since I became a Christian? How much have I grown in love of God and people?</li>
<li><strong>Self-control is so important</strong>: 1 Cor 9:25 says, “Every athlete exercises self-control in all things.” Athletes exercise self-control because it’s necessary to have good performance. Even in building a simple habit of running for 30 minutes a day, this requires self-control and discipline to find the time to do so, sleeping early to wake up early to do this (if you want to do it in the morning before your kids wake up), committing to a running plan, actually running the runs on those plans, etc. In Christian life, growing in self-control over my desires means I can better fight temptation and sinful desires and ultimately be a better instrument for noble purposes, useful to God for any good work (2 Tim 2:21).</li>
<li><strong>Don’t run aimlessly</strong>: It’s been helpful to have goals while running. Following the NRC running plan was helpful. Knowing what runs I was going to do on each day was helpful. Knowing the purpose of each run and what it was doing to my body was motivating as well. There were times I didn’t have a good idea of how far I was going to run that day. Sometimes on those days I wound up cutting my runs short because of the lack of motivation. In Christian life, it’s important to have spiritual direction. Where is God leading you? And if you have a family and especially if you are a husband, how and where are you leading your family?</li>
<li><strong>Disciplining the body</strong>: Running has helped me discipline my body. Starting off the day with something physically demanding helps set the tone for the rest of the day. Another example is running provides an outlet for me to think and pray. This helps to get my mind settled for the day ahead as well.</li>
</ul>
<p>1 Tim 4:8 says, “for while bodily training is of some value, godliness is of value in every way, as it holds promise for the present life and also for the life to come.” The Bible says bodily training is of some value! This should provide some motivation to a Christian to take exercise seriously. However the passage goes onto say that godliness is more important because it holds promise for this life and the life to come. I take this to mean our spiritual fitness and our relationship with Christ is more important to God than our physical fitness. There were times on this running journey I took running too seriously and prioritized it above the things God wanted me to prioritize like my family. So one big takeaway has been to not allow good things (like running) to supercede the best things (honoring and glorifying God).</p>
</section>
<section id="why-i-plan-to-continue-to-run" class="level2">
<h2 class="anchored" data-anchor-id="why-i-plan-to-continue-to-run">Why I plan to continue to run</h2>
<p>I started out on this running journey because I wanted to reach my 70s and 80s healthy enough to be able to do normal activities that I take for granted like walk up hill or God-willing hold my grandkids. It started with a simple 2 mile run. It’s turned into a habit now that I really enjoy where I try to run 20-30 miles a week.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/last_6_months_450_miles.jpg" class="img-fluid figure-img" width="400"></p>
<figcaption>Last 6 months of running</figcaption>
</figure>
</div>
<p>Along the way I’ve learned so much about running, myself and even Christian life. Given I’ve also had 3 major leg injuries, I thank God he’s allowed me to run these hundreds of miles these last 5 months. I’m excited to see where running takes me next.</p>


</section>

 ]]></description>
  <category>running</category>
  <category>faith</category>
  <guid>https://lawwu.github.io/blog.html/posts/2024-10-13-running-6-months/</guid>
  <pubDate>Sun, 13 Oct 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Introduction to LangGraph Tutorial</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/posts/2024-09-20-langgraph-tutorial/</link>
  <description><![CDATA[ 




<p>The LangChain team recently released the first course in their LangChain Academy called Introduction to LangGraph (<a href="https://github.com/langchain-ai/langchain-academy">repo</a>). As I’m working through it I will make some notes on what I’ve learned. Note many of these snippets were generated using Claude 3.5 Sonnet (passing a prompt and the Jupyter notebook plain text, it did a better job than <code>o1-preview</code>, surprisingly)</p>
<section id="module-2---state-and-memory" class="level2">
<h2 class="anchored" data-anchor-id="module-2---state-and-memory">Module 2 - State and Memory</h2>
<section id="lesson-2---state-reducers" class="level3">
<h3 class="anchored" data-anchor-id="lesson-2---state-reducers">Lesson 2 - State Reducers</h3>
<ul>
<li><a href="https://github.com/langchain-ai/langchain-academy/blob/8cca5e1092d01931f6aa9143ffc87d21ccd6052f/module-2/state-reducers.ipynb">Notebook</a></li>
</ul>
<p>Reducers are used to specify how state updates are performed when multiple nodes try to update the same key:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Annotated</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> operator <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> add</span>
<span id="cb1-3"></span>
<span id="cb1-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> State(TypedDict):</span>
<span id="cb1-5">    foo: Annotated[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>], add]</span></code></pre></div></div>
<p>Custom reducers can be defined to handle complex state update logic:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> reduce_list(left: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>, right: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> <span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">None</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>:</span>
<span id="cb2-2">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> left:</span>
<span id="cb2-3">        left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-4">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">not</span> right:</span>
<span id="cb2-5">        right <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> []</span>
<span id="cb2-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> left <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> right</span>
<span id="cb2-7"></span>
<span id="cb2-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CustomReducerState(TypedDict):</span>
<span id="cb2-9">    foo: Annotated[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>], reduce_list]</span></code></pre></div></div>
<p>MessagesState is a useful shortcut for working with message-based states. These two are equivalent:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Annotated</span>
<span id="cb3-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MessagesState</span>
<span id="cb3-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AnyMessage</span>
<span id="cb3-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph.message <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> add_messages</span>
<span id="cb3-5"></span>
<span id="cb3-6"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a custom TypedDict that includes a list of messages with add_messages reducer</span></span>
<span id="cb3-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> CustomMessagesState(TypedDict):</span>
<span id="cb3-8">    messages: Annotated[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">list</span>[AnyMessage], add_messages]</span>
<span id="cb3-9">    added_key_1: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb3-10">    added_key_2: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb3-11">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># etc</span></span>
<span id="cb3-12"></span>
<span id="cb3-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Use MessagesState, which includes the messages key with add_messages reducer</span></span>
<span id="cb3-14"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> ExtendedMessagesState(MessagesState):</span>
<span id="cb3-15">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add any keys needed beyond messages, which is pre-built </span></span>
<span id="cb3-16">    added_key_1: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb3-17">    added_key_2: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb3-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># etc</span></span></code></pre></div></div>
<p>The <code>add_messages</code> reducer allows appending messages to the state:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph.message <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> add_messages</span>
<span id="cb4-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AIMessage, HumanMessage</span>
<span id="cb4-3"></span>
<span id="cb4-4">new_state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> add_messages(existing_messages, new_message)</span></code></pre></div></div>
<p>Messages can be overwritten by using the same ID:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">new_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"New content"</span>, name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"User"</span>, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"existing_id"</span>)</span>
<span id="cb5-2">updated_state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> add_messages(existing_messages, new_message)</span></code></pre></div></div>
<p>Messages can be removed using <code>RemoveMessage</code>:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RemoveMessage</span>
<span id="cb6-2"></span>
<span id="cb6-3">delete_messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [RemoveMessage(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> messages_to_delete]</span>
<span id="cb6-4">updated_state <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> add_messages(existing_messages, delete_messages)</span></code></pre></div></div>
</section>
<section id="lesson-3---multiple-schemas" class="level3">
<h3 class="anchored" data-anchor-id="lesson-3---multiple-schemas">Lesson 3 - Multiple Schemas</h3>
<ul>
<li><a href="https://github.com/langchain-ai/langchain-academy/blob/8cca5e1092d01931f6aa9143ffc87d21ccd6052f/module-2/multiple-schemas.ipynb">Notebook</a></li>
<li>A graph can have multiple states. This is useful for controlling what information is shown to the user.</li>
</ul>
<p>Private State: You can pass private state between nodes that isn’t relevant for the overall graph input or output.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing_extensions <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> TypedDict</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, display</span>
<span id="cb7-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, START, END</span>
<span id="cb7-4"></span>
<span id="cb7-5"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> OverallState(TypedDict):</span>
<span id="cb7-6">    foo: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb7-7"></span>
<span id="cb7-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> PrivateState(TypedDict):</span>
<span id="cb7-9">    baz: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span></span>
<span id="cb7-10"></span>
<span id="cb7-11"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> node_1(state: OverallState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> PrivateState:</span>
<span id="cb7-12">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---Node 1---"</span>)</span>
<span id="cb7-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"baz"</span>: state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'foo'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>}</span>
<span id="cb7-14"></span>
<span id="cb7-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> node_2(state: PrivateState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> OverallState:</span>
<span id="cb7-16">    <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">print</span>(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"---Node 2---"</span>)</span>
<span id="cb7-17">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"foo"</span>: state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'baz'</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>}</span>
<span id="cb7-18"></span>
<span id="cb7-19"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Build graph</span></span>
<span id="cb7-20">builder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(OverallState)</span>
<span id="cb7-21">builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_1"</span>, node_1)</span>
<span id="cb7-22">builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_2"</span>, node_2)</span>
<span id="cb7-23"></span>
<span id="cb7-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Logic</span></span>
<span id="cb7-25">builder.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_1"</span>)</span>
<span id="cb7-26">builder.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_1"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_2"</span>)</span>
<span id="cb7-27">builder.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"node_2"</span>, END)</span>
<span id="cb7-28"></span>
<span id="cb7-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add</span></span>
<span id="cb7-30">graph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> builder.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span></code></pre></div></div>
<p>Input/Output Schema: You can define explicit input and output schemas for a graph, which is useful for constraining the input and output. Filtering: Input and output schemas perform filtering on what keys are permitted on the input and output of the graph.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> InputState(TypedDict):</span>
<span id="cb8-2">    question: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb8-3"></span>
<span id="cb8-4"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> OutputState(TypedDict):</span>
<span id="cb8-5">    answer: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb8-6"></span>
<span id="cb8-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> OverallState(TypedDict):</span>
<span id="cb8-8">    question: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb8-9">    answer: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb8-10">    notes: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb8-11"></span>
<span id="cb8-12"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> thinking_node(state: InputState):</span>
<span id="cb8-13">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bye"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"notes"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"... his is name is Lance"</span>}</span>
<span id="cb8-14"></span>
<span id="cb8-15"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> answer_node(state: OverallState) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> OutputState:</span>
<span id="cb8-16">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bye Lance"</span>}</span>
<span id="cb8-17"></span>
<span id="cb8-18">graph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(OverallState, <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">input</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>InputState, output<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OutputState)</span>
<span id="cb8-19">graph.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer_node"</span>, answer_node)</span>
<span id="cb8-20">graph.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thinking_node"</span>, thinking_node)</span>
<span id="cb8-21">graph.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thinking_node"</span>)</span>
<span id="cb8-22">graph.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thinking_node"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer_node"</span>)</span>
<span id="cb8-23">graph.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"answer_node"</span>, END)</span>
<span id="cb8-24"></span>
<span id="cb8-25">graph <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> graph.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">compile</span>()</span>
<span id="cb8-26"></span>
<span id="cb8-27"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># View</span></span>
<span id="cb8-28">display(Image(graph.get_graph().draw_mermaid_png()))</span>
<span id="cb8-29"></span>
<span id="cb8-30">graph.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"question"</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hi"</span>})</span>
<span id="cb8-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Output: {'answer': 'bye Lance'}</span></span></code></pre></div></div>
</section>
<section id="lesson-4---trim-and-filter-messages" class="level3">
<h3 class="anchored" data-anchor-id="lesson-4---trim-and-filter-messages">Lesson 4 - Trim and Filter Messages</h3>
<ul>
<li><a href="https://github.com/langchain-ai/langchain-academy/blob/8cca5e1092d01931f6aa9143ffc87d21ccd6052f/module-2/trim-filter-messages.ipynb">Notebook</a></li>
<li>You can filter messages using the <code>RemoveMessage</code> class.</li>
<li>As a use case, you can preserve the state (e.g.&nbsp;with 5 messages in the message history) but only call the LLM with the last n messages</li>
<li>You can also trim messages based on a set number of tokens using <code>trim_messages</code></li>
</ul>
<p>Filtering messages using RemoveMessage:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RemoveMessage</span>
<span id="cb9-2"></span>
<span id="cb9-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> filter_messages(state: MessagesState):</span>
<span id="cb9-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete all but the 2 most recent messages</span></span>
<span id="cb9-5">    delete_messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [RemoveMessage(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]]</span>
<span id="cb9-6">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: delete_messages}</span>
<span id="cb9-7"></span>
<span id="cb9-8">builder <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(MessagesState)</span>
<span id="cb9-9">builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"filter"</span>, filter_messages)</span>
<span id="cb9-10">builder.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat_model"</span>, chat_model_node)</span>
<span id="cb9-11">builder.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"filter"</span>)</span>
<span id="cb9-12">builder.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"filter"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat_model"</span>)</span></code></pre></div></div>
<p>Trimming messages based on token count:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> trim_messages</span>
<span id="cb10-2"></span>
<span id="cb10-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> chat_model_node(state: MessagesState):</span>
<span id="cb10-4">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> trim_messages(</span>
<span id="cb10-5">            state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>],</span>
<span id="cb10-6">            max_tokens<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">100</span>,</span>
<span id="cb10-7">            strategy<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"last"</span>,</span>
<span id="cb10-8">            token_counter<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>ChatOpenAI(model<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"gpt-4o"</span>),</span>
<span id="cb10-9">            allow_partial<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">False</span>,</span>
<span id="cb10-10">        )</span>
<span id="cb10-11">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [llm.invoke(messages)]}</span></code></pre></div></div>
</section>
<section id="lesson-5---chatbot-w-summarizing-messages-and-memory" class="level3">
<h3 class="anchored" data-anchor-id="lesson-5---chatbot-w-summarizing-messages-and-memory">Lesson 5 - Chatbot w/ Summarizing Messages and Memory</h3>
<ul>
<li>Interesting example of using the above ideas to create a chatbot that creates a running summary of messages as a way of condensing the memory.</li>
<li>You can pass a thread to the LangChain runnable and the runnable will continue the conversation from that previous state.</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MessagesState</span>
<span id="cb11-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> State(MessagesState):</span>
<span id="cb11-3">    summary: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span></span>
<span id="cb11-4"></span>
<span id="cb11-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain_core.messages <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> SystemMessage, HumanMessage, RemoveMessage</span>
<span id="cb11-6"></span>
<span id="cb11-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the logic to call the model</span></span>
<span id="cb11-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> call_model(state: State):</span>
<span id="cb11-9">    </span>
<span id="cb11-10">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Get summary if it exists</span></span>
<span id="cb11-11">    summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"summary"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>)</span>
<span id="cb11-12"></span>
<span id="cb11-13">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># If there is summary, then we add it</span></span>
<span id="cb11-14">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> summary:</span>
<span id="cb11-15">        </span>
<span id="cb11-16">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add summary to system message</span></span>
<span id="cb11-17">        system_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"Summary of conversation earlier: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>summary<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb11-18"></span>
<span id="cb11-19">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Append summary to any newer messages</span></span>
<span id="cb11-20">        messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [SystemMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>system_message)] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="cb11-21">    </span>
<span id="cb11-22">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb11-23">        messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>]</span>
<span id="cb11-24">    </span>
<span id="cb11-25">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.invoke(messages)</span>
<span id="cb11-26">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: response}</span></code></pre></div></div>
<p>Note, here we’ll use <code>RemoveMessage</code> to filter our state after we’ve produced the summary.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb12" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> summarize_conversation(state: State):</span>
<span id="cb12-2">    </span>
<span id="cb12-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># First, we get any existing summary</span></span>
<span id="cb12-4">    summary <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state.get(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"summary"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">""</span>)</span>
<span id="cb12-5"></span>
<span id="cb12-6">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create our summarization prompt </span></span>
<span id="cb12-7">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> summary:</span>
<span id="cb12-8">        </span>
<span id="cb12-9">        <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A summary already exists</span></span>
<span id="cb12-10">        summary_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> (</span>
<span id="cb12-11">            <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"This is summary of the conversation to date: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>summary<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ch" style="color: #20794D;
background-color: null;
font-style: inherit;">\n\n</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb12-12">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Extend the summary by taking into account the new messages above:"</span></span>
<span id="cb12-13">        )</span>
<span id="cb12-14">        </span>
<span id="cb12-15">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb12-16">        summary_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Create a summary of the conversation above:"</span></span>
<span id="cb12-17"></span>
<span id="cb12-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Add prompt to our history</span></span>
<span id="cb12-19">    messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">+</span> [HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>summary_message)]</span>
<span id="cb12-20">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.invoke(messages)</span>
<span id="cb12-21">    </span>
<span id="cb12-22">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Delete all but the 2 most recent messages</span></span>
<span id="cb12-23">    delete_messages <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [RemoveMessage(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span><span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>m.<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">id</span>) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> state[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>][:<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">2</span>]]</span>
<span id="cb12-24">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"summary"</span>: response.content, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: delete_messages}</span></code></pre></div></div>
<p>Adding memory:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb13" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> IPython.display <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Image, display</span>
<span id="cb13-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.checkpoint.memory <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> MemorySaver</span>
<span id="cb13-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langgraph.graph <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StateGraph, START</span>
<span id="cb13-4"></span>
<span id="cb13-5"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define a new graph</span></span>
<span id="cb13-6">workflow <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StateGraph(State)</span>
<span id="cb13-7">workflow.add_node(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversation"</span>, call_model)</span>
<span id="cb13-8">workflow.add_node(summarize_conversation)</span>
<span id="cb13-9"></span>
<span id="cb13-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Set the entrypoint as conversation</span></span>
<span id="cb13-11">workflow.add_edge(START, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversation"</span>)</span>
<span id="cb13-12">workflow.add_conditional_edges(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"conversation"</span>, should_continue)</span>
<span id="cb13-13">workflow.add_edge(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"summarize_conversation"</span>, END)</span></code></pre></div></div>
<p>A checkpointer saves the state at each step as a checkpoint. These saved checkpoints can be grouped into a <code>thread</code> of conversation. Below we setting a thread_id. You can then continue the conversation by passing the config to the LangChain Runnable.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb14" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Create a thread</span></span>
<span id="cb14-2">config <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"configurable"</span>: {<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"thread_id"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"1"</span>}}</span>
<span id="cb14-3"></span>
<span id="cb14-4"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Start conversation</span></span>
<span id="cb14-5">input_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"hi! I'm Lance"</span>)</span>
<span id="cb14-6">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> graph.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [input_message]}, config) </span>
<span id="cb14-7"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> output[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'messages'</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]:</span>
<span id="cb14-8">    m.pretty_print()</span>
<span id="cb14-9"></span>
<span id="cb14-10">input_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"what's my name?"</span>)</span>
<span id="cb14-11">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> graph.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [input_message]}, config) </span>
<span id="cb14-12"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> output[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'messages'</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]:</span>
<span id="cb14-13">    m.pretty_print()</span>
<span id="cb14-14"></span>
<span id="cb14-15">input_message <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> HumanMessage(content<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"i like the 49ers!"</span>)</span>
<span id="cb14-16">output <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> graph.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"messages"</span>: [input_message]}, config) </span>
<span id="cb14-17"><span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> m <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> output[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'messages'</span>][<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>:]:</span>
<span id="cb14-18">    m.pretty_print()</span></code></pre></div></div>
</section>
<section id="lesson-6---chatbot-w-summarizing-messages-and-external-memory" class="level3">
<h3 class="anchored" data-anchor-id="lesson-6---chatbot-w-summarizing-messages-and-external-memory">Lesson 6 - Chatbot w/ Summarizing Messages and External Memory</h3>
<ul>
<li><a href="https://github.com/langchain-ai/langchain-academy/blob/8cca5e1092d01931f6aa9143ffc87d21ccd6052f/module-2/chatbot-external-memory.ipynb">Notebook</a></li>
<li>You can easily configure external memory to a database like sqlite.</li>
<li>Therefore you can persist memory across notebook sessions</li>
</ul>


</section>
</section>

 ]]></description>
  <category>ai</category>
  <category>summary</category>
  <guid>https://lawwu.github.io/blog.html/posts/2024-09-20-langgraph-tutorial/</guid>
  <pubDate>Fri, 20 Sep 2024 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
