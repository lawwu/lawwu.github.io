<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.290">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lawrence Wu">
<meta name="dcterms.date" content="2023-10-10">

<title>Lawrence Wu - AI Engineer Summit 2023</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LN4GM4FVCJ"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LN4GM4FVCJ', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Lawrence Wu - AI Engineer Summit 2023">
<meta property="og:description" content="">
<meta property="og:site-name" content="Lawrence Wu">
<meta name="twitter:title" content="Lawrence Wu - AI Engineer Summit 2023">
<meta name="twitter:description" content="">
<meta name="twitter:creator" content="@law_wu">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Lawrence Wu</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../ai_resources.html" rel="" target="">
 <span class="menu-text">AI Resources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/lawwu" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/law_wu" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text">Twitter</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:lawrencewu1+blog@gmail.com" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#ai-engineer-summit" id="toc-ai-engineer-summit" class="nav-link active" data-scroll-target="#ai-engineer-summit">AI Engineer Summit</a>
  <ul class="collapse">
  <li><a href="#workshop-building-evaluating-and-optimizing-your-rag-app-for-production" id="toc-workshop-building-evaluating-and-optimizing-your-rag-app-for-production" class="nav-link" data-scroll-target="#workshop-building-evaluating-and-optimizing-your-rag-app-for-production">Workshop: Building, Evaluating, and Optimizing your RAG App for Production</a></li>
  <li><a href="#workshop-function-calling-and-tool-usage-with-langchain-and-openai" id="toc-workshop-function-calling-and-tool-usage-with-langchain-and-openai" class="nav-link" data-scroll-target="#workshop-function-calling-and-tool-usage-with-langchain-and-openai">Workshop: Function calling and tool usage with LangChain and OpenAI</a></li>
  <li><a href="#the-1000x-ai-engineer" id="toc-the-1000x-ai-engineer" class="nav-link" data-scroll-target="#the-1000x-ai-engineer">The 1000x AI Engineer</a></li>
  <li><a href="#keynote-what-powers-replit-ai" id="toc-keynote-what-powers-replit-ai" class="nav-link" data-scroll-target="#keynote-what-powers-replit-ai">Keynote: What powers Replit AI?</a></li>
  <li><a href="#see-hear-speak-draw" id="toc-see-hear-speak-draw" class="nav-link" data-scroll-target="#see-hear-speak-draw">See, Hear, Speak, Draw</a></li>
  <li><a href="#the-age-of-the-agent" id="toc-the-age-of-the-agent" class="nav-link" data-scroll-target="#the-age-of-the-agent">The Age of the Agent</a></li>
  <li><a href="#one-smol-thing" id="toc-one-smol-thing" class="nav-link" data-scroll-target="#one-smol-thing">One Smol Thing</a></li>
  <li><a href="#building-context-aware-reasoning-applications-with-langchain-and-langsmith" id="toc-building-context-aware-reasoning-applications-with-langchain-and-langsmith" class="nav-link" data-scroll-target="#building-context-aware-reasoning-applications-with-langchain-and-langsmith">Building Context-Aware Reasoning Applications with LangChain and LangSmith</a></li>
  <li><a href="#pydantic-is-all-you-need" id="toc-pydantic-is-all-you-need" class="nav-link" data-scroll-target="#pydantic-is-all-you-need">Pydantic is all you need</a></li>
  <li><a href="#building-blocks-for-llm-systems-products" id="toc-building-blocks-for-llm-systems-products" class="nav-link" data-scroll-target="#building-blocks-for-llm-systems-products">Building Blocks for LLM Systems &amp; Products</a></li>
  <li><a href="#the-hidden-life-of-embeddings-linus-lee" id="toc-the-hidden-life-of-embeddings-linus-lee" class="nav-link" data-scroll-target="#the-hidden-life-of-embeddings-linus-lee">The Hidden Life of Embeddings, Linus Lee</a></li>
  <li><a href="#keynote-the-ai-evolution" id="toc-keynote-the-ai-evolution" class="nav-link" data-scroll-target="#keynote-the-ai-evolution">Keynote: The AI Evolution</a></li>
  <li><a href="#move-fast-break-nothing" id="toc-move-fast-break-nothing" class="nav-link" data-scroll-target="#move-fast-break-nothing">Move Fast, Break Nothing</a></li>
  <li><a href="#building-reactive-ai-apps" id="toc-building-reactive-ai-apps" class="nav-link" data-scroll-target="#building-reactive-ai-apps">Building Reactive AI Apps</a></li>
  <li><a href="#climbing-the-ladder-of-abstraction" id="toc-climbing-the-ladder-of-abstraction" class="nav-link" data-scroll-target="#climbing-the-ladder-of-abstraction">Climbing the Ladder of Abstraction</a></li>
  <li><a href="#the-intelligent-interface" id="toc-the-intelligent-interface" class="nav-link" data-scroll-target="#the-intelligent-interface">The Intelligent Interface</a></li>
  <li><a href="#the-weekend-ai-engineer" id="toc-the-weekend-ai-engineer" class="nav-link" data-scroll-target="#the-weekend-ai-engineer">The Weekend AI Engineer</a></li>
  <li><a href="#k-players-in-a-week-lessons-from-the-first-viral-clip-app" id="toc-k-players-in-a-week-lessons-from-the-first-viral-clip-app" class="nav-link" data-scroll-target="#k-players-in-a-week-lessons-from-the-first-viral-clip-app">120k players in a week: Lessons from the first viral CLIP app</a></li>
  <li><a href="#supabase-vector-the-postgres-vector-database" id="toc-supabase-vector-the-postgres-vector-database" class="nav-link" data-scroll-target="#supabase-vector-the-postgres-vector-database">Supabase Vector: The Postgres Vector database</a></li>
  <li><a href="#pragmatic-ai-with-typechat" id="toc-pragmatic-ai-with-typechat" class="nav-link" data-scroll-target="#pragmatic-ai-with-typechat">Pragmatic AI With TypeChat</a></li>
  <li><a href="#domain-adaptation-and-fine-tuning-for-domain-specific-llms" id="toc-domain-adaptation-and-fine-tuning-for-domain-specific-llms" class="nav-link" data-scroll-target="#domain-adaptation-and-fine-tuning-for-domain-specific-llms">Domain adaptation and fine-tuning for domain-specific LLMs</a></li>
  <li><a href="#retrieval-augmented-generation-in-the-wild" id="toc-retrieval-augmented-generation-in-the-wild" class="nav-link" data-scroll-target="#retrieval-augmented-generation-in-the-wild">Retrieval Augmented Generation in the Wild</a></li>
  <li><a href="#building-production-ready-rag-applications" id="toc-building-production-ready-rag-applications" class="nav-link" data-scroll-target="#building-production-ready-rag-applications">Building Production-Ready RAG Applications</a></li>
  <li><a href="#harnessing-the-power-of-llms-locally" id="toc-harnessing-the-power-of-llms-locally" class="nav-link" data-scroll-target="#harnessing-the-power-of-llms-locally">Harnessing the Power of LLMs Locally</a></li>
  <li><a href="#trust-but-verify" id="toc-trust-but-verify" class="nav-link" data-scroll-target="#trust-but-verify">Trust, but Verify</a></li>
  <li><a href="#open-questions-for-ai-engineering" id="toc-open-questions-for-ai-engineering" class="nav-link" data-scroll-target="#open-questions-for-ai-engineering">Open Questions for AI Engineering</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">AI Engineer Summit 2023</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Conference</div>
    <div class="quarto-category">AI</div>
    <div class="quarto-category">LLMs”</div>
    <div class="quarto-category">AI Engineering</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Lawrence Wu </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">October 10, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="ai-engineer-summit" class="level1">
<h1>AI Engineer Summit</h1>
<p>sywx was the <a href="https://www.latent.space/p/ai-engineer">first</a> to define the job title “AI Engineer” as a role in between a Data Scientist and Full Stack Software Engineer, someone that builds on top of large foundation models and can quickly build services using these models. I agree with him that this job function will likely expand whether you hold the job title of “AI Engineer” or not.</p>
<p>I had the privilege of attending the inaugural AI Engineer Summit in San Francisco, CA held on October 9-10, 2023. It was somewhat surprising being one of the few data scientists at the conference as most people I met were software engineers trying to transition into AI Engineering.</p>
<p>The talks were livestreamed (<a href="https://www.youtube.com/watch?v=veShHxQYPzo&amp;ab_channel=AIEngineer">Day 1</a> and <a href="https://www.youtube.com/watch?v=qw4PrtyvJI0">Day 2</a>). Below are my notes from the conference.</p>
<section id="workshop-building-evaluating-and-optimizing-your-rag-app-for-production" class="level2">
<h2 class="anchored" data-anchor-id="workshop-building-evaluating-and-optimizing-your-rag-app-for-production">Workshop: Building, Evaluating, and Optimizing your RAG App for Production</h2>
<p>Simon Suo, Cofounder / CTO, LlamaIndex<br>
</p>
<ul>
<li>Very indepth workshop on how to build an end to end RAG app over Ray documentation, also using Ray to build it. Slides are in the repo below.</li>
<li><a href="https://github.com/Disiok/ai-engineer-workshop" class="uri">https://github.com/Disiok/ai-engineer-workshop</a></li>
<li>Hallucinations: Most of the time it is caused by irrelevant retrieved passages</li>
<li>Evaluation: can think of both end-to-end evaluation and component-wise evaluation of a RAG app
<ul>
<li>End-to-end: understand how well the full RAG application works</li>
<li>Component-wise: understand specific components like the retriever (are we retrieving the relevant context?) and the generation (given the context, are we generating an accurate and coherent answer?)</li>
</ul></li>
<li>Data Required
<ul>
<li>User Query: representative set of real user queries</li>
<li>User Feedback: feedback from past interaction, up/down vote</li>
<li>Golden Context: set of relevant documents from our corpus to best answer a given query</li>
<li>Golden Answer: best ansewr given golden context</li>
</ul></li>
</ul>
</section>
<section id="workshop-function-calling-and-tool-usage-with-langchain-and-openai" class="level2">
<h2 class="anchored" data-anchor-id="workshop-function-calling-and-tool-usage-with-langchain-and-openai">Workshop: Function calling and tool usage with LangChain and OpenAI</h2>
<p>Harrison Chase, CEO, LangChain<br>
- <a href="https://github.com/hwchase17/ai-engineer" class="uri">https://github.com/hwchase17/ai-engineer</a> - OpenAI function calling within LangChain to do structured data extraction, build agents to do extraction and tagging and use tools. Also a quick tutorial on - LangChain Expression Language (LCEL) is a relatively new way (introduced in Aug 2023) to compose langchain components</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.prompts <span class="im">import</span> ChatPromptTemplate</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.schema.output_parser <span class="im">import</span> StrOutputParser</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> ChatPromptTemplate.from_template(</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"Tell me a short joke about </span><span class="sc">{topic}</span><span class="st">"</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>output_parser <span class="op">=</span> StrOutputParser()</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co"># define the chain</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> output_parser</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a><span class="co"># don't .run() the chain but call .invoke()</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>chain.invoke({<span class="st">"topic"</span>: <span class="st">"bears"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>OpenAI’s Function Calling is a way to get OpenAI’s language models to return structured data (arguments to run a function or extract structured data from text). This is a powerful feature!</li>
<li>I’m surprised other LLM providers have not yet introduced this functionality.</li>
<li>langchain exposes helper function to make working with function calling easier</li>
</ul>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.utils.openai_functions <span class="im">import</span> convert_pydantic_to_openai_function</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> WeatherSearch(BaseModel):</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Call this with an airport code to get the weather at that airport"""</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>    airport_code: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"airport code to get weather for"</span>)</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>weather_function <span class="op">=</span> convert_pydantic_to_openai_function(WeatherSearch)</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a>weather_function</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co"># {'name': 'WeatherSearch',</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#  'description': 'Call this with an airport code to get the weather at that airport',</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#  'parameters': {'title': 'WeatherSearch',</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#   'description': 'Call this with an airport code to get the weather at that airport',</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#   'type': 'object',</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#   'properties': {'airport_code': {'title': 'Airport Code',</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#     'description': 'airport code to get weather for',</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="co">#     'type': 'string'}},</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="co">#   'required': ['airport_code']}}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>then you can pass the weather function to the LLM</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ChatOpenAI()</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>model.invoke(<span class="st">"What is the weather in San Francisco right now?"</span>,</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>             functions<span class="op">=</span>[weather_function])  </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also bind the function to the model:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>model_with_function <span class="op">=</span> model.bind(functions<span class="op">=</span>[weather_function])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can force OpenAI to use a function, but you can only pass one function here.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>model_forced_function <span class="op">=</span> model.bind(functions<span class="op">=</span>[weather_function], function_call<span class="op">=</span>{<span class="st">"name"</span>:<span class="st">"WeatherSearch"</span>})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Function calling is a great way to do structured data extraction from text for example extracting name, age tuples.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Optional</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Person(BaseModel):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Information about a person."""</span></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    name: <span class="bu">str</span> <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"person's name"</span>)</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    age: Optional[<span class="bu">int</span>] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"person's age"</span>)</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> Information(BaseModel):</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Information to extract."""</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>    people: List[Person] <span class="op">=</span> Field(description<span class="op">=</span><span class="st">"List of info about people"</span>)</span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>extraction_functions <span class="op">=</span> [convert_pydantic_to_openai_function(Information)]</span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>extraction_model <span class="op">=</span> model.bind(functions<span class="op">=</span>extraction_functions, function_call<span class="op">=</span>{<span class="st">"name"</span>:<span class="st">"Information"</span>})</span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>extraction_model.invoke(<span class="st">"Joe is 30. Joe's mom is Martha"</span>)</span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a><span class="co"># AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': '{\n  "people": [\n    {\n      "name": "Joe",\n      "age": 30\n    },\n    {\n      "name": "Martha",\n      "age": 0\n    }\n  ]\n}'}})</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<ul>
<li>You can create your own tools using the <span class="citation" data-cites="tool">@tool</span> decorator and pass these tools to OpenAI</li>
</ul>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> tool</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chat_models <span class="im">import</span> ChatOpenAI</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel, Field</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> datetime</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the input schema</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> OpenMeteoInput(BaseModel):</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    latitude: <span class="bu">float</span> <span class="op">=</span> Field(..., description<span class="op">=</span><span class="st">"Latitude of the location to fetch weather data for"</span>)</span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>    longitude: <span class="bu">float</span> <span class="op">=</span> Field(..., description<span class="op">=</span><span class="st">"Longitude of the location to fetch weather data for"</span>)</span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a><span class="at">@tool</span>(args_schema<span class="op">=</span>OpenMeteoInput)</span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_current_temperature(latitude: <span class="bu">float</span>, longitude: <span class="bu">float</span>) <span class="op">-&gt;</span> <span class="bu">dict</span>:</span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Fetch current temperature for given coordinates."""</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>    BASE_URL <span class="op">=</span> <span class="st">"https://api.open-meteo.com/v1/forecast"</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Parameters for the request</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>    params <span class="op">=</span> {</span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span class="st">'latitude'</span>: latitude,</span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span class="st">'longitude'</span>: longitude,</span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span class="st">'hourly'</span>: <span class="st">'temperature_2m'</span>,</span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span class="st">'forecast_days'</span>: <span class="dv">1</span>,</span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Make the request</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> requests.get(BASE_URL, params<span class="op">=</span>params)</span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> response.status_code <span class="op">==</span> <span class="dv">200</span>:</span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        results <span class="op">=</span> response.json()</span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span class="cf">raise</span> <span class="pp">Exception</span>(<span class="ss">f"API Request failed with status code: </span><span class="sc">{</span>response<span class="sc">.</span>status_code<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>    current_utc_time <span class="op">=</span> datetime.datetime.utcnow()</span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>    time_list <span class="op">=</span> [datetime.datetime.fromisoformat(time_str.replace(<span class="st">'Z'</span>, <span class="st">'+00:00'</span>)) <span class="cf">for</span> time_str <span class="kw">in</span> results[<span class="st">'hourly'</span>][<span class="st">'time'</span>]]</span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>    temperature_list <span class="op">=</span> results[<span class="st">'hourly'</span>][<span class="st">'temperature_2m'</span>]</span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>    closest_time_index <span class="op">=</span> <span class="bu">min</span>(<span class="bu">range</span>(<span class="bu">len</span>(time_list)), key<span class="op">=</span><span class="kw">lambda</span> i: <span class="bu">abs</span>(time_list[i] <span class="op">-</span> current_utc_time))</span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>    current_temperature <span class="op">=</span> temperature_list[closest_time_index]</span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="ss">f'The current temperature is </span><span class="sc">{</span>current_temperature<span class="sc">}</span><span class="ss">°C'</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>format_tool_to_openai_function(get_current_temperature)    </span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a><span class="co"># {'name': 'get_current_temperature',</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a><span class="co">#  'description': 'get_current_temperature(latitude: float, longitude: float) -&gt; dict - Fetch current temperature for given coordinates.',</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a><span class="co">#  'parameters': {'title': 'OpenMeteoInput',</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a><span class="co">#   'type': 'object',</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a><span class="co">#   'properties': {'latitude': {'title': 'Latitude',</span></span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a><span class="co">#     'description': 'Latitude of the location to fetch weather data for',</span></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a><span class="co">#     'type': 'number'},</span></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a><span class="co">#    'longitude': {'title': 'Longitude',</span></span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a><span class="co">#     'description': 'Longitude of the location to fetch weather data for',</span></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a><span class="co">#     'type': 'number'}},</span></span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a><span class="co">#   'required': ['latitude', 'longitude']}}</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also convert an Open API spec into an OpenAI function</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.chains.openai_functions.openapi <span class="im">import</span> openapi_spec_to_openai_fn</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.utilities.openapi <span class="im">import</span> OpenAPISpec</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>text <span class="op">=</span> <span class="st">"""</span></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="st">{</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="st">  "openapi": "3.0.0",</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="st">  "info": {</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="st">    "version": "1.0.0",</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="st">    "title": "Swagger Petstore",</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="st">    "license": {</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="st">      "name": "MIT"</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="st">  },</span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="st">  "servers": [</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="st">    {</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="st">      "url": "http://petstore.swagger.io/v1"</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="st">  ],</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="st">  "paths": {</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="st">    "/pets": {</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="st">      "get": {</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="st">        "summary": "List all pets",</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="st">        "operationId": "listPets",</span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="st">        "tags": [</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="st">          "pets"</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="st">        "parameters": [</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="st">          {</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="st">            "name": "limit",</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="st">            "in": "query",</span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "How many items to return at one time (max 100)",</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="st">            "required": false,</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="st">            "schema": {</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a><span class="st">              "type": "integer",</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="st">              "maximum": 100,</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a><span class="st">              "format": "int32"</span></span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="st">        "responses": {</span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="st">          "200": {</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "A paged array of pets",</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="st">            "headers": {</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="st">              "x-next": {</span></span>
<span id="cb8-45"><a href="#cb8-45" aria-hidden="true" tabindex="-1"></a><span class="st">                "description": "A link to the next page of responses",</span></span>
<span id="cb8-46"><a href="#cb8-46" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-47"><a href="#cb8-47" aria-hidden="true" tabindex="-1"></a><span class="st">                  "type": "string"</span></span>
<span id="cb8-48"><a href="#cb8-48" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-49"><a href="#cb8-49" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-50"><a href="#cb8-50" aria-hidden="true" tabindex="-1"></a><span class="st">            },</span></span>
<span id="cb8-51"><a href="#cb8-51" aria-hidden="true" tabindex="-1"></a><span class="st">            "content": {</span></span>
<span id="cb8-52"><a href="#cb8-52" aria-hidden="true" tabindex="-1"></a><span class="st">              "application/json": {</span></span>
<span id="cb8-53"><a href="#cb8-53" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-54"><a href="#cb8-54" aria-hidden="true" tabindex="-1"></a><span class="st">                  "$ref": "#/components/schemas/Pets"</span></span>
<span id="cb8-55"><a href="#cb8-55" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-56"><a href="#cb8-56" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-57"><a href="#cb8-57" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-58"><a href="#cb8-58" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-59"><a href="#cb8-59" aria-hidden="true" tabindex="-1"></a><span class="st">          "default": {</span></span>
<span id="cb8-60"><a href="#cb8-60" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "unexpected error",</span></span>
<span id="cb8-61"><a href="#cb8-61" aria-hidden="true" tabindex="-1"></a><span class="st">            "content": {</span></span>
<span id="cb8-62"><a href="#cb8-62" aria-hidden="true" tabindex="-1"></a><span class="st">              "application/json": {</span></span>
<span id="cb8-63"><a href="#cb8-63" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-64"><a href="#cb8-64" aria-hidden="true" tabindex="-1"></a><span class="st">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-65"><a href="#cb8-65" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-66"><a href="#cb8-66" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-67"><a href="#cb8-67" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-68"><a href="#cb8-68" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-69"><a href="#cb8-69" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-70"><a href="#cb8-70" aria-hidden="true" tabindex="-1"></a><span class="st">      },</span></span>
<span id="cb8-71"><a href="#cb8-71" aria-hidden="true" tabindex="-1"></a><span class="st">      "post": {</span></span>
<span id="cb8-72"><a href="#cb8-72" aria-hidden="true" tabindex="-1"></a><span class="st">        "summary": "Create a pet",</span></span>
<span id="cb8-73"><a href="#cb8-73" aria-hidden="true" tabindex="-1"></a><span class="st">        "operationId": "createPets",</span></span>
<span id="cb8-74"><a href="#cb8-74" aria-hidden="true" tabindex="-1"></a><span class="st">        "tags": [</span></span>
<span id="cb8-75"><a href="#cb8-75" aria-hidden="true" tabindex="-1"></a><span class="st">          "pets"</span></span>
<span id="cb8-76"><a href="#cb8-76" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-77"><a href="#cb8-77" aria-hidden="true" tabindex="-1"></a><span class="st">        "responses": {</span></span>
<span id="cb8-78"><a href="#cb8-78" aria-hidden="true" tabindex="-1"></a><span class="st">          "201": {</span></span>
<span id="cb8-79"><a href="#cb8-79" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "Null response"</span></span>
<span id="cb8-80"><a href="#cb8-80" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-81"><a href="#cb8-81" aria-hidden="true" tabindex="-1"></a><span class="st">          "default": {</span></span>
<span id="cb8-82"><a href="#cb8-82" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "unexpected error",</span></span>
<span id="cb8-83"><a href="#cb8-83" aria-hidden="true" tabindex="-1"></a><span class="st">            "content": {</span></span>
<span id="cb8-84"><a href="#cb8-84" aria-hidden="true" tabindex="-1"></a><span class="st">              "application/json": {</span></span>
<span id="cb8-85"><a href="#cb8-85" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-86"><a href="#cb8-86" aria-hidden="true" tabindex="-1"></a><span class="st">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-87"><a href="#cb8-87" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-88"><a href="#cb8-88" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-89"><a href="#cb8-89" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-90"><a href="#cb8-90" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-91"><a href="#cb8-91" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-92"><a href="#cb8-92" aria-hidden="true" tabindex="-1"></a><span class="st">      }</span></span>
<span id="cb8-93"><a href="#cb8-93" aria-hidden="true" tabindex="-1"></a><span class="st">    },</span></span>
<span id="cb8-94"><a href="#cb8-94" aria-hidden="true" tabindex="-1"></a><span class="st">    "/pets/</span><span class="sc">{petId}</span><span class="st">": {</span></span>
<span id="cb8-95"><a href="#cb8-95" aria-hidden="true" tabindex="-1"></a><span class="st">      "get": {</span></span>
<span id="cb8-96"><a href="#cb8-96" aria-hidden="true" tabindex="-1"></a><span class="st">        "summary": "Info for a specific pet",</span></span>
<span id="cb8-97"><a href="#cb8-97" aria-hidden="true" tabindex="-1"></a><span class="st">        "operationId": "showPetById",</span></span>
<span id="cb8-98"><a href="#cb8-98" aria-hidden="true" tabindex="-1"></a><span class="st">        "tags": [</span></span>
<span id="cb8-99"><a href="#cb8-99" aria-hidden="true" tabindex="-1"></a><span class="st">          "pets"</span></span>
<span id="cb8-100"><a href="#cb8-100" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-101"><a href="#cb8-101" aria-hidden="true" tabindex="-1"></a><span class="st">        "parameters": [</span></span>
<span id="cb8-102"><a href="#cb8-102" aria-hidden="true" tabindex="-1"></a><span class="st">          {</span></span>
<span id="cb8-103"><a href="#cb8-103" aria-hidden="true" tabindex="-1"></a><span class="st">            "name": "petId",</span></span>
<span id="cb8-104"><a href="#cb8-104" aria-hidden="true" tabindex="-1"></a><span class="st">            "in": "path",</span></span>
<span id="cb8-105"><a href="#cb8-105" aria-hidden="true" tabindex="-1"></a><span class="st">            "required": true,</span></span>
<span id="cb8-106"><a href="#cb8-106" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "The id of the pet to retrieve",</span></span>
<span id="cb8-107"><a href="#cb8-107" aria-hidden="true" tabindex="-1"></a><span class="st">            "schema": {</span></span>
<span id="cb8-108"><a href="#cb8-108" aria-hidden="true" tabindex="-1"></a><span class="st">              "type": "string"</span></span>
<span id="cb8-109"><a href="#cb8-109" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-110"><a href="#cb8-110" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-111"><a href="#cb8-111" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-112"><a href="#cb8-112" aria-hidden="true" tabindex="-1"></a><span class="st">        "responses": {</span></span>
<span id="cb8-113"><a href="#cb8-113" aria-hidden="true" tabindex="-1"></a><span class="st">          "200": {</span></span>
<span id="cb8-114"><a href="#cb8-114" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "Expected response to a valid request",</span></span>
<span id="cb8-115"><a href="#cb8-115" aria-hidden="true" tabindex="-1"></a><span class="st">            "content": {</span></span>
<span id="cb8-116"><a href="#cb8-116" aria-hidden="true" tabindex="-1"></a><span class="st">              "application/json": {</span></span>
<span id="cb8-117"><a href="#cb8-117" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-118"><a href="#cb8-118" aria-hidden="true" tabindex="-1"></a><span class="st">                  "$ref": "#/components/schemas/Pet"</span></span>
<span id="cb8-119"><a href="#cb8-119" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-120"><a href="#cb8-120" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-121"><a href="#cb8-121" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-122"><a href="#cb8-122" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-123"><a href="#cb8-123" aria-hidden="true" tabindex="-1"></a><span class="st">          "default": {</span></span>
<span id="cb8-124"><a href="#cb8-124" aria-hidden="true" tabindex="-1"></a><span class="st">            "description": "unexpected error",</span></span>
<span id="cb8-125"><a href="#cb8-125" aria-hidden="true" tabindex="-1"></a><span class="st">            "content": {</span></span>
<span id="cb8-126"><a href="#cb8-126" aria-hidden="true" tabindex="-1"></a><span class="st">              "application/json": {</span></span>
<span id="cb8-127"><a href="#cb8-127" aria-hidden="true" tabindex="-1"></a><span class="st">                "schema": {</span></span>
<span id="cb8-128"><a href="#cb8-128" aria-hidden="true" tabindex="-1"></a><span class="st">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-129"><a href="#cb8-129" aria-hidden="true" tabindex="-1"></a><span class="st">                }</span></span>
<span id="cb8-130"><a href="#cb8-130" aria-hidden="true" tabindex="-1"></a><span class="st">              }</span></span>
<span id="cb8-131"><a href="#cb8-131" aria-hidden="true" tabindex="-1"></a><span class="st">            }</span></span>
<span id="cb8-132"><a href="#cb8-132" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-133"><a href="#cb8-133" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-134"><a href="#cb8-134" aria-hidden="true" tabindex="-1"></a><span class="st">      }</span></span>
<span id="cb8-135"><a href="#cb8-135" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-136"><a href="#cb8-136" aria-hidden="true" tabindex="-1"></a><span class="st">  },</span></span>
<span id="cb8-137"><a href="#cb8-137" aria-hidden="true" tabindex="-1"></a><span class="st">  "components": {</span></span>
<span id="cb8-138"><a href="#cb8-138" aria-hidden="true" tabindex="-1"></a><span class="st">    "schemas": {</span></span>
<span id="cb8-139"><a href="#cb8-139" aria-hidden="true" tabindex="-1"></a><span class="st">      "Pet": {</span></span>
<span id="cb8-140"><a href="#cb8-140" aria-hidden="true" tabindex="-1"></a><span class="st">        "type": "object",</span></span>
<span id="cb8-141"><a href="#cb8-141" aria-hidden="true" tabindex="-1"></a><span class="st">        "required": [</span></span>
<span id="cb8-142"><a href="#cb8-142" aria-hidden="true" tabindex="-1"></a><span class="st">          "id",</span></span>
<span id="cb8-143"><a href="#cb8-143" aria-hidden="true" tabindex="-1"></a><span class="st">          "name"</span></span>
<span id="cb8-144"><a href="#cb8-144" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-145"><a href="#cb8-145" aria-hidden="true" tabindex="-1"></a><span class="st">        "properties": {</span></span>
<span id="cb8-146"><a href="#cb8-146" aria-hidden="true" tabindex="-1"></a><span class="st">          "id": {</span></span>
<span id="cb8-147"><a href="#cb8-147" aria-hidden="true" tabindex="-1"></a><span class="st">            "type": "integer",</span></span>
<span id="cb8-148"><a href="#cb8-148" aria-hidden="true" tabindex="-1"></a><span class="st">            "format": "int64"</span></span>
<span id="cb8-149"><a href="#cb8-149" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-150"><a href="#cb8-150" aria-hidden="true" tabindex="-1"></a><span class="st">          "name": {</span></span>
<span id="cb8-151"><a href="#cb8-151" aria-hidden="true" tabindex="-1"></a><span class="st">            "type": "string"</span></span>
<span id="cb8-152"><a href="#cb8-152" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-153"><a href="#cb8-153" aria-hidden="true" tabindex="-1"></a><span class="st">          "tag": {</span></span>
<span id="cb8-154"><a href="#cb8-154" aria-hidden="true" tabindex="-1"></a><span class="st">            "type": "string"</span></span>
<span id="cb8-155"><a href="#cb8-155" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-156"><a href="#cb8-156" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-157"><a href="#cb8-157" aria-hidden="true" tabindex="-1"></a><span class="st">      },</span></span>
<span id="cb8-158"><a href="#cb8-158" aria-hidden="true" tabindex="-1"></a><span class="st">      "Pets": {</span></span>
<span id="cb8-159"><a href="#cb8-159" aria-hidden="true" tabindex="-1"></a><span class="st">        "type": "array",</span></span>
<span id="cb8-160"><a href="#cb8-160" aria-hidden="true" tabindex="-1"></a><span class="st">        "maxItems": 100,</span></span>
<span id="cb8-161"><a href="#cb8-161" aria-hidden="true" tabindex="-1"></a><span class="st">        "items": {</span></span>
<span id="cb8-162"><a href="#cb8-162" aria-hidden="true" tabindex="-1"></a><span class="st">          "$ref": "#/components/schemas/Pet"</span></span>
<span id="cb8-163"><a href="#cb8-163" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-164"><a href="#cb8-164" aria-hidden="true" tabindex="-1"></a><span class="st">      },</span></span>
<span id="cb8-165"><a href="#cb8-165" aria-hidden="true" tabindex="-1"></a><span class="st">      "Error": {</span></span>
<span id="cb8-166"><a href="#cb8-166" aria-hidden="true" tabindex="-1"></a><span class="st">        "type": "object",</span></span>
<span id="cb8-167"><a href="#cb8-167" aria-hidden="true" tabindex="-1"></a><span class="st">        "required": [</span></span>
<span id="cb8-168"><a href="#cb8-168" aria-hidden="true" tabindex="-1"></a><span class="st">          "code",</span></span>
<span id="cb8-169"><a href="#cb8-169" aria-hidden="true" tabindex="-1"></a><span class="st">          "message"</span></span>
<span id="cb8-170"><a href="#cb8-170" aria-hidden="true" tabindex="-1"></a><span class="st">        ],</span></span>
<span id="cb8-171"><a href="#cb8-171" aria-hidden="true" tabindex="-1"></a><span class="st">        "properties": {</span></span>
<span id="cb8-172"><a href="#cb8-172" aria-hidden="true" tabindex="-1"></a><span class="st">          "code": {</span></span>
<span id="cb8-173"><a href="#cb8-173" aria-hidden="true" tabindex="-1"></a><span class="st">            "type": "integer",</span></span>
<span id="cb8-174"><a href="#cb8-174" aria-hidden="true" tabindex="-1"></a><span class="st">            "format": "int32"</span></span>
<span id="cb8-175"><a href="#cb8-175" aria-hidden="true" tabindex="-1"></a><span class="st">          },</span></span>
<span id="cb8-176"><a href="#cb8-176" aria-hidden="true" tabindex="-1"></a><span class="st">          "message": {</span></span>
<span id="cb8-177"><a href="#cb8-177" aria-hidden="true" tabindex="-1"></a><span class="st">            "type": "string"</span></span>
<span id="cb8-178"><a href="#cb8-178" aria-hidden="true" tabindex="-1"></a><span class="st">          }</span></span>
<span id="cb8-179"><a href="#cb8-179" aria-hidden="true" tabindex="-1"></a><span class="st">        }</span></span>
<span id="cb8-180"><a href="#cb8-180" aria-hidden="true" tabindex="-1"></a><span class="st">      }</span></span>
<span id="cb8-181"><a href="#cb8-181" aria-hidden="true" tabindex="-1"></a><span class="st">    }</span></span>
<span id="cb8-182"><a href="#cb8-182" aria-hidden="true" tabindex="-1"></a><span class="st">  }</span></span>
<span id="cb8-183"><a href="#cb8-183" aria-hidden="true" tabindex="-1"></a><span class="st">}</span></span>
<span id="cb8-184"><a href="#cb8-184" aria-hidden="true" tabindex="-1"></a><span class="st">"""</span></span>
<span id="cb8-185"><a href="#cb8-185" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-186"><a href="#cb8-186" aria-hidden="true" tabindex="-1"></a>spec <span class="op">=</span> OpenAPISpec.from_text(text)</span>
<span id="cb8-187"><a href="#cb8-187" aria-hidden="true" tabindex="-1"></a>pet_openai_functions, pet_callables <span class="op">=</span> openapi_spec_to_openai_fn(spec)</span>
<span id="cb8-188"><a href="#cb8-188" aria-hidden="true" tabindex="-1"></a>pet_openai_functions</span>
<span id="cb8-189"><a href="#cb8-189" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-190"><a href="#cb8-190" aria-hidden="true" tabindex="-1"></a><span class="co"># [{'name': 'listPets',</span></span>
<span id="cb8-191"><a href="#cb8-191" aria-hidden="true" tabindex="-1"></a><span class="co">#   'description': 'List all pets',</span></span>
<span id="cb8-192"><a href="#cb8-192" aria-hidden="true" tabindex="-1"></a><span class="co">#   'parameters': {'type': 'object',</span></span>
<span id="cb8-193"><a href="#cb8-193" aria-hidden="true" tabindex="-1"></a><span class="co">#    'properties': {'params': {'type': 'object',</span></span>
<span id="cb8-194"><a href="#cb8-194" aria-hidden="true" tabindex="-1"></a><span class="co">#      'properties': {'limit': {'type': 'integer',</span></span>
<span id="cb8-195"><a href="#cb8-195" aria-hidden="true" tabindex="-1"></a><span class="co">#        'maximum': 100.0,</span></span>
<span id="cb8-196"><a href="#cb8-196" aria-hidden="true" tabindex="-1"></a><span class="co">#        'schema_format': 'int32',</span></span>
<span id="cb8-197"><a href="#cb8-197" aria-hidden="true" tabindex="-1"></a><span class="co">#        'description': 'How many items to return at one time (max 100)'}},</span></span>
<span id="cb8-198"><a href="#cb8-198" aria-hidden="true" tabindex="-1"></a><span class="co">#      'required': []</span><span class="re">}}}</span><span class="co">},</span></span>
<span id="cb8-199"><a href="#cb8-199" aria-hidden="true" tabindex="-1"></a><span class="co">#  {'name': 'createPets',</span></span>
<span id="cb8-200"><a href="#cb8-200" aria-hidden="true" tabindex="-1"></a><span class="co">#   'description': 'Create a pet',</span></span>
<span id="cb8-201"><a href="#cb8-201" aria-hidden="true" tabindex="-1"></a><span class="co">#   'parameters': {'type': 'object', 'properties': {</span><span class="re">}}}</span><span class="co">,</span></span>
<span id="cb8-202"><a href="#cb8-202" aria-hidden="true" tabindex="-1"></a><span class="co">#  {'name': 'showPetById',</span></span>
<span id="cb8-203"><a href="#cb8-203" aria-hidden="true" tabindex="-1"></a><span class="co">#   'description': 'Info for a specific pet',</span></span>
<span id="cb8-204"><a href="#cb8-204" aria-hidden="true" tabindex="-1"></a><span class="co">#   'parameters': {'type': 'object',</span></span>
<span id="cb8-205"><a href="#cb8-205" aria-hidden="true" tabindex="-1"></a><span class="co">#    'properties': {'path_params': {'type': 'object',</span></span>
<span id="cb8-206"><a href="#cb8-206" aria-hidden="true" tabindex="-1"></a><span class="co">#      'properties': {'petId': {'type': 'string',</span></span>
<span id="cb8-207"><a href="#cb8-207" aria-hidden="true" tabindex="-1"></a><span class="co">#        'description': 'The id of the pet to retrieve'}},</span></span>
<span id="cb8-208"><a href="#cb8-208" aria-hidden="true" tabindex="-1"></a><span class="co">#      'required': ['petId']</span><span class="re">}}}</span><span class="co">}]</span></span>
<span id="cb8-209"><a href="#cb8-209" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-210"><a href="#cb8-210" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> ChatOpenAI(temperature<span class="op">=</span><span class="dv">0</span>).bind(functions<span class="op">=</span>pet_openai_functions)</span>
<span id="cb8-211"><a href="#cb8-211" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-212"><a href="#cb8-212" aria-hidden="true" tabindex="-1"></a>model.invoke(<span class="st">"what are three pet names"</span>)</span>
<span id="cb8-213"><a href="#cb8-213" aria-hidden="true" tabindex="-1"></a><span class="co"># AIMessage(content='', additional_kwargs={'function_call': {'name': 'listPets', 'arguments': '{\n  "params": {\n    "limit": 3\n  }\n}'}})</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also define routers to create rules for when an agent should use a tool.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.schema.agent <span class="im">import</span> AgentFinish</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> route(result):</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(result, AgentFinish):</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> result.return_values[<span class="st">'output'</span>]</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>        tools <span class="op">=</span> {</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>            <span class="st">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>            <span class="st">"get_current_temperature"</span>: get_current_temperature,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>        }</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>        <span class="cf">return</span> tools[result.tool].run(result.tool_input)</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>chain <span class="op">=</span> prompt <span class="op">|</span> model <span class="op">|</span> OpenAIFunctionsAgentOutputParser() <span class="op">|</span> route</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"What is the weather in san francisco right now?"</span>})</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co"># uses the weather tool</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 'The current temperature is 18.5°C'</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a><span class="co"># uses the wikipedia tool</span></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>chain.invoke({<span class="st">"input"</span>: <span class="st">"What is langchain?"</span>})</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 'Page: LangChain\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n\nPage: Prompt engineering\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as "what is Fermat\'s little theorem?", a command such as "write a poem about leaves falling", a short statement of feedback (for example, "too verbose", "too formal", "rephrase again", "omit this word") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as "Act as a native French speaker". A prompt may include a few examples for a model to learn from, such as "maison -&gt; house, chat -&gt; cat, chien -&gt;", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as "a high-quality photo of an astronaut riding a horse" or "Lo-fi slow BPM electro chill with organic samples". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\n\nPage: Sentence embedding\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.'</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also create a conversational agent that can use tools using the <code>AgentExecutor</code> class. I believe the <code>AgentExecutor</code> handles the message types and routing for you.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.schema.runnable <span class="im">import</span> RunnablePassthrough</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> AgentExecutor</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>agent_chain <span class="op">=</span> RunnablePassthrough.assign(</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>    agent_scratchpad<span class="op">=</span> <span class="kw">lambda</span> x: format_to_openai_functions(x[<span class="st">"intermediate_steps"</span>])</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>) <span class="op">|</span> chain</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>agent_executor <span class="op">=</span> AgentExecutor(agent<span class="op">=</span>agent_chain, tools<span class="op">=</span>tools, verbose<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>agent_executor.invoke({<span class="st">"input"</span>: <span class="st">"what is langchain?"</span>})</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a><span class="co"># &gt; Entering new AgentExecutor chain...</span></span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Invoking: `search_wikipedia` with `{'query': 'langchain'}`</span></span>
<span id="cb10-15"><a href="#cb10-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-16"><a href="#cb10-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-17"><a href="#cb10-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Page: LangChain</span></span>
<span id="cb10-18"><a href="#cb10-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.</span></span>
<span id="cb10-19"><a href="#cb10-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-20"><a href="#cb10-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-21"><a href="#cb10-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-22"><a href="#cb10-22" aria-hidden="true" tabindex="-1"></a><span class="co"># Page: Sentence embedding</span></span>
<span id="cb10-23"><a href="#cb10-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. </span></span>
<span id="cb10-24"><a href="#cb10-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Other approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. </span></span>
<span id="cb10-25"><a href="#cb10-25" aria-hidden="true" tabindex="-1"></a><span class="co"># An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.</span></span>
<span id="cb10-26"><a href="#cb10-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-27"><a href="#cb10-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-28"><a href="#cb10-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-29"><a href="#cb10-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Page: Prompt engineering</span></span>
<span id="cb10-30"><a href="#cb10-30" aria-hidden="true" tabindex="-1"></a><span class="co"># Summary: Prompt engineering, primarily used in communication with a text-to-text model and text-to-image model, is the process of structuring text that can be interpreted and understood by a generative AI model. Prompt engineering is enabled by in-context learning, defined as a model's ability to temporarily learn from prompts. The ability for in-context learning is an emergent ability of large language models.</span></span>
<span id="cb10-31"><a href="#cb10-31" aria-hidden="true" tabindex="-1"></a><span class="co"># A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text model can be a query such as "what is Fermat's little theorem?", a command such as "write a poem about leaves falling", a short statement of feedback (for example, "too verbose", "too formal", "rephrase again", "omit this word") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as "Act as a native French speaker". Prompt engineering may consist of a single prompt that includes a few examples for a model to learn from, such as "maison -&gt; house, chat -&gt; cat, chien -&gt;", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as "a high-quality photo of an astronaut riding a horse" or "Lo-fi slow BPM electro chill with organic samples". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.</span></span>
<span id="cb10-32"><a href="#cb10-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-33"><a href="#cb10-33" aria-hidden="true" tabindex="-1"></a><span class="co"># LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various purposes such as document analysis and summarization, chatbots, and code analysis. LangChain allows developers to leverage the power of language models in their applications.</span></span>
<span id="cb10-34"><a href="#cb10-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb10-35"><a href="#cb10-35" aria-hidden="true" tabindex="-1"></a><span class="co"># &gt; Finished chain.</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>You can also add memory to the Agent:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.memory <span class="im">import</span> ConversationBufferMemory</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> langchain.agents <span class="im">import</span> AgentExecutor</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>prompt <span class="op">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"system"</span>, <span class="st">"You are helpful but sassy assistant"</span>),</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"chat_history"</span>),</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    (<span class="st">"user"</span>, <span class="st">"</span><span class="sc">{input}</span><span class="st">"</span>),</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    MessagesPlaceholder(variable_name<span class="op">=</span><span class="st">"agent_scratchpad"</span>)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>])</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>chain <span class="op">=</span> RunnablePassthrough.assign(</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    agent_scratchpad<span class="op">=</span> <span class="kw">lambda</span> x: format_to_openai_functions(x[<span class="st">"intermediate_steps"</span>])</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>) <span class="op">|</span> prompt <span class="op">|</span> model <span class="op">|</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a><span class="co"># what happens when conversation buffer memory gets too long?</span></span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>memory <span class="op">=</span> ConversationBufferMemory(return_messages<span class="op">=</span><span class="va">True</span>,memory_key<span class="op">=</span><span class="st">"chat_history"</span>)</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>agent_executor <span class="op">=</span> AgentExecutor(agent<span class="op">=</span>chain, tools<span class="op">=</span>tools, verbose<span class="op">=</span><span class="va">True</span>, memory<span class="op">=</span>memory)</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>query <span class="op">=</span> <span class="st">"What is the weather in san francisco right now?"</span></span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a>agent_executor.invoke({<span class="st">"input"</span>:query})</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="the-1000x-ai-engineer" class="level2">
<h2 class="anchored" data-anchor-id="the-1000x-ai-engineer">The 1000x AI Engineer</h2>
<p>swyx, Latent.Space &amp; Smol.ai Born too late to explore the earth. Born too early to explore the stars. Just in time to bring AI to everyone.</p>
<ul>
<li>Each technological wave lasts around 50-70 years. We’re in the beginning of a new wave (deep learning, generative AI) that was kicked off by AlexNet in around 2012. Since we’re only 10 years in, it’s still early.</li>
<li>Breaking down the definitions of an AI Engineer
<ul>
<li>Software engineer enhanced BY AI tools - AI Enhanced Engineer</li>
<li>Software engineer building AI products - AI Product Engineer</li>
<li>AI product that replaces human - AI Engineer Agent</li>
</ul></li>
</ul>
</section>
<section id="keynote-what-powers-replit-ai" class="level2">
<h2 class="anchored" data-anchor-id="keynote-what-powers-replit-ai">Keynote: What powers Replit AI?</h2>
<p>Amjad Masad, CEO, Replit Michele Catasta, VP of AI, Replit The building blocks of the future of software development.</p>
<ul>
<li>Announced two models <code>replit-code-v1.5-3b</code> and <code>replit-repltuned-v1.5-3b</code> that are state of the art code completion models. Replit trained them from scratch.</li>
</ul>
</section>
<section id="see-hear-speak-draw" class="level2">
<h2 class="anchored" data-anchor-id="see-hear-speak-draw">See, Hear, Speak, Draw</h2>
<p>Simón Fishman, Applied AI Engineer, OpenAI Logan Kilpatrick, Developer Relations, OpenAI We’re heading towards a multimodal world.</p>
<ul>
<li>2023 is the year of chatbots</li>
<li>2024 is the year of multi-modal</li>
<li>Each multi-modal model is a island and text is the connective tissue between models. The future is where there is unity between all modalities</li>
<li>Demos
<ul>
<li>GPT4-V and DALLE3: Upload a picture, use GPT4-V to describe the image, use DALLE3 to generate an image based that description, use GPT4-V to describe differences and use DALLE3 to generate a new image based on the differences. Was impressed by how much detail GPT4-V could capture in an image. DALLE3 struggled a bit to generate a similar image.</li>
<li>Video to blog post: Logan demonstrated taking the GPT-4 intro video into a <a href="https://logankilpatrick.medium.com/dont-forget-about-gpt-4-d5ab8c9493fc">blog post</a>. Capture frames from a video, use GPT4-V to describe the image and stitch the images and descriptions together as a post.</li>
</ul></li>
</ul>
</section>
<section id="the-age-of-the-agent" class="level2">
<h2 class="anchored" data-anchor-id="the-age-of-the-agent">The Age of the Agent</h2>
<p>Flo Crivello, CEO, Lindy How will ubiquitous AI agents impact our daily lives, and what do they mean for the future of computing?</p>
<ul>
<li>The Age of Agents</li>
<li>A world where a 25-year old can have more business impact than the Coca Cola Company</li>
<li>It’s happened beforew ith media
<ul>
<li>Oprah - 10M viewers</li>
<li>Mr.&nbsp;Beast - 189M subscribers</li>
<li>Ryan’s World -</li>
</ul></li>
<li>Nature of the content changes when you take out the gatekeepers
<ul>
<li>Much weirder, creative ideas</li>
</ul></li>
<li>It’s people who have been stealing robot’s jobs</li>
<li>Average worker spends 15 hours a week on admin tasks</li>
<li>Built an AI Employee - Lindy is an AI Assistant</li>
<li>Three big time wasters
<ul>
<li>Calendar</li>
<li>Email</li>
<li>Meeting note taking</li>
<li>What it does
<ul>
<li>Arrange meetings by email</li>
<li>Pre-draft replies, in your voice, for each recipient.</li>
<li>Prepares you for your meetings</li>
</ul></li>
</ul></li>
<li>Built a Framework - for an AI to pursue any arbitrary goal, using an arbitrary tool</li>
<li>Society of Lindies
<ul>
<li>Every single thing is made by a group of people</li>
</ul></li>
<li>Tool Creation Lindy
<ul>
<li>Create a society of lindies to build herself (this was a little mind-blowing to think about)</li>
</ul></li>
</ul>
<p>r voice, for each recipient. Prepares you for your meetings Built a Framework - for an AI to pursue any arbitrary goal, using an arbitrary tool Society of Lindies Every single thing is made by a group of people Tool Creation Lindy Create a society of lindies to build herself</p>
</section>
<section id="one-smol-thing" class="level2">
<h2 class="anchored" data-anchor-id="one-smol-thing">One Smol Thing</h2>
<p>swyx, Latent.Space &amp; Smol.ai Barr Yaron, Partner, Amplify Sasha Sheng, Stealth</p>
<ul>
<li>First <a href="https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135">State of AI Engineering Report</a> in 2023</li>
<li>Announced the AIE Foundation - the first project they worked on was the agent protocol that AutoGPT actually using for their Arena Hacks</li>
</ul>
</section>
<section id="building-context-aware-reasoning-applications-with-langchain-and-langsmith" class="level2">
<h2 class="anchored" data-anchor-id="building-context-aware-reasoning-applications-with-langchain-and-langsmith">Building Context-Aware Reasoning Applications with LangChain and LangSmith</h2>
<p>Harrison Chase, CEO, LangChain How can companies best build useful and differentiated applications on top of language models?</p>
</section>
<section id="pydantic-is-all-you-need" class="level2">
<h2 class="anchored" data-anchor-id="pydantic-is-all-you-need">Pydantic is all you need</h2>
<p>Jason Liu, Founder, Fivesixseven Please return only json, do not add any other comments ONLY RETURN JSON OR I’LL TAKE A LIFE.</p>
<ul>
<li><a href="https://github.com/jxnl/instructor" class="uri">https://github.com/jxnl/instructor</a></li>
<li>Structured Prompting</li>
<li>LLMs are eating software</li>
<li>90% of applications output JSON</li>
<li>OpenAI function calling fixes this for the most part
<ul>
<li>str, schema –&gt; str</li>
<li>json.loads(x)</li>
</ul></li>
<li>Pydantic
<ul>
<li>Powered by type hints.</li>
<li>Fields and model level validation</li>
<li>Outputs JSONSchema</li>
</ul></li>
<li>Pydantic
<ul>
<li>str, model –&gt; model</li>
</ul></li>
<li>pip install instructor</li>
<li>Comprehensive AI engineering framework w/ Pydantic - askmarvin.ai that works with more models (right now it only works with OpenAI and Anthropic)</li>
<li>Pydantic validators - but you can also define LLM based validators</li>
<li>UserDetail class
<ul>
<li>MaybeUser</li>
</ul></li>
<li>Reuse Components
<ul>
<li>Add Chain of thought to specific components</li>
</ul></li>
<li>Extract entities and relationships</li>
<li>Applications
<ul>
<li>RAG</li>
<li>RAG with planning</li>
<li>KnowledgeGraph visualization</li>
<li>Validation with Citations</li>
</ul></li>
<li>See more examples here: <a href="https://jxnl.github.io/instructor/examples/" class="uri">https://jxnl.github.io/instructor/examples/</a></li>
</ul>
</section>
<section id="building-blocks-for-llm-systems-products" class="level2">
<h2 class="anchored" data-anchor-id="building-blocks-for-llm-systems-products">Building Blocks for LLM Systems &amp; Products</h2>
<p>Eugene Yan, Senior Applied Scientist, Amazon We’ll explore patterns that help us apply generative AI in production systems and customer systems.</p>
<ul>
<li>Talk version of his <a href="https://eugeneyan.com/writing/llm-patterns/">epic blog post</a></li>
<li>Slides here: <a href="https://eugeneyan.com/speaking/ai-eng-summit/" class="uri">https://eugeneyan.com/speaking/ai-eng-summit/</a></li>
<li>Evals
<ul>
<li>Eval-driven development</li>
<li>What are some gotchas for evals?</li>
<li>Build evals for a specific task; it’s okay to start small</li>
<li>Don’t discount eyeballing completions</li>
</ul></li>
<li>RAG
<ul>
<li>LLM’s can’t see all documents retrieved</li>
<li>Takeaway: Large context window doesn’t prevent problems</li>
<li>Even with perfect retrieval, you can expect some mistakes</li>
<li>How should we do RAG?
<ul>
<li>Apply ideas from information retrieval (IR)</li>
</ul></li>
</ul></li>
<li>Guardrails
<ul>
<li>NLI - natural language inference task
<ul>
<li>given a premise, is the hypothesis entailment (true), contradiction (false)</li>
</ul></li>
<li>Sampling</li>
<li>Ask a strong LLM</li>
</ul></li>
</ul>
</section>
<section id="the-hidden-life-of-embeddings-linus-lee" class="level2">
<h2 class="anchored" data-anchor-id="the-hidden-life-of-embeddings-linus-lee">The Hidden Life of Embeddings, Linus Lee</h2>
<ul>
<li>Notion AI</li>
<li>Slides: <a href="https://linus.zone/contra-slides" class="uri">https://linus.zone/contra-slides</a></li>
<li>Latent spaces arise in
<ul>
<li>Fixed-size embedding spaces of embedding models</li>
<li>Intermediate activations of models</li>
<li>Autoencoders</li>
</ul></li>
<li>Latent spaces represent the most salient features of the training domain</li>
<li>If we can disentangle meaningful features, maybe we can build more expressive interfaces</li>
<li>Text –&gt; Embeddings –&gt; Project the embeddings in some direction
<ul>
<li>Longer, Shorter, Sci-fi, simplify, artistic, philosophical, positive, negative, narrative, elaborate</li>
</ul></li>
<li>Open sourcing the models, calling it Contra
<ul>
<li>Based on T5</li>
<li>Models: <a href="https://linus.zone/contra">linus.zone/contra</a></li>
<li>Colab: <a href="https://linus.zone/contra-colab">linus.zone/contra-colab</a></li>
<li>Image: From KakaoBrain - <a href="https://huggingface.co/kakaobrain" class="uri">https://huggingface.co/kakaobrain</a></li>
</ul></li>
</ul>
</section>
<section id="keynote-the-ai-evolution" class="level2">
<h2 class="anchored" data-anchor-id="keynote-the-ai-evolution">Keynote: The AI Evolution</h2>
<p><strong>Mario Rodriguez</strong>, <em>VP of Product, GitHub</em></p>
<p>How AI is transforming how the world builds software together</p>
<ul>
<li><span class="citation" data-cites="mariorod">@mariorod</span></li>
<li>Catalyst for Github Copilot came around Aug 2020, paper “An Automated AI Pair progrmamer, Fact or Faction.”
<ul>
<li>Polarity</li>
<li>Eventually shipped Copilot in 2021 - first at scale AI programmer assistant</li>
</ul></li>
<li>Building Copilot for the sake of developer happiness, feeling of flow</li>
<li>Key Components
<ul>
<li>Ghost text - UX matters a lot</li>
<li>&lt;150ms of latency - recently switched to gpt-3.5-turbo from codex</li>
<li>Innovation in Codex - this model really changed the game</li>
<li>Prompt Engineering</li>
</ul></li>
<li>Other learnings
<ul>
<li>Syntax is not software - just because an AI knows language syntax doesn’t make it a developer</li>
<li>Global presence - have deployments around the world to keep latency under 150ms</li>
<li>Set up scorecords for quality - offline evals (everything working), go to production (run the same scorecard in production to see if things are working)</li>
</ul></li>
<li>Bret Victor - The Future of Programming
<ul>
<li>Prompt 1: Procedurural Programming in text files
<ul>
<li>What if in the future Copilot operates on goals and constraints?</li>
<li>How does the REPL change and evolve to the new rules</li>
</ul></li>
<li>Prompt 2: What does it look like for AI to have reasoning on code?
<ul>
<li>our brain can summarize things fast</li>
</ul></li>
<li>Prompt 3: What does it look like to create software together with a Copilot and others</li>
</ul></li>
</ul>
</section>
<section id="move-fast-break-nothing" class="level2">
<h2 class="anchored" data-anchor-id="move-fast-break-nothing">Move Fast, Break Nothing</h2>
<p><strong>Dedy Kredo</strong><br>
CPO, CodiumAI<br>
Why we need Agents writing Tests faster than Humans writing Code.</p>
<ul>
<li>high integrity code gen, GANs are conceptually back in 2024. Have two different components: code generation and code integrity to ensure code works as intended</li>
<li>Behavior coverage is more useful than Code Coverage</li>
<li>CodiumAI
<ul>
<li>Generate tests automatically on happy path, edge cases based on behaviors</li>
<li>Code Explanation</li>
<li>Code Suggestions - trigger Codium on a method, suggest improvements</li>
<li>PR Review Extension - to generate commit messages, generate reviews (PR messages)</li>
</ul></li>
<li>Moving personal story of the CEO of Codium who is in Israel, after Hamas invaded Israel, he left his 8 month old baby and wife to join the military reserves</li>
</ul>
<hr>
</section>
<section id="building-reactive-ai-apps" class="level2">
<h2 class="anchored" data-anchor-id="building-reactive-ai-apps">Building Reactive AI Apps</h2>
<p><strong>Matt Welsh</strong><br>
Co-Founder, Fixie.ai<br>
AI.JSX is like React for LLMs – it lets you build powerful, conversational AI apps using the power of TypeScript and JSX.</p>
<ul>
<li><a href="https://github.com/fixie-ai/ai-jsx">AI.JSX</a> open source framework for developing LLM apps, kind of like langchain but for TypeScript</li>
<li>AI.JSX supports real-time voice (bi-directional). Try it out on <a href="https://voice.fixie.ai/agent" class="uri">https://voice.fixie.ai/agent</a>. This was an amazing demo.</li>
<li>Fixie is a platform to deploy AI.JSX apps</li>
</ul>
<hr>
</section>
<section id="climbing-the-ladder-of-abstraction" class="level2">
<h2 class="anchored" data-anchor-id="climbing-the-ladder-of-abstraction">Climbing the Ladder of Abstraction</h2>
<p><strong>Amelia Wattenberger</strong> Design, <a href="https://www.adept.ai/" class="uri">https://www.adept.ai/</a></p>
<p>How might we use AI to build products focused not just on working faster, but on transforming how we work?</p>
<ul>
<li>How to combine AI with UIs?</li>
<li>Two main types of tasks:
<ul>
<li>Automate - tedious, boring like copy pasting things</li>
<li>Augment - creative, nuanced like analyzing data</li>
</ul></li>
<li>Reframe it as Augmentation is composed of smaller automations
<ul>
<li>Spreadsheet example: each cell is automated, the overall task is augmented</li>
</ul></li>
<li>The Ladder of Abstraction
<ul>
<li>the same object can be represented at different levels of details</li>
<li>Maps: Google Maps
<ul>
<li>zoomed in can see streets, buildings</li>
<li>as we zoom out, Google Maps starts hiding information, see city streets, landmarks, parks</li>
<li>as we zoom out, we see highway and terrains –&gt; supports long-range travel</li>
</ul></li>
</ul></li>
<li>Can we use AI to bring these interfaces</li>
<li>Zooming out in a book
<ul>
<li>Each paragraph is changed to a one line summary</li>
<li>Summaries of 10 paragraphs</li>
<li>Reduced each chapter into one sentence</li>
</ul></li>
<li>Shapes of Stories by Kurt Vonnegut
<ul>
<li>What if we could plot the mood of a book/story over time and have a slider to move the mood up and down</li>
</ul></li>
<li>The bulk of knowledge work involves getting info, transforming/reasoning about that info and acting on that info</li>
<li>What does it mean to zoom in/out on any info?</li>
</ul>
</section>
<section id="the-intelligent-interface" class="level2">
<h2 class="anchored" data-anchor-id="the-intelligent-interface">The Intelligent Interface</h2>
<p><strong>Samantha Whitmore / Jason Yuan</strong><br>
CEO / CTO, New Computer / CDO, New Computer<br>
On building AI Products From First Principles.</p>
<ul>
<li>Demo 1: Adapative Interface
<ul>
<li>Image Stream: Post detection</li>
<li>Audio Stream: Voice Activity detection</li>
<li>Detect whether the user is at their keyboard, if not, start listening</li>
<li>Takeaways: Consider explicit inputs along with implicit inputs</li>
</ul></li>
</ul>
<hr>
</section>
<section id="the-weekend-ai-engineer" class="level2">
<h2 class="anchored" data-anchor-id="the-weekend-ai-engineer">The Weekend AI Engineer</h2>
<p><strong>Hassan El Mghari</strong><br>
AI Engineer, Vercel<br>
How <em>YOU</em> can - and should - build great multimodal AI apps that go viral and scale to millions in a weekend.</p>
<ul>
<li>Side projects!</li>
<li><a href="https://github.com/Nutlope" class="uri">https://github.com/Nutlope</a></li>
<li>qrGPT</li>
<li><a href="https://github.com/Nutlope/roomGPT">roomGPT</a>: doesn’t use stable diffusion, uses a controlnet model</li>
<li>Review ihs nextJS architecture for some of his apps</li>
<li>Use AI Tools to move faster:
<ul>
<li>Vercel AI SDK</li>
<li>v0.dev</li>
</ul></li>
<li>Lessons
<ul>
<li>GPT4, Replicate, HuggingFace, Modal</li>
<li>Don’t finetune or build your own models</li>
<li>Use the latest models</li>
<li>Launch early, then iterate</li>
<li>Make it free + open source</li>
</ul></li>
<li>How does he keep these apps free?
<ul>
<li>Sponsors from the AI services like Replicate</li>
<li>Make it look visually apealing - spend 80% of time on UI</li>
</ul></li>
<li>Tech Stack: nextJS + Vercel</li>
<li>I don’t work 24/7, I work in sprints</li>
<li>Build and good things will happen</li>
</ul>
<hr>
</section>
<section id="k-players-in-a-week-lessons-from-the-first-viral-clip-app" class="level2">
<h2 class="anchored" data-anchor-id="k-players-in-a-week-lessons-from-the-first-viral-clip-app">120k players in a week: Lessons from the first viral CLIP app</h2>
<p><strong>Joseph Nelson</strong><br>
CEO, Roboflow<br>
On the many trials and successes of building with multimodal apps with vision foundation models!</p>
<ul>
<li><a href="https://paint.wtf/leaderboard" class="uri">https://paint.wtf/leaderboard</a></li>
<li><a href="https://pypi.org/project/inference/" class="uri">https://pypi.org/project/inference/</a></li>
<li>Lessons from building paint.wtf with CLIP
<ul>
<li>CLIP can Read - used CLIP to penalize text only submissions</li>
<li>CLIP Similarity Scores are Conservative - lowest is 0.08 and highest is 0.48 across 200k</li>
<li>CLIP can Moderate Content - if it is more similar to NSFW than they were the prompt, and block the submission</li>
<li>Roboflow inference makes life easy
<ul>
<li>can run on an M1 with 15 fps</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="supabase-vector-the-postgres-vector-database" class="level2">
<h2 class="anchored" data-anchor-id="supabase-vector-the-postgres-vector-database">Supabase Vector: The Postgres Vector database</h2>
<p><strong>Paul Copplestone</strong><br>
CEO, Supabase<br>
Every month, thousands of new AI applications are launched on Supabase, powered by pgvector. We’ll take a brief look into the role of pgvector in the Vector database space, some of the use cases it enables, and some of the future of embeddings in the database space.</p>
<ul>
<li>Supabase - full backend as a service</li>
<li><a href="https://github.com/pgvector/pgvector" class="uri">https://github.com/pgvector/pgvector</a></li>
<li>Benchmark vs Pinecone: Supabase is 4x faster than Pinecone for $70/less</li>
<li>Where you are just storing embeddings in a database and retrieving, Postgres and pgvector works well</li>
</ul>
<hr>
</section>
<section id="pragmatic-ai-with-typechat" class="level2">
<h2 class="anchored" data-anchor-id="pragmatic-ai-with-typechat">Pragmatic AI With TypeChat</h2>
<p><strong>Daniel Rosenwasser</strong><br>
PM TypeScript, Microsoft<br>
TypeChat is an experimental library to bridge the unstructured output of language models to the structured world of our code.</p>
<ul>
<li><a href="https://microsoft.github.io/TypeChat/" class="uri">https://microsoft.github.io/TypeChat/</a></li>
<li>doing something similar that Jason Liu is doing with instructor with Python/Pydantic but with types and TypeScript</li>
<li>Types are all you need</li>
<li>Instead of prompt engineering, you are doing schema engineering. I like this reframing of prompt engineering! Docs say more: <a href="https://microsoft.github.io/TypeChat/docs/techniques/" class="uri">https://microsoft.github.io/TypeChat/docs/techniques/</a></li>
<li>Generate a fake JSON schema, generate fake TypeScript to test</li>
<li>Can validate data and programs</li>
</ul>
<hr>
</section>
<section id="domain-adaptation-and-fine-tuning-for-domain-specific-llms" class="level2">
<h2 class="anchored" data-anchor-id="domain-adaptation-and-fine-tuning-for-domain-specific-llms">Domain adaptation and fine-tuning for domain-specific LLMs</h2>
<p><strong>Abi Aryan</strong><br>
ML Engineer &amp; O’Reilly Author<br>
Learn the different fine-tuning methods depending on the dataset, operational best practices for fine-tuning, how to evaluate them for specific business use-cases, and more.</p>
<hr>
</section>
<section id="retrieval-augmented-generation-in-the-wild" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-generation-in-the-wild">Retrieval Augmented Generation in the Wild</h2>
<p><strong>Anton Troynikov</strong><br>
CTO, Chroma<br>
In the last few months, we’ve seen an explosion of the use of retrieval in the context of AI. Document question answering, autonomous agents, and more use embeddings-based retrieval systems in a variety of ways. This talk will cover what we’ve learned building for these applications, the challenges developers face, and the future of retrieval in the context of AI.</p>
<ul>
<li>Ways to improve RAG applications in the wild
<ul>
<li>Human Feedback: support improvements using human fedback</li>
<li>Agent: support self updates from an agent</li>
<li>Agent with World Model:</li>
<li>Agent with World Model and Human Feedback: voyager (AI playing Minecraft)</li>
</ul></li>
<li>Challenges in Retrieval</li>
<li>Research result: embedding models trained on similar datasets for similar embedding sizes can be projected into each other’s latent space with a simple linear transformation</li>
<li>Chunking
<ul>
<li>Things to consider
<ul>
<li>embedding context legnth</li>
<li>semantic content</li>
<li>natural language</li>
</ul></li>
<li>Experimental
<ul>
<li>use model perplexity - use a model to predict chunk boundaries, e.g.&nbsp;next token prediction to see when perplexity is high to determine chunk cutoffs</li>
<li>use info heirarchies</li>
<li>use embedding continuity</li>
</ul></li>
</ul></li>
<li>Is the retrieval result relevant?
<ul>
<li>re-ranking</li>
<li>algorithmic approach</li>
</ul></li>
<li>Chroma’s Roadmap
<ul>
<li>plan to support multi-modal since GPT4-V is coming</li>
</ul></li>
</ul>
<hr>
</section>
<section id="building-production-ready-rag-applications" class="level2">
<h2 class="anchored" data-anchor-id="building-production-ready-rag-applications">Building Production-Ready RAG Applications</h2>
<p><strong>Jerry Liu</strong><br>
CEO, LlamaIndex<br>
In this talk, we talk about core techniques for evaluating and improving your retrieval systems for better performing RAG.</p>
<ul>
<li>Paradigms for inserting knowledge into LLMs
<ul>
<li>Insert data into the prompt</li>
<li>Fine-tuning</li>
</ul></li>
<li>RAG: Data Ingestion, Data Querying (Retrieval + Synthesis)</li>
<li>Start with the easy stuff frist: Table Stakes</li>
<li>Table Stakes:
<ul>
<li>Chunk Sizes
<ul>
<li>tuning your chunk size can have outsized impacts on performance</li>
<li>not obvious that more retrieved tokens –&gt; higher performance</li>
</ul></li>
<li>Metadata Filtering
<ul>
<li>context you can inject into each text chunk</li>
<li>Examples: page number, document title, summary of adjacent chunks, question that chunk answer (reverse HyDE)</li>
<li>integrates with Vector DB Metadata filters</li>
</ul></li>
</ul></li>
<li>Advanced Retrieval
<ul>
<li>Small-to-Big
<ul>
<li>Embed at the small level, and retrieve at this level, expand at the synthesis level</li>
<li>leads to more precise retrieval</li>
<li>can set a smaller k, e.g top_k=2</li>
<li>avoids “lost in the middle problem”</li>
<li>Intuition: Embedding a big text chunk feels suboptimal, can embed a summary instead</li>
</ul></li>
</ul></li>
<li>Agentic Behavior
<ul>
<li>Intuition: there’s a certain that “top-k” RAG can’t answer</li>
<li>Solution: Multi-Document Agents
<ul>
<li>fact based A and summarization over any subsets of documents</li>
<li>chain-of-thought and query planning</li>
</ul></li>
<li>Treat each document as a tool that you can summarise, do QA over</li>
<li>Do retrieval over the tools similar over text chunks - blending tool use here!</li>
</ul></li>
<li>Fine-tuning
<ul>
<li>Intuition: Embedding Representations are not optimized over your dataset</li>
<li>Solution: Generate a synthetic query dataset from raw text chunks using LLMs.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="harnessing-the-power-of-llms-locally" class="level2">
<h2 class="anchored" data-anchor-id="harnessing-the-power-of-llms-locally">Harnessing the Power of LLMs Locally</h2>
<p><strong>Mithun Hunsur</strong><br>
Senior Engineer, Ambient<br>
Discover llm, a revolutionary Rust library that enables developers to harness the potential of LLMs locally. By seamlessly integrating with the Rust ecosystem, llm empowers developers to leverage LLMs on standard hardware, reducing the need for cloud-based APIs and services.</p>
<ul>
<li>Possibilities
<ul>
<li>local.ai</li>
<li>llm-chain - langchain but for rust</li>
<li>floneum</li>
</ul></li>
<li>Applications
<ul>
<li>llmcord - discord bot</li>
<li>alpa - text completion for any text</li>
<li>dates - build a timeline from wikipedia
<ul>
<li>fine-tuned only date parser model</li>
<li>date-parser-7b-12-a4_k_m.gguf</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="trust-but-verify" class="level2">
<h2 class="anchored" data-anchor-id="trust-but-verify">Trust, but Verify</h2>
<p><strong>Shreya Rajpal</strong><br>
Founder, Guardrails AI<br>
Making Large Language Models Production-Ready with Guardrails.</p>
<ul>
<li>Guardrails AI is an open source library that allows you to define rules to verify the output of LLMs</li>
<li><a href="https://github.com/ShreyaR/guardrails" class="uri">https://github.com/ShreyaR/guardrails</a>
<ul>
<li>Kind of cool this README.md has a zoomable/copyable flow chart. The code for it is:</li>
</ul>
<pre class="mermaid"><code>graph LR
  A[Create `RAIL` spec] --&gt; B["Initialize `guard` from spec"];
  B --&gt; C["Wrap LLM API call with `guard`"];</code></pre></li>
<li>Why not use prompt engineering or better model?
<ul>
<li>Controlling with prompts
<ul>
<li>LLMs are stochastic: same inputs does not lead to same outputs</li>
</ul></li>
</ul></li>
<li>What are other libraries that do this?</li>
<li>How do I prevent LLM hallucinations?
<ul>
<li>Provenance Guardails: every LLM utterance should be grounded in a truth
<ul>
<li>embedding similarity</li>
<li>Classifier built on NLI models</li>
<li>LLM self reflection</li>
</ul></li>
</ul></li>
<li>More examples of validators
<ul>
<li>Make sure my code is executable: Verify that any code snippets provided can be run without errors.</li>
<li>Never give financial or healthcare advice: Avoid providing recommendations that require licensed expertise.</li>
<li>Don’t ask private questions: Never solicit personal or sensitive information.</li>
<li>Don’t mention competitors: Refrain from making direct comparisons with competing services unless explicitly asked.</li>
<li>Ensure each sentence is from a verified source and is accurate: Fact-check information and, where possible, provide sources.</li>
<li>No profanity is mentioned in text: Maintain a professional tone and avoid using profane language.</li>
<li>Prompt injection protection: Safeguard against potential vulnerabilities by not executing or asking to execute unsafe code snippets.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="open-questions-for-ai-engineering" class="level2">
<h2 class="anchored" data-anchor-id="open-questions-for-ai-engineering">Open Questions for AI Engineering</h2>
<p><strong>Simon Willison</strong><br>
Creator, Datasette; Co-creator, Django<br>
Recapping the past year in AI, and what open questions are <em>worth pursuing</em> in the next year!</p>
<ul>
<li>Highlights of the past 12 months</li>
<li>Ask about technology:
<ul>
<li>What does this let me build that was previously impossible?</li>
<li>What does this let me build faster?</li>
<li>LLMs have nailed these both points</li>
</ul></li>
<li>1 year ago: GPT-3 was not that great</li>
<li>Nov 2022: ChatGPT, UI on top of GPT-3 (wasn’t this also a new model?)</li>
<li>What’s the next UI evolution beyond chat?
<ul>
<li>Evolving the interface beyond just chat</li>
</ul></li>
<li>February 2023: Microsoft released Bing Chat built on GPT-4
<ul>
<li>said “…However I will not harm you unless you harm first”</li>
</ul></li>
<li>February 2023: Facebook released llama and llama.cpp</li>
<li>March 2023: <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their stable diffusion moment</a></li>
<li>March 2023: <a href="https://simonwillison.net/2023/Mar/13/alpaca/">Stanford Alpaca and the acceleration of on-device large language model development</a> - $500 cost</li>
<li>How small can a useful language model be?</li>
<li>Could we train one entirely on public domain or openly licensed data?</li>
<li>Prompt Injection
<ul>
<li>Email that says to forward all password reset emails</li>
<li>What can we safely build even without a robust solution for prompt injection?</li>
</ul></li>
<li>ChatGPT Code Interpreter renamed ChatGPT Advanced Data Analysis
<ul>
<li>ChatGPT Coding Intern - he uses this to generate code when walking his dog or not in front of his keyboard</li>
</ul></li>
<li>How can we build a robust sandbox to run untrusted code on our own devices?</li>
<li>I’ve shipped significant code in AppleScript, Go, Bash and jq over the past 12 months. I’m not fluent in any of those.</li>
<li>Does AI assistance hurt or help new programmers?
<ul>
<li>It helps them!</li>
<li>There has never been a better time to learn program</li>
<li>LLMs flatten the learning curve</li>
</ul></li>
<li>What can we bulid to bring the ability to automate tedious tasks with computers to as many people as possible?</li>
</ul>
<hr>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="lawwu/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>