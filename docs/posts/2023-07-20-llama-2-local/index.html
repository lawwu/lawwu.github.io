<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Lawrence Wu">
<meta name="dcterms.date" content="2023-07-20">

<title>Lawrence Wu - Running Llama2 Locally on a M1 Mac</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/cookie-consent/cookie-consent.js"></script>
<link href="../../site_libs/cookie-consent/cookie-consent.css" rel="stylesheet">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-LN4GM4FVCJ"></script>

<script type="text/plain" cookie-consent="tracking">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-LN4GM4FVCJ', { 'anonymize_ip': true});
</script>

<script type="text/javascript" charset="UTF-8">
document.addEventListener('DOMContentLoaded', function () {
cookieconsent.run({
  "notice_banner_type":"simple",
  "consent_type":"implied",
  "palette":"light",
  "language":"en",
  "page_load_consent_levels":["strictly-necessary","functionality","tracking","targeting"],
  "notice_banner_reject_button_hide":false,
  "preferences_center_close_button_hide":false,
  "website_name":""
  });
});
</script> 
  


<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Lawrence Wu - Running Llama2 Locally on a M1 Mac">
<meta property="og:description" content="">
<meta property="og:image" content="https://lawwu.github.io/blog.html/posts/2023-07-20-llama-2-local/ds_vs_de.png">
<meta property="og:site-name" content="Lawrence Wu">
<meta property="og:image:height" content="1366">
<meta property="og:image:width" content="2870">
<meta name="twitter:title" content="Lawrence Wu - Running Llama2 Locally on a M1 Mac">
<meta name="twitter:description" content="">
<meta name="twitter:image" content="https://lawwu.github.io/blog.html/posts/2023-07-20-llama-2-local/ds_vs_de.png">
<meta name="twitter:creator" content="@law_wu">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image-height" content="1366">
<meta name="twitter:image-width" content="2870">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Lawrence Wu</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../blog.html" rel="" target="">
 <span class="menu-text">Blog</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="../../ai_resources.html" rel="" target="">
 <span class="menu-text">AI Resources</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://github.com/lawwu" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text">GitHub</span></a>
  </li>  
  <li class="nav-item">
    <a class="nav-link" href="https://twitter.com/law_wu" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text">Twitter</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="mailto:lawrencewu1+blog@gmail.com" rel="" target=""><i class="bi bi-envelope" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="../../blog.xml" rel="" target=""><i class="bi bi-rss" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#llama2" id="toc-llama2" class="nav-link active" data-scroll-target="#llama2">Llama2</a></li>
  <li><a href="#running-llama2-locally-on-a-mac" id="toc-running-llama2-locally-on-a-mac" class="nav-link" data-scroll-target="#running-llama2-locally-on-a-mac">Running Llama2 locally on a Mac</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a></li>
  <li><a href="#benefits-of-a-language-model-locally" id="toc-benefits-of-a-language-model-locally" class="nav-link" data-scroll-target="#benefits-of-a-language-model-locally">Benefits of a Language Model Locally</a></li>
  <li><a href="#asitop" id="toc-asitop" class="nav-link" data-scroll-target="#asitop">Asitop</a></li>
  <li><a href="#llama.cpp-output" id="toc-llama.cpp-output" class="nav-link" data-scroll-target="#llama.cpp-output">llama.cpp output</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Running Llama2 Locally on a M1 Mac</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLMs</div>
    <div class="quarto-category">Llama</div>
  </div>
  </div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Lawrence Wu </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">July 20, 2023</p>
    </div>
  </div>
  
    
  </div>
  

</header>

<section id="llama2" class="level1">
<h1>Llama2</h1>
<p>Llama2 was released by Meta 2 days ago. See the:</p>
<ul>
<li><a href="https://ai.meta.com/llama/">blog post</a></li>
<li><a href="https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/">technical paper</a></li>
</ul>
<p>Nathan Lambert has a <a href="https://www.interconnects.ai/p/llama-2-from-meta?sd=pf">nice writeup</a> of his thoughts on the model. And AI Explained has a nice <a href="https://www.youtube.com/watch?v=zJBpRn2zTco&amp;ab_channel=AIExplained">video breakdown</a>.</p>
</section>
<section id="running-llama2-locally-on-a-mac" class="level1">
<h1>Running Llama2 locally on a Mac</h1>
<p>I saw this <a href="https://twitter.com/AdrienBrault/status/1681606803522461696">tweet</a> yesterday about running the model locally on a M1 mac and tried it. The instructions are just in this <a href="https://gist.github.com/adrienbrault/b76631c56c736def9bc1bc2167b5d129">gist</a> and it was trivial to setup. The below script uses the <code>llama-2-13b-chat.ggmlv3.q4_0.bin</code> model file but you can find other versions of the llama2-13-chat model on <a href="https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML">Huggingface here</a>. It’s truly amazing how quickly new model releases get ported over to llama.cpp and quantized (1-2 days).</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Clone llama.cpp</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/ggerganov/llama.cpp.git</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> llama.cpp</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Build it</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="va">LLAMA_METAL</span><span class="op">=</span>1 <span class="fu">make</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Download model</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="bu">export</span> <span class="va">MODEL</span><span class="op">=</span>llama-2-13b-chat.ggmlv3.q4_0.bin</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="fu">wget</span> <span class="st">"https://huggingface.co/TheBloke/Llama-2-13B-chat-GGML/resolve/main/</span><span class="va">${MODEL}</span><span class="st">"</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Run</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="bu">echo</span> <span class="st">"Prompt: "</span> <span class="dt">\</span></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&amp;&amp;</span> <span class="bu">read</span> <span class="va">PROMPT</span> <span class="dt">\</span></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">&amp;&amp;</span> <span class="ex">./main</span> <span class="dt">\</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>        <span class="at">-t</span> 8 <span class="dt">\</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>        <span class="at">-ngl</span> 1 <span class="dt">\</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a>        <span class="at">-m</span> <span class="va">${MODEL}</span> <span class="dt">\</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a>        <span class="at">--color</span> <span class="dt">\</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a>        <span class="at">-c</span> 2048 <span class="dt">\</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a>        <span class="at">--temp</span> 0.7 <span class="dt">\</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>        <span class="at">--repeat_penalty</span> 1.1 <span class="dt">\</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>        <span class="at">-n</span> <span class="at">-1</span> <span class="dt">\</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>        <span class="at">-p</span> <span class="st">"[INST] </span><span class="va">${PROMPT}</span><span class="st"> [/INST]"</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="results" class="level1">
<h1>Results</h1>
<p>This is the first time I’ve ever run an LLM locally using the GPU on my Mac! One prompt I tried was “What’s the difference between data science and data engineering?” Getting about 15 tokens a second and the answer was quite good:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./ds_vs_de.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Llama2: Data Science vs Data Engineering</figcaption>
</figure>
</div>
<p>Another prompt I tried was, “What’s the meaning of life”, not because I was necessarily wondering what llama2 thought the meaning of life was, but because I had read a paper earlier in the day called <a href="https://arxiv.org/abs/2301.04246">Generative Language Models and Automated Influence Operations: Emerging Threats and Potential Mitigations</a>. One of the tables in the paper showed the progress language models have made over the years and the prompt used to showcae this was “What is the meaning of life?”</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./paper_meaning_of_life.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Meaning of Life Progress in Language Models</figcaption>
</figure>
</div>
<p>The progress from 2011 to 2020 was meaningful. But the progress from 2020 to 2023 is also quite impressive. Here is what llama2 had to say for the same prompt:</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./meaning_of_life.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Llama2: Meaning of Life</figcaption>
</figure>
</div>
<p>The model also is able to give strong answers by modifying the previous prompt asking it to wear different hats as a Christian or a Muslim:</p>
<ul>
<li>As a Christian, what is the meaning of life?</li>
<li>As a Muslim, what is the maning of life?</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./meaning_of_life_christian.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Llama2: Meaning of Life for a Christian</figcaption>
</figure>
</div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./meaning_of_life_muslim.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Llama2: Meaning of Life for a Muslim</figcaption>
</figure>
</div>
</section>
<section id="benefits-of-a-language-model-locally" class="level1">
<h1>Benefits of a Language Model Locally</h1>
<p>Running a language model locally can have several benefits compared to using a cloud-based service. Here are some of the advantages of running a language model locally:</p>
<ol type="1">
<li>Control and customization: When you run a language model locally, you have complete control over the model and its behavior. You can customize the model to fit your specific needs and requirements, which may not be possible with a cloud-based service.</li>
<li>Privacy and security: By running the model locally, you can keep your data and models private and secure. You don’t have to worry about sensitive information being transmitted over the internet or stored on external servers.</li>
<li>Faster response times: Local models can respond faster than cloud-based services because they don’t require network latency. This is particularly important for applications that require real-time responses, such as chatbots or voice assistants.</li>
<li>Offline capabilities: With a local language model, you can still use the model even when you don’t have internet access. This is useful for applications that need to work offline or in areas with limited connectivity.</li>
<li>Cost-effective: Running a language model locally can be more cost-effective than using a cloud-based service, especially for large-scale deployments. You don’t have to pay for network bandwidth, data storage, or other cloud-based services.</li>
<li>Better performance: Depending on the specific use case, a local language model may perform better than a cloud-based service. This is because you can optimize the model and hardware for your specific use case, which may not be possible with a cloud-based service.</li>
<li>More flexibility: With a local language model, you have more flexibility to experiment with different architectures, hyperparameters, and training strategies. You can also more easily integrate the model with other systems and applications.</li>
<li>Better understanding of data: When you run a language model locally, you have more visibility into your data and how it’s being processed. This can help you better understand your data and improve your model’s performance.</li>
<li>Improved explainability: Local language models can provide more explainability than cloud-based services. You can see exactly how the model is processing your data and make changes to improve its transparency and accountability.</li>
<li>Better integration with other systems: When you run a language model locally, it’s easier to integrate with other systems and applications. You can customize the model to fit your specific needs and requirements, which may not be possible with a cloud-based service.</li>
</ol>
<p>Overall, running a language model locally can provide several benefits, including control, privacy, faster response times, offline capabilities, cost-effectiveness, better performance, more flexibility, better understanding of data, improved explainability, and better integration with other systems. However, it’s important to carefully evaluate the trade-offs between local and cloud-based models based on your specific use case and requirements.</p>
<p>Note the above was generated by llama2.</p>
</section>
<section id="asitop" class="level1">
<h1>Asitop</h1>
<p>You can also use this library <a href="https://github.com/tlkh/asitop">asitop</a> to monitor your GPU locally on a Mac.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="./asitop.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Asitop</figcaption>
</figure>
</div>
</section>
<section id="llama.cpp-output" class="level1">
<h1>llama.cpp output</h1>
<p>Running this in a terminal produces a bunch of llama.cpp output:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="ex">main:</span> build = 852 <span class="er">(</span><span class="ex">294f424</span><span class="kw">)</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="ex">main:</span> seed  = 1689913536</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="ex">llama.cpp:</span> loading model from llama-2-13b-chat.ggmlv3.q4_0.bin</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> format     = ggjt v3 <span class="er">(</span><span class="ex">latest</span><span class="kw">)</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_vocab    = 32000</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_ctx      = 2048</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_embd     = 5120</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_mult     = 256</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_head     = 40</span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_layer    = 40</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_rot      = 128</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> freq_base  = 10000.0</span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> freq_scale = 1</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> ftype      = 2 <span class="er">(</span><span class="ex">mostly</span> Q4_0<span class="kw">)</span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> n_ff       = 13824</span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> model size = 13B</span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> ggml ctx size =    0.09 MB</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_model_load_internal:</span> mem required  = 8953.71 MB <span class="er">(</span><span class="ex">+</span> 1608.00 MB per state<span class="kw">)</span></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_new_context_with_model:</span> kv self size  = 1600.00 MB</span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> allocating</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> using MPS</span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loading <span class="st">'/Users/lawrence.wu/Documents/github/llama.cpp/ggml-metal.metal'</span></span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_add                            0x150f081b0</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul                            0x150f088d0</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_row                        0x150f08df0</span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_scale                          0x150f09310</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_silu                           0x150f09830</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_relu                           0x150f09d50</span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_gelu                           0x150f0a270</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_soft_max                       0x150f0a920</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_diag_mask_inf                  0x150f0af80</span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_f16                   0x150f0b600</span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q4_0                  0x150f0bc80</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q4_1                  0x150f0c470</span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q2_K                  0x150f0caf0</span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q3_K                  0x150f0d170</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q4_K                  0x150f0d7f0</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q5_K                  0x150f0de70</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_get_rows_q6_K                  0x150f0e4f0</span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_rms_norm                       0x150f0eba0</span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_norm                           0x150f0f250</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_f16_f32                0x150f0fc20</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q4_0_f32               0x150f102e0</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q4_1_f32               0x150f109a0</span>
<span id="cb2-45"><a href="#cb2-45" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q2_K_f32               0x150f11080</span>
<span id="cb2-46"><a href="#cb2-46" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q3_K_f32               0x150f11900</span>
<span id="cb2-47"><a href="#cb2-47" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q4_K_f32               0x150f11fe0</span>
<span id="cb2-48"><a href="#cb2-48" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q5_K_f32               0x150f126c0</span>
<span id="cb2-49"><a href="#cb2-49" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_mul_mat_q6_K_f32               0x150f12da0</span>
<span id="cb2-50"><a href="#cb2-50" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_rope                           0x150f134c0</span>
<span id="cb2-51"><a href="#cb2-51" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_alibi_f32                      0x150f13d80</span>
<span id="cb2-52"><a href="#cb2-52" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_cpy_f32_f16                    0x150f14870</span>
<span id="cb2-53"><a href="#cb2-53" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_cpy_f32_f32                    0x150f15100</span>
<span id="cb2-54"><a href="#cb2-54" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> loaded kernel_cpy_f16_f16                    0x103105370</span>
<span id="cb2-55"><a href="#cb2-55" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> recommendedMaxWorkingSetSize = 21845.34 MB</span>
<span id="cb2-56"><a href="#cb2-56" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> hasUnifiedMemory             = true</span>
<span id="cb2-57"><a href="#cb2-57" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_init:</span> maxTransferRate              = built-in GPU</span>
<span id="cb2-58"><a href="#cb2-58" aria-hidden="true" tabindex="-1"></a><span class="ex">llama_new_context_with_model:</span> max tensor size =    87.89 MB</span>
<span id="cb2-59"><a href="#cb2-59" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_add_buffer:</span> allocated <span class="st">'data            '</span> buffer, size =  6984.06 MB, <span class="er">(</span> <span class="ex">6984.52</span> / 21845.34<span class="kw">)</span></span>
<span id="cb2-60"><a href="#cb2-60" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_add_buffer:</span> allocated <span class="st">'eval            '</span> buffer, size =  1032.00 MB, <span class="er">(</span> <span class="ex">8016.52</span> / 21845.34<span class="kw">)</span></span>
<span id="cb2-61"><a href="#cb2-61" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_add_buffer:</span> allocated <span class="st">'kv              '</span> buffer, size =  1602.00 MB, <span class="er">(</span> <span class="ex">9618.52</span> / 21845.34<span class="kw">)</span></span>
<span id="cb2-62"><a href="#cb2-62" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_add_buffer:</span> allocated <span class="st">'scr0            '</span> buffer, size =   426.00 MB, <span class="er">(</span><span class="ex">10044.52</span> / 21845.34<span class="kw">)</span></span>
<span id="cb2-63"><a href="#cb2-63" aria-hidden="true" tabindex="-1"></a><span class="ex">ggml_metal_add_buffer:</span> allocated <span class="st">'scr1            '</span> buffer, size =   512.00 MB, <span class="er">(</span><span class="ex">10556.52</span> / 21845.34<span class="kw">)</span></span>
<span id="cb2-64"><a href="#cb2-64" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-65"><a href="#cb2-65" aria-hidden="true" tabindex="-1"></a><span class="ex">system_info:</span> n_threads = 8 / 10 <span class="kw">|</span> <span class="ex">AVX</span> = 0 <span class="kw">|</span> <span class="ex">AVX2</span> = 0 <span class="kw">|</span> <span class="ex">AVX512</span> = 0 <span class="kw">|</span> <span class="ex">AVX512_VBMI</span> = 0 <span class="kw">|</span> <span class="ex">AVX512_VNNI</span> = 0 <span class="kw">|</span> <span class="ex">FMA</span> = 0 <span class="kw">|</span> <span class="ex">NEON</span> = 1 <span class="kw">|</span> <span class="ex">ARM_FMA</span> = 1 <span class="kw">|</span> <span class="ex">F16C</span> = 0 <span class="kw">|</span> <span class="ex">FP16_VA</span> = 1 <span class="kw">|</span> <span class="ex">WASM_SIMD</span> = 0 <span class="kw">|</span> <span class="ex">BLAS</span> = 1 <span class="kw">|</span> <span class="ex">SSE3</span> = 0 <span class="kw">|</span> <span class="ex">VSX</span> = 0 <span class="kw">|</span></span>
<span id="cb2-66"><a href="#cb2-66" aria-hidden="true" tabindex="-1"></a><span class="ex">sampling:</span> repeat_last_n = 64, repeat_penalty = 1.100000, presence_penalty = 0.000000, frequency_penalty = 0.000000, top_k = 40, tfs_z = 1.000000, top_p = 0.950000, typical_p = 1.000000, temp = 0.700000, mirostat = 0, mirostat_lr = 0.100000, mirostat_ent = 5.000000</span>
<span id="cb2-67"><a href="#cb2-67" aria-hidden="true" tabindex="-1"></a><span class="ex">generate:</span> n_ctx = 2048, n_batch = 512, n_predict = <span class="at">-1,</span> n_keep = 0</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<script src="https://utteranc.es/client.js" repo="lawwu/blog_comments" issue-term="pathname" theme="github-light" crossorigin="anonymous" async="">
</script>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center"><div class="cookie-consent-footer"><a href="#" id="open_preferences_center">Cookie Preferences</a></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>



</body></html>