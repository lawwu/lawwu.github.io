<?xml version="1.0" encoding="UTF-8"?>
<rss  xmlns:atom="http://www.w3.org/2005/Atom" 
      xmlns:media="http://search.yahoo.com/mrss/" 
      xmlns:content="http://purl.org/rss/1.0/modules/content/" 
      xmlns:dc="http://purl.org/dc/elements/1.1/" 
      version="2.0">
<channel>
<title>Lawrence Wu</title>
<link>https://lawwu.github.io/blog.html/conferences.html</link>
<atom:link href="https://lawwu.github.io/blog.html/conferences.xml" rel="self" type="application/rss+xml"/>
<description>This is Lawrence Wu&#39;s personal website</description>
<generator>quarto-1.8.25</generator>
<lastBuildDate>Fri, 30 May 2025 00:00:00 GMT</lastBuildDate>
<item>
  <title>LangChain Interrupt Agent Conference 2025</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2025-05-30-langchain-interrupt-2025/</link>
  <description><![CDATA[ 




<p>Some content related to the LangChain Conference:</p>
<ul>
<li><a href="https://lawwu.github.io/posts/2025-05-30-langchain-interrupt-lwu-recap/" class="uri">https://lawwu.github.io/posts/2025-05-30-langchain-interrupt-lwu-recap/</a></li>
<li><a href="https://lawwu.github.io/posts/2025-05-23-langchain-interrupt-2025-recap/" class="uri">https://lawwu.github.io/posts/2025-05-23-langchain-interrupt-2025-recap/</a></li>
</ul>



 ]]></description>
  <category>Conference</category>
  <category>LangChain</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2025-05-30-langchain-interrupt-2025/</guid>
  <pubDate>Fri, 30 May 2025 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Marriage</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-1-marriage/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3.5 Sonnet.</p>
<section id="summary-of-john-streets-marriage-seminar" class="level1">
<h1>Summary of John Street’s Marriage Seminar</h1>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main Points</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=284s">4:44</a> God designed marriage, not humans</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=1916s">31:56</a> Marriage is given by God as a covenant relationship</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=2091s">34:51</a> Marriage is not to compete with human options or substitutes</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=2378s">39:38</a> The primary purpose of marriage is companionship, not procreation</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3181s">53:01</a> The parent-child relationship is intended to be temporary, while the husband-wife relationship is permanent</li>
</ol>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=902s">15:02</a> Contemporary societal views on marriage (e.g., trial marriages, contract marriages) contradict God’s design</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=1590s">26:30</a> Adam’s naming of the animals demonstrates his loneliness and need for a suitable companion</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=2818s">46:58</a> The foundation of marriage should be commitment, not romantic feelings</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3418s">56:58</a> Becoming “one flesh” involves unity in all aspects of life, not just physical intimacy</li>
</ol>
</section>
<section id="bible-verses" class="level2">
<h2 class="anchored" data-anchor-id="bible-verses">Bible Verses</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=1569s">26:09</a> Genesis 1:26-27 - Discusses the creation of man and woman in God’s image</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=2196s">36:36</a> Genesis 2:18 - “It is not good for man to be alone”</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3027s">50:27</a> Genesis 2:24 - Describes leaving, cleaving, and becoming one flesh in marriage</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3043s">50:43</a> Proverbs 2:17 and Malachi 2:14 - Referenced to describe marriage as a covenant</li>
</ol>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3476s">57:56</a> Prioritize the spouse over children in daily life (e.g., serving food, opening car doors)</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3592s">59:52</a> Base marriage on commitment rather than feelings or what the other person brings to the relationship</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=4073s">1:07:53</a> Work towards unity in all aspects of life (e.g., parenting philosophy, finances, spiritual views)</li>
<li><a href="https://www.youtube.com/watch?v=SMrCnTZUYS8&amp;t=3934s">1:05:34</a> Understand that losing some individuality in marriage is positive, leading to true companionship</li>
</ol>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>John Street’s marriage seminar presents a biblical perspective on the institution of marriage, emphasizing its divine origin and purpose. The central message is that God designed marriage as a covenant relationship primarily for companionship, not procreation or personal fulfillment. Street argues against contemporary societal views that undermine the permanence and sanctity of marriage, using Scripture to support his points.</p>
<p>Throughout the seminar, Street uses biblical passages, particularly from Genesis, to illustrate God’s intentions for marriage. He contrasts these with modern concepts like trial marriages and robotic companions, arguing that these deviate from God’s design. The seminar emphasizes the importance of commitment over feelings, the permanence of the marital relationship compared to the temporary nature of the parent-child relationship, and the concept of “becoming one flesh” in all aspects of life.</p>
<p>Street’s approach to marriage is deeply rooted in biblical teaching, presenting a conservative, traditional view of marital roles and purposes. He challenges modern cultural norms and encourages couples to base their marriages on God’s design rather than societal trends or personal desires.</p>
</section>
<section id="recurring-themes" class="level2">
<h2 class="anchored" data-anchor-id="recurring-themes">Recurring Themes</h2>
<ul>
<li>The divine origin of marriage</li>
<li>The primacy of the marital relationship over all other human relationships</li>
<li>The importance of commitment and covenant in marriage</li>
<li>The contrast between biblical marriage and contemporary societal views</li>
<li>The comprehensive nature of marital unity (“one flesh”)</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-1-marriage/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Husbands</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-2-husbands/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3 Opus and Claude 3.5 Sonnet. I actually preferred Claude 3.5 Sonnet’s summary. See the appendix for the Opus summary.</p>
<section id="summary-of-john-streets-marriage-seminar" class="level1">
<h1>Summary of John Street’s Marriage Seminar</h1>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main Points</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=42s">00:00:42</a> God’s design for husbands includes clear roles and responsibilities</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=978s">00:16:18</a> Three key areas for husbands to remember: Learner, Lover, Leader</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1406s">00:23:26</a> Husbands must be learners of their wives</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=2499s">00:41:39</a> Husbands must be Christ-like lovers</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=3201s">00:53:21</a> Husbands must be godly leaders</li>
</ol>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=301s">00:05:01</a> The curse in Genesis 3 resulted in a struggle for control between husbands and wives</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1225s">00:20:25</a> Husbands must dwell with their wives knowledgeably, requiring time and effort</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=2558s">00:42:38</a> Biblical love gives to a woman rather than takes from her</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=3399s">00:56:39</a> Godly leadership is not about being a dictator but about setting an example</li>
</ol>
</section>
<section id="bible-verses" class="level2">
<h2 class="anchored" data-anchor-id="bible-verses">Bible Verses</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1034s">00:17:14</a> Matthew 20:25-28 - Contrasting worldly leadership with servant leadership</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1404s">00:23:24</a> 1 Peter 3:7 - Husbands living with wives in an understanding way</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=2502s">00:41:42</a> Ephesians 5:25 - Husbands loving wives as Christ loved the church</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=3185s">00:53:05</a> Ephesians 5:23-24 - Husband as head of the wife</li>
</ol>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1903s">00:31:43</a> Study your wife’s unique gifts, abilities, and struggles</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=2856s">00:47:36</a> Love your wife first, most, and unmistakably</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=3470s">00:57:50</a> Set godly goals for your marriage and family</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=3543s">00:59:03</a> Be a joy to live with, not a source of stress for your family</li>
</ol>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>John Street’s marriage seminar focuses on God’s design for husbands, emphasizing three key roles: learner, lover, and leader. The central message revolves around the idea that husbands have a divine responsibility to understand their wives deeply, love them sacrificially, and lead them spiritually.</p>
<p>Street uses biblical passages to support his arguments, particularly drawing from Genesis, Ephesians, and 1 Peter. He contrasts worldly notions of leadership and love with biblical concepts, emphasizing servant leadership and sacrificial love modeled after Christ’s relationship with the church.</p>
<p>The seminar presents a complementarian approach to marriage, where husbands and wives have distinct roles, but the husband’s leadership is characterized by servanthood rather than domination. Street consistently emphasizes the husband’s responsibility to initiate love, understanding, and spiritual growth in the marriage.</p>
</section>
<section id="recurring-themes" class="level2">
<h2 class="anchored" data-anchor-id="recurring-themes">Recurring Themes</h2>
<ul>
<li>The impact of sin on marital relationships</li>
<li>The contrast between worldly and biblical concepts of love and leadership</li>
<li>The importance of intentionality in understanding and loving one’s wife</li>
<li>The connection between a husband’s treatment of his wife and his spiritual life</li>
</ul>
</section>
</section>
<section id="appendix" class="level1">
<h1>Appendix</h1>
<p>Claude 3 Opus Summary</p>
<section id="john-streets-marriage-seminar-analysis" class="level2">
<h2 class="anchored" data-anchor-id="john-streets-marriage-seminar-analysis">John Street’s Marriage Seminar Analysis</h2>
<section id="main-points-1" class="level3">
<h3 class="anchored" data-anchor-id="main-points-1">Main Points</h3>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=42m52s">00:42:52</a> To be a godly husband, you need to be a learner of your wife, studying her and knowing her better than anyone else.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=50m55s">00:50:55</a> Husbands are called to be Christ-like lovers, loving their wives as sacrificially as Christ loved the church.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=55m23s">00:55:23</a> Husbands should be leaders in the marriage and home, providing humble, servant-hearted leadership.</li>
</ol>
</section>
<section id="arguments-1" class="level3">
<h3 class="anchored" data-anchor-id="arguments-1">Arguments</h3>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=24m40s">00:24:40</a> God’s curse after the Fall introduced conflict in marriage, with the wife desiring to control her husband and the husband ruling over his wife. This is not God’s original intent.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=38m35s">00:38:35</a> The world’s view of leadership is about exercising top-down authority, but Jesus modeled servant leadership which should be applied in marriage.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=50m28s">00:50:28</a> The Bible assumes husbands already love themselves a lot. They need to love their wives more than their natural tendency toward self-love.</li>
</ol>
</section>
<section id="bible-verses-1" class="level3">
<h3 class="anchored" data-anchor-id="bible-verses-1">Bible Verses</h3>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=11m52s">00:11:52</a> Genesis 3:16 - Describes the curse on the woman, that her desire will be for her husband and he will rule over her.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=38m13s">00:38:13</a> Matthew 20:25-28 - Jesus teaches that worldly leadership is about lording authority over others, but whoever wants to be great must be a servant.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=53m07s">00:53:07</a> Ephesians 5:23-25 - Instructs husbands to love their wives as Christ loved the church, and to be the head of the wife as Christ is head of the church.</li>
</ol>
</section>
<section id="practical-applications-1" class="level3">
<h3 class="anchored" data-anchor-id="practical-applications-1">Practical Applications</h3>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=44m27s">00:44:27</a> Husbands should give focused attention to their wives, treating her as a precious gift to be cherished and honored.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=55m50s">00:55:50</a> Godly leadership is not about making all the decisions but valuing the wife’s input and perspective. Husbands should lead by example, not force.</li>
<li><a href="https://www.youtube.com/watch?v=gC2bM77vS4A&amp;t=1h1m03s">01:01:03</a> Husbands should aim to be a joy for their wives and families to be around, not bringing stress from work into the home.</li>
</ol>
</section>
<section id="overview-1" class="level3">
<h3 class="anchored" data-anchor-id="overview-1">Overview</h3>
<p>The central message of John Street’s seminar is that husbands are called to humble, Christ-like leadership and love in their marriages. He argues that sin has distorted the marriage relationship, but husbands can live out God’s intent by prioritizing knowing their wives, sacrificially loving them, and providing servant leadership in the home.</p>
<p>Street supports his main points with biblical arguments, drawing from Genesis, Jesus’ teachings, and Paul’s household instructions. He emphasizes that the world’s self-centered view of leadership and love is contrary to the other-oriented, sacrificial mindset Christian husbands should cultivate.</p>
<p>Throughout the seminar, Street provides practical advice for husbands to implement these principles. Key applications include intentionally learning about one’s wife, cherishing her as a precious gift, humbly leading by example, and bringing joy into the home.</p>
<p>Recurring themes include the impact of the Fall on marriage, contrasting worldly and biblical mindsets, and specific ways husbands can sacrificially love and lead like Christ. Street’s overall approach emphasizes the husband’s weighty responsibility to shape the marriage according to God’s Word and the power of living out these truths.</p>
<p>The transcript appears to cover the seminar content clearly, without major ambiguities. Street’s points are well-developed and supported by scripture and practical illustrations.</p>


</section>
</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <category>Husbands</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-2-husbands/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Wives</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-3-wives/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3.5 Sonnet.</p>
<section id="summary-of-john-streets-marriage-seminar" class="level1">
<h1>Summary of John Street’s Marriage Seminar</h1>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main Points</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=25s">00:00:25</a> Three things for a godly husband: learner, lover, leader</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=63s">00:01:03</a> Marriage became a battleground of the sexes after the Fall</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=330s">00:05:30</a> Biblical submission is misunderstood in modern culture</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2195s">00:36:35</a> Three things for a godly wife: submission, suitable helper, selflessly reverent</li>
</ol>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=420s">00:07:00</a> Submission doesn’t mean inequality, as demonstrated by the Trinity</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=836s">00:13:56</a> Submission doesn’t mean intellectual stagnation or being a doormat</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=911s">00:15:11</a> Submissive people can be highly influential, like Jesus</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2018s">00:33:38</a> A wife’s primary ministry should be her husband</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2563s">00:42:43</a> Respecting and honoring a husband has a humbling effect, not an ego-boosting one</li>
</ol>
</section>
<section id="bible-verses" class="level2">
<h2 class="anchored" data-anchor-id="bible-verses">Bible Verses</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=50s">00:00:50</a> Genesis 3:16 - Explains the curse and its effect on marriage</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=378s">00:06:18</a> Ephesians 5:22-24 - Instructions for wives to submit to their husbands</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=1679s">00:27:59</a> 1 Peter 3:1-6 - How wives should live with unbelieving husbands</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=1977s">00:32:57</a> 1 Timothy 2:13-15 - Explains the basis for submission in creation order</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2492s">00:41:32</a> Ephesians 5:33 - Summary verse on husband’s love and wife’s respect</li>
</ol>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=1187s">00:19:47</a> Wives should use their intellect to complement their husbands and further the marriage</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=1796s">00:29:56</a> Wives should win over unbelieving husbands through conduct, not words</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=1887s">00:31:27</a> Focus on inner beauty rather than external adornment</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2699s">00:44:59</a> Find admirable qualities in your husband and focus on them</li>
<li><a href="https://www.youtube.com/watch?v=zMJ73hBGnIA&amp;t=2729s">00:45:29</a> Let the Holy Spirit convict your husband; don’t try to be his personal Holy Spirit</li>
</ol>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>John Street’s marriage seminar focuses on the biblical roles of husbands and wives, emphasizing the concept of submission within marriage. The central message revolves around the idea that following God’s design for marriage leads to harmony and happiness, while deviating from it results in conflict and misery.</p>
<p>Street uses various Bible verses to support his arguments, primarily drawing from Ephesians, 1 Peter, and 1 Timothy. He presents a complementarian view of marriage, where husbands and wives have distinct roles that work together for the good of the relationship. The seminar addresses common misconceptions about submission and argues that it is not demeaning or oppressive when properly understood and applied.</p>
<p>Throughout the seminar, Street emphasizes the importance of wives respecting and honoring their husbands, while also encouraging wives to use their intellect and abilities to complement their husbands. He presents a view of marriage where the husband is the leader, but the wife plays a crucial role as a “suitable helper” and influential partner.</p>
</section>
<section id="recurring-themes" class="level2">
<h2 class="anchored" data-anchor-id="recurring-themes">Recurring Themes</h2>
<ol type="1">
<li>The importance of following God’s design for marriage</li>
<li>Misconceptions about biblical submission</li>
<li>The influence of cultural feminism on modern marriages</li>
<li>The role of wives in supporting and respecting their husbands</li>
<li>The transformative power of living according to biblical principles in marriage</li>
</ol>


</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <category>Wives</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-3-wives/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Communication</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-4-communication/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3.5 Sonnet.</p>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main Points</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=39s">00:00:39</a> Good communication in Christian marriage does not happen automatically.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=77s">00:01:17</a> Christian marriages are not immune from problems.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=105s">00:01:45</a> The myth of compatibility in dating and marriage</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=153s">00:02:33</a> Every marriage is dysfunctional due to sin</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=201s">00:03:21</a> Sinful nature complicates communication in marriage</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=231s">00:03:51</a> Biblical reconciliation goes beyond conflict resolution</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=277s">00:04:37</a> The root cause of conflicts in relationships</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=949s">00:15:49</a> Four rules of communication for a godly marriage</li>
</ol>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=111s">00:01:51</a> Dating websites promote a myth of compatibility that doesn’t account for the reality of differences and sin in marriage.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=160s">00:02:40</a> Every marriage is dysfunctional because it involves two sinners making vows to each other.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=294s">00:04:54</a> Personality differences are not the root cause of conflicts; rather, it’s the passions and desires within each person that lead to conflicts.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=541s">00:09:01</a> Legitimate desires can become idolatrous and lead to sinful responses in marriage.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=956s">00:15:56</a> Permanent change in Christian life requires both putting off sinful practices and putting on godly practices.</li>
</ol>
</section>
<section id="bible-verses" class="level2">
<h2 class="anchored" data-anchor-id="bible-verses">Bible Verses</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=265s">00:04:25</a> James 4:1 - Used to explain the source of conflicts in relationships</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=423s">00:07:03</a> Matthew 5 - Referenced to explain Jesus’ teaching on hatred and murder</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=922s">00:15:22</a> Ephesians 4:22-24 - Explains the process of putting off the old self and putting on the new self</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1199s">00:19:59</a> Ephesians 4:25 - First rule of communication: Be honest</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1695s">00:28:15</a> Colossians 3:9 - Instruction not to lie to one another</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1732s">00:28:52</a> Ephesians 4:15 - Speaking the truth in love</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1852s">00:30:52</a> Ephesians 4:26-27 - Second rule of communication: Keep current</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=2211s">00:36:51</a> Ephesians 4:29 - Third rule of communication: Attack the problem, not the person</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=2592s">00:43:12</a> Ephesians 4:31-32 - Fourth rule of communication: Act, don’t react</li>
</ol>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1075s">00:17:55</a> Practice putting off sinful communication habits and putting on godly ones.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1236s">00:20:36</a> Speak up and be truthful in communication; avoid clamming up or giving the silent treatment.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1371s">00:22:51</a> Be aware of subtle forms of dishonesty in communication, such as incongruities and disguised communication.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1739s">00:28:59</a> Speak the truth with the other person’s best interest in mind.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=1919s">00:31:59</a> Deal with anger as soon as possible; don’t let it linger.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=2248s">00:37:28</a> Use edifying words that focus on the problem, not attacking the person’s character.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=2489s">00:41:29</a> Use phrases that express a desire to understand and work through problems together.</li>
<li><a href="https://www.youtube.com/watch?v=rFzx6ecKkaE&amp;t=2777s">00:46:17</a> Practice being kind, tenderhearted, and forgiving in conflicts.</li>
</ol>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>John Street’s marriage seminar focuses on the importance of godly communication in Christian marriages. The central message emphasizes that good communication doesn’t happen automatically, even in Christian relationships, and that every marriage faces challenges due to the sinful nature of humans. Street argues against the popular notion of compatibility, asserting that conflicts arise not from personality differences but from internal desires and passions.</p>
<p>The seminar is structured around four main rules of communication derived from Ephesians 4: be honest, keep current, attack the problem (not the person), and act (don’t react). Street uses various Bible verses to support these points, particularly drawing from Ephesians and James. He emphasizes the need for Christians to not only stop negative communication patterns but also actively practice positive ones.</p>
<p>Street’s approach to marriage is deeply rooted in biblical principles, focusing on personal responsibility, forgiveness, and the pursuit of godliness in marital relationships. He stresses the importance of understanding the root causes of conflicts and addressing them promptly and lovingly. The seminar provides practical applications for implementing these communication rules in daily life, encouraging couples to be intentional about changing their habits to align with biblical teachings.</p>
<p>Throughout the seminar, there is a recurring theme of the transformative power of applying biblical principles to marriage. Street consistently emphasizes the need for deliberate effort in changing communication patterns and the importance of viewing one’s spouse through the lens of grace and forgiveness. His teaching style combines theological explanation with practical examples, making the content accessible and applicable to his audience.</p>


</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <category>Communication</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-4-communication/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Marital Union</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-5-marital-union/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3.5 Sonnet.</p>
<section id="main-points" class="level2">
<h2 class="anchored" data-anchor-id="main-points">Main Points</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=52s">00:00:52</a> Sex and marriage is a pure and very holy thing</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=948s">00:15:48</a> Sex is not the basis of marriage, and marriage is not just a sexual relationship</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=1435s">00:23:55</a> Sex has as its primary goal the satisfaction of one’s spouse</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2166s">00:36:06</a> God created both husband and wife with an equal ability to satisfy one another</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2649s">00:44:09</a> Pleasure in sex is not sinful and forbidden, but assured and even encouraged within marriage</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=3014s">00:50:14</a> Sexual relationships should be regular and continuous in marriage</li>
</ol>
</section>
<section id="arguments" class="level2">
<h2 class="anchored" data-anchor-id="arguments">Arguments</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=472s">00:07:52</a> God created males and females fully and completely, and called this creation “very good”</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=994s">00:16:34</a> Unity in marriage goes beyond just the sexual relationship</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=1473s">00:24:33</a> When you said “I do,” you gave yourself to your spouse for their fulfillment</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2178s">00:36:18</a> No one has sole power or authority in the sexual relationship; it should be equal and reciprocal</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2749s">00:45:49</a> Greed-oriented sex has no place in the Christian life</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=3056s">00:50:56</a> Paul outlines four guidelines for when not to have sex in marriage</li>
</ol>
</section>
<section id="bible-verses" class="level2">
<h2 class="anchored" data-anchor-id="bible-verses">Bible Verses</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=798s">00:13:18</a> Hebrews 13:4 - Marriage bed should be held in honor and kept undefiled</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=1318s">00:21:58</a> 1 Corinthians 7:3-4 - Spouses should fulfill marital duty to each other</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2461s">00:41:01</a> Proverbs 5:18-19 - Be intoxicated with your spouse’s love</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2738s">00:45:38</a> Ephesians 5:3 - Sexual immorality must not be named among believers</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=3022s">00:50:22</a> 1 Corinthians 7:5 - Do not deprive one another except by agreement for a limited time</li>
</ol>
</section>
<section id="practical-applications" class="level2">
<h2 class="anchored" data-anchor-id="practical-applications">Practical Applications</h2>
<ol type="1">
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=1675s">00:27:55</a> Focus on giving pleasure to your spouse rather than getting pleasure for yourself</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2015s">00:33:35</a> Take initiative to make sure your spouse is fulfilled sexually</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2256s">00:37:36</a> Leave energy for your spouse at the end of the day</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=2816s">00:46:56</a> Avoid pornography and other forms of sexual gratification outside of marriage</li>
<li><a href="https://www.youtube.com/watch?v=vxXotY2lSfQ&amp;t=3179s">00:52:59</a> Do not expect your spouse to do things they find repugnant in the sexual relationship</li>
</ol>
</section>
<section id="overview" class="level2">
<h2 class="anchored" data-anchor-id="overview">Overview</h2>
<p>John Street’s marriage seminar focuses on presenting a biblical view of sexuality within marriage. The central message emphasizes that sex is a pure, holy, and God-designed aspect of marriage, intended for mutual satisfaction and enjoyment between spouses. Street argues against both extremes of viewing sex as dirty or taboo and seeing it as the highest form of human relationship.</p>
<p>Throughout the seminar, Street uses biblical passages to support his main points, drawing primarily from 1 Corinthians 7, Proverbs 5, and other relevant verses. He emphasizes that the Bible presents sex as a good gift from God, but one that should be expressed exclusively within the confines of a heterosexual, monogamous marriage. The arguments and verses are used to reinforce the idea that sexual intimacy in marriage should be characterized by mutual giving, equal rights and responsibilities, and regular engagement.</p>
<p>Street’s approach to marriage and sexuality is deeply rooted in biblical principles, challenging cultural norms and encouraging couples to view their sexual relationship as a ministry to each other. He stresses the importance of putting one’s spouse’s needs and satisfaction above personal gratification, presenting this as a reflection of Christ-like love and service within marriage.</p>
</section>
<section id="recurring-themes-and-unique-perspectives" class="level2">
<h2 class="anchored" data-anchor-id="recurring-themes-and-unique-perspectives">Recurring Themes and Unique Perspectives</h2>
<ol type="1">
<li>Emphasis on the purity and holiness of marital sexuality</li>
<li>Rejection of both Victorian prudishness and modern sexual liberation</li>
<li>Focus on mutual satisfaction and giving rather than self-gratification</li>
<li>Equal rights and responsibilities for both husband and wife in the sexual relationship</li>
<li>Warning against pornography and other forms of sexual immorality</li>
<li>Presentation of sexual intimacy as a form of ministry to one’s spouse</li>
</ol>
<p>The seminar presents a comprehensive and nuanced view of Christian sexuality, addressing common misconceptions and providing practical advice for married couples. Street’s teaching style is direct and sometimes humorous, using personal anecdotes and hypothetical scenarios to illustrate his points.</p>


</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-5-marital-union/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>John Street - God’s Design for Marriage Q&amp;A</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-6-qa/</link>
  <description><![CDATA[ 




<p>Note: This summary is AI generated by Claude 3.5 Sonnet.</p>
<section id="biblical-counseling-qa-session-summary" class="level1">
<h1>Biblical Counseling Q&amp;A Session Summary</h1>
<section id="q1-how-can-i-get-training-in-true-biblical-counseling" class="level2">
<h2 class="anchored" data-anchor-id="q1-how-can-i-get-training-in-true-biblical-counseling"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=101s">Q1: How can I get training in true biblical counseling?</a></h2>
<p>Dr.&nbsp;Street recommends several options:</p>
<ol type="1">
<li>Get an accredited graduate degree in biblical counseling for in-depth study.</li>
<li>Attend training sessions offered by the Association of Certified Biblical Counselors (ACBC).</li>
<li>Look for undergraduate programs in biblical counseling at schools like Boyce College or The Master’s University.</li>
<li>Attend seminars and workshops on biblical counseling.</li>
</ol>
<p>He emphasizes the importance of ensuring the training adheres to true biblical counseling standards, which can be verified by checking the ACBC website (biblicalcounseling.com) for their statement of faith and practice.</p>
</section>
<section id="q2-how-do-we-deal-with-past-hurts-pains-difficulties-and-abuse" class="level2">
<h2 class="anchored" data-anchor-id="q2-how-do-we-deal-with-past-hurts-pains-difficulties-and-abuse"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=371s">Q2: How do we deal with past hurts, pains, difficulties and abuse?</a></h2>
<p>Dr.&nbsp;Street provides the following guidance:</p>
<ol type="1">
<li>Understand that we live in a sinful world where bad things happen.</li>
<li>Choose whether to let past traumas define you or allow Christ to define you.</li>
<li>Focus on doing good and not repaying evil with evil.</li>
<li>Seek peace and pursue righteousness.</li>
<li>Be prepared to explain your faith and hope to others who notice your changed behavior.</li>
</ol>
<p>He emphasizes that while traumatic experiences are real, Christians should not let them control their lives, but instead find their identity in Christ.</p>
</section>
<section id="q3-at-what-age-do-you-encourage-children-to-move-out-of-the-home" class="level2">
<h2 class="anchored" data-anchor-id="q3-at-what-age-do-you-encourage-children-to-move-out-of-the-home"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=748s">Q3: At what age do you encourage children to move out of the home?</a></h2>
<p>Dr.&nbsp;Street provides the following guidelines:</p>
<ol type="1">
<li>There’s no specific age, as individual circumstances (like disabilities) may affect this decision.</li>
<li>Children should be raised with the expectation of eventually leaving home.</li>
<li>Parents should encourage independence when children are physically and mentally capable of supporting themselves.</li>
<li>For adult children living at home, parents can implement strategies like charging rent to encourage moving out.</li>
<li>Parents should act as a safety net but not enable prolonged dependence.</li>
</ol>
</section>
<section id="q4-what-do-you-say-to-couples-living-together-prior-to-marriage" class="level2">
<h2 class="anchored" data-anchor-id="q4-what-do-you-say-to-couples-living-together-prior-to-marriage"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=977s">Q4: What do you say to couples living together prior to marriage?</a></h2>
<p>Dr.&nbsp;Street strongly advises against cohabitation before marriage:</p>
<ol type="1">
<li>He states that couples living together before marriage are “living openly in sin.”</li>
<li>He emphasizes that Christians should be different from worldly practices.</li>
<li>He advises couples to stop cohabiting, repent, and ask each other for forgiveness.</li>
<li>He explains that sexual relationships should only occur within a monogamous, heterosexual marriage.</li>
<li>He warns that premarital cohabitation can undermine trust and integrity in the future marriage.</li>
</ol>
</section>
<section id="q5-what-do-christian-parents-do-when-an-unmarried-couple-want-to-spend-the-night-together-in-their-home" class="level2">
<h2 class="anchored" data-anchor-id="q5-what-do-christian-parents-do-when-an-unmarried-couple-want-to-spend-the-night-together-in-their-home"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=1166s">Q5: What do Christian parents do when an unmarried couple want to spend the night together in their home?</a></h2>
<p>Dr.&nbsp;Street advises:</p>
<ol type="1">
<li>Parents should not allow unmarried couples to share a room in their home.</li>
<li>They should make separate sleeping arrangements, even if it means parents sleeping separately to accommodate guests.</li>
<li>Parents shouldn’t compromise their principles to accommodate others’ ungodliness.</li>
<li>While parents can express love in other ways, they shouldn’t enable or approve of sinful behavior.</li>
<li>This applies to all unmarried couples, regardless of sexual orientation.</li>
</ol>
</section>
<section id="q6-how-do-we-help-young-men-and-women-who-are-not-married-but-want-to-become-married" class="level2">
<h2 class="anchored" data-anchor-id="q6-how-do-we-help-young-men-and-women-who-are-not-married-but-want-to-become-married"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=1353s">Q6: How do we help young men and women who are not married but want to become married?</a></h2>
<p>Dr.&nbsp;Street references 1 Thessalonians 4:3-7 and advises:</p>
<ol type="1">
<li>Teach them to choose a spouse based on holiness and honor, not primarily on physical attraction.</li>
<li>Encourage them to consider whether their relationship leads to greater holiness for both partners.</li>
<li>Help them understand the importance of honoring parents’ wisdom in choosing a spouse.</li>
<li>Prepare them for the reality that they’re marrying someone with flaws, not the idealized version they see while dating.</li>
</ol>
</section>
<section id="q7-what-role-do-godly-parents-play-in-encouraging-their-children-into-a-godly-marriage" class="level2">
<h2 class="anchored" data-anchor-id="q7-what-role-do-godly-parents-play-in-encouraging-their-children-into-a-godly-marriage"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=1670s">Q7: What role do godly parents play in encouraging their children into a godly marriage?</a></h2>
<p>Dr.&nbsp;Street suggests:</p>
<ol type="1">
<li>Parents should teach their children what Scripture says about marriage.</li>
<li>They should guide their children in making decisions about marriage in an honorable and godly way.</li>
<li>Parents often have wisdom that younger people lack, even if the parents aren’t believers.</li>
<li>Children should pay close attention to their parents’ input about potential spouses.</li>
<li>Parents should help their children realize they’re marrying someone with flaws, not a perfect person.</li>
</ol>
</section>
<section id="q8-should-married-couples-live-with-their-in-laws" class="level2">
<h2 class="anchored" data-anchor-id="q8-should-married-couples-live-with-their-in-laws"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=1917s">Q8: Should married couples live with their in-laws?</a></h2>
<p>Dr.&nbsp;Street provides the following guidance:</p>
<ol type="1">
<li>There’s no simple yes or no answer, as circumstances vary.</li>
<li>Living with in-laws can be necessary for caregiving or financial reasons.</li>
<li>Generally, it’s not the best arrangement for newly married couples.</li>
<li>If couples do live with in-laws, it’s crucial to maintain proper boundaries and priorities.</li>
<li>The married couple must present a unified front and prioritize their relationship over parental relationships.</li>
<li>The husband and wife should always side with each other, not their respective parents.</li>
</ol>
</section>
<section id="q9-how-do-i-make-my-husband-a-priority-when-i-have-a-career" class="level2">
<h2 class="anchored" data-anchor-id="q9-how-do-i-make-my-husband-a-priority-when-i-have-a-career"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=2164s">Q9: How do I make my husband a priority when I have a career?</a></h2>
<p>Dr.&nbsp;Street advises:</p>
<ol type="1">
<li>It’s not wrong for a woman to have a career, but it shouldn’t dictate family priorities.</li>
<li>A woman’s primary responsibility should be to her husband, children, and home, not her career.</li>
<li>Husbands should take leadership in providing for the family financially.</li>
<li>Both spouses should work together to balance career and home responsibilities.</li>
<li>Husbands should actively help with household tasks, especially if both spouses work outside the home.</li>
</ol>
</section>
<section id="q10-can-i-have-a-calling-at-work-as-a-woman" class="level2">
<h2 class="anchored" data-anchor-id="q10-can-i-have-a-calling-at-work-as-a-woman"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=2470s">Q10: Can I have a calling at work as a woman?</a></h2>
<p>Dr.&nbsp;Street states:</p>
<ol type="1">
<li>There is no special “calling” for women in careers in the same way as pastoral ministry.</li>
<li>Women can have successful careers and be well-accomplished professionally.</li>
<li>Careers can be used in good and godly ways, including in Christian service.</li>
<li>However, a woman’s home and husband should always be her top priority.</li>
<li>Women should ensure their career doesn’t overshadow their primary responsibilities to family and home.</li>
</ol>
</section>
<section id="q11-what-are-some-basic-principles-to-apply-if-a-christian-is-married-to-a-non-christian" class="level2">
<h2 class="anchored" data-anchor-id="q11-what-are-some-basic-principles-to-apply-if-a-christian-is-married-to-a-non-christian"><a href="https://www.youtube.com/watch?v=CVyerCbKlvY&amp;t=2674s">Q11: What are some basic principles to apply if a Christian is married to a non-Christian?</a></h2>
<p>Dr.&nbsp;Street provides the following guidance based on 1 Peter 3:</p>
<ol type="1">
<li>For wives with unbelieving husbands, follow 1 Peter 3:1-6 as your guide.</li>
<li>For husbands with unbelieving wives, follow 1 Peter 3:7.</li>
<li>Focus on unity with other Christians, sympathy, love, and humility.</li>
<li>Don’t repay evil with evil, but bless others instead.</li>
<li>Seek peace and pursue righteousness.</li>
<li>Be prepared to explain your faith when your spouse asks about your changed behavior.</li>
<li>View yourself as God’s missionary to your unbelieving spouse.</li>
<li>Live out your faith consistently, even in the face of difficulties.</li>
</ol>
</section>
<section id="main-themes-of-the-qa-session" class="level2">
<h2 class="anchored" data-anchor-id="main-themes-of-the-qa-session">Main Themes of the Q&amp;A Session:</h2>
<ol type="1">
<li>Biblical approach to counseling and dealing with past traumas</li>
<li>Christian perspectives on marriage, cohabitation, and family life</li>
<li>Balancing career and family responsibilities, especially for women</li>
<li>Parenting adult children and encouraging independence</li>
<li>Navigating relationships with in-laws</li>
<li>Guidance for Christians married to non-believers</li>
<li>The importance of maintaining biblical standards in a secular culture</li>
</ol>
<p>The session emphasizes a strong commitment to biblical principles in all aspects of life, particularly in marriage and family relationships. It also stresses the importance of distinctively Christian behavior in contrast to worldly practices.</p>


</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>Marriage</category>
  <category>God</category>
  <category>John Street</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-08-14-john-street-6-qa/</guid>
  <pubDate>Wed, 14 Aug 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>Mastering LLMs - Fine-Tuning Workshop 3 - Instrumenting &amp; Evaluating LLMs (guest speakers Harrison Chase, Bryan Bischof, Shreya Shankar, Eugene Yan)</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2024-05-28-mllms-workshop3/</link>
  <description><![CDATA[ 




<section id="key-takeaways" class="level1">

<ul>
<li>Evaluation is critical: It drives the iterative process of improving your LLM application, enabling you to make informed decisions about prompt engineering, fine-tuning, and model selection.</li>
<li>Don’t overcomplicate things: Start simple with unit tests and focus on practical metrics that align with your specific use case. Avoid building overly complex evaluation frameworks prematurely.</li>
<li>Human judgment is still essential: While LMs can assist with evaluation, human experts are ultimately responsible for defining what constitutes good performance and aligning the LLM to those preferences.</li>
<li>Look at your data: Regularly examine the inputs and outputs of your LLM system, as well as production data, to identify failure modes, refine evaluation criteria, and ensure the system is behaving as intended.</li>
<li>Evaluation is iterative: Both evaluation criteria and the methods for evaluating those criteria will evolve as you learn more about the task and gather more data. Be prepared to adapt and refine your evaluation process over time.</li>
</ul>
</section>
<section id="insights" class="level1">
<h1>Insights:</h1>
<ul>
<li>Traditional ML evaluation principles still apply: Leverage existing evaluation techniques and adapt them to the nuances of LLMs. Don’t treat LLM evaluation as an entirely new field.</li>
<li>Use case experts are invaluable: Involve them in the evaluation process from the beginning to ensure alignment between evaluation metrics and user needs.</li>
<li>LM-assisted evaluation is not a silver bullet: While helpful for scaling evaluations and providing directional insights, it requires careful and methodical application. Multiple judges, models, and shots should be used, and human alignment should be checked regularly.</li>
<li>Production endpoints are key: Evaluating directly against production endpoints minimizes drift and ensures consistency between development and production environments.</li>
</ul>
</section>
<section id="action-items" class="level1">
<h1>Action Items:</h1>
<ul>
<li>Implement unit tests: Identify and codify basic sanity checks for your LLM application to catch common errors.</li>
<li>Start logging traces: Use existing tools like LangSmith, Braintrust, or Instruct to capture the inputs and outputs of your LLM pipeline for detailed analysis and debugging.</li>
<li>Develop a simple evaluation framework: Focus on key metrics relevant to your use case, and build the framework iteratively as you gain more experience and data.</li>
<li>Involve use case experts: Work with them to define evaluation criteria, review outputs, and provide feedback on the evaluation process.</li>
<li>Explore LLM-assisted evaluation: Experiment with tools and techniques that leverage LLMs to scale your evaluation efforts, but do so with a critical eye and ensure human alignment.</li>
</ul>
</section>
<section id="other-interesting-information" class="level1">
<h1>Other Interesting Information:</h1>
<ul>
<li>Several tools and resources for LLM evaluation were mentioned, including LangSmith, Braintrust, Weights &amp; Biases, Instruct, Identic.Logfire, Weave, OpenTelemetry, and a book on recommendation systems by Brian Bishop.</li>
<li>A research prototype interface called EvalGen was presented, which assists developers in creating and iterating on LLM evaluations in a more intuitive and user-friendly way.</li>
<li>The talk emphasized the importance of minimizing wait time in the evaluation process by involving humans in the loop for tasks like editing criteria, refining criteria, and interactively grading LLM outputs.</li>
</ul>


</section>

 ]]></description>
  <category>Conference</category>
  <category>AI</category>
  <category>LLMs</category>
  <category>Mastering LLMs</category>
  <category>Evaluation</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2024-05-28-mllms-workshop3/</guid>
  <pubDate>Tue, 28 May 2024 00:00:00 GMT</pubDate>
</item>
<item>
  <title>AI Engineer Summit 2023</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2023-10-10-ai-engineer-summit/</link>
  <description><![CDATA[ 




<section id="ai-engineer-summit" class="level1">
<h1>AI Engineer Summit</h1>
<p>sywx was the <a href="https://www.latent.space/p/ai-engineer">first</a> to define the job title “AI Engineer” as a role in between a Data Scientist and Full Stack Software Engineer, someone that builds on top of large foundation models and can quickly build services using these models. I agree with him that this job function will likely expand whether you hold the job title of “AI Engineer” or not.</p>
<p>I had the privilege of attending the inaugural AI Engineer Summit in San Francisco, CA held on October 9-10, 2023. It was somewhat surprising being one of the few data scientists at the conference as most people I met were software engineers trying to transition into AI Engineering.</p>
<p>The talks were livestreamed (<a href="https://www.youtube.com/watch?v=veShHxQYPzo&amp;ab_channel=AIEngineer">Day 1</a> and <a href="https://www.youtube.com/watch?v=qw4PrtyvJI0">Day 2</a>). Below are my notes from the conference.</p>
<section id="workshop-building-evaluating-and-optimizing-your-rag-app-for-production" class="level2">
<h2 class="anchored" data-anchor-id="workshop-building-evaluating-and-optimizing-your-rag-app-for-production">Workshop: Building, Evaluating, and Optimizing your RAG App for Production</h2>
<p>Simon Suo, Cofounder / CTO, LlamaIndex<br>
</p>
<ul>
<li>Very indepth workshop on how to build an end to end RAG app over Ray documentation, also using Ray to build it. Slides are in the repo below.</li>
<li><a href="https://github.com/Disiok/ai-engineer-workshop" class="uri">https://github.com/Disiok/ai-engineer-workshop</a></li>
<li>Hallucinations: Most of the time it is caused by irrelevant retrieved passages</li>
<li>Evaluation: can think of both end-to-end evaluation and component-wise evaluation of a RAG app
<ul>
<li>End-to-end: understand how well the full RAG application works</li>
<li>Component-wise: understand specific components like the retriever (are we retrieving the relevant context?) and the generation (given the context, are we generating an accurate and coherent answer?)</li>
</ul></li>
<li>Data Required
<ul>
<li>User Query: representative set of real user queries</li>
<li>User Feedback: feedback from past interaction, up/down vote</li>
<li>Golden Context: set of relevant documents from our corpus to best answer a given query</li>
<li>Golden Answer: best ansewr given golden context</li>
</ul></li>
</ul>
</section>
<section id="workshop-function-calling-and-tool-usage-with-langchain-and-openai" class="level2">
<h2 class="anchored" data-anchor-id="workshop-function-calling-and-tool-usage-with-langchain-and-openai">Workshop: Function calling and tool usage with LangChain and OpenAI</h2>
<p>Harrison Chase, CEO, LangChain<br>
</p>
<ul>
<li><a href="https://github.com/hwchase17/ai-engineer" class="uri">https://github.com/hwchase17/ai-engineer</a></li>
<li>OpenAI function calling within LangChain to do structured data extraction, build agents to do extraction and tagging and use tools. Also a quick tutorial on</li>
<li>LangChain Expression Language (LCEL) is a relatively new way (introduced in Aug 2023) to compose langchain components</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb1" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.prompts <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatPromptTemplate</span>
<span id="cb1-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.chat_models <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb1-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.schema.output_parser <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> StrOutputParser</span>
<span id="cb1-4"></span>
<span id="cb1-5">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatPromptTemplate.from_template(</span>
<span id="cb1-6">    <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Tell me a short joke about </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{topic}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span></span>
<span id="cb1-7">)</span>
<span id="cb1-8">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI()</span>
<span id="cb1-9">output_parser <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> StrOutputParser()</span>
<span id="cb1-10"></span>
<span id="cb1-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># define the chain</span></span>
<span id="cb1-12">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> output_parser</span>
<span id="cb1-13"></span>
<span id="cb1-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># don't .run() the chain but call .invoke()</span></span>
<span id="cb1-15">chain.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"topic"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"bears"</span>})</span></code></pre></div></div>
<ul>
<li>OpenAI’s Function Calling is a way to get OpenAI’s language models to return structured data (arguments to run a function or extract structured data from text). This is a powerful feature!</li>
<li>I’m surprised other LLM providers have not yet introduced this functionality.</li>
<li>langchain exposes helper function to make working with function calling easier</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.utils.openai_functions <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> convert_pydantic_to_openai_function</span>
<span id="cb2-2"></span>
<span id="cb2-3"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> WeatherSearch(BaseModel):</span>
<span id="cb2-4">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Call this with an airport code to get the weather at that airport"""</span></span>
<span id="cb2-5">    airport_code: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"airport code to get weather for"</span>)</span>
<span id="cb2-6"></span>
<span id="cb2-7">weather_function <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> convert_pydantic_to_openai_function(WeatherSearch)</span>
<span id="cb2-8">weather_function</span>
<span id="cb2-9"></span>
<span id="cb2-10"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># {'name': 'WeatherSearch',</span></span>
<span id="cb2-11"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  'description': 'Call this with an airport code to get the weather at that airport',</span></span>
<span id="cb2-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  'parameters': {'title': 'WeatherSearch',</span></span>
<span id="cb2-13"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'description': 'Call this with an airport code to get the weather at that airport',</span></span>
<span id="cb2-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'type': 'object',</span></span>
<span id="cb2-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'properties': {'airport_code': {'title': 'Airport Code',</span></span>
<span id="cb2-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'description': 'airport code to get weather for',</span></span>
<span id="cb2-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'type': 'string'}},</span></span>
<span id="cb2-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'required': ['airport_code']}}</span></span></code></pre></div></div>
<p>then you can pass the weather function to the LLM</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.chat_models <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb3-2">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI()</span>
<span id="cb3-3">model.invoke(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the weather in San Francisco right now?"</span>,</span>
<span id="cb3-4">             functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[weather_function])  </span></code></pre></div></div>
<p>You can also bind the function to the model:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1">model_with_function <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.bind(functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[weather_function])</span></code></pre></div></div>
<p>You can force OpenAI to use a function, but you can only pass one function here.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1">model_forced_function <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.bind(functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>[weather_function], function_call<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"WeatherSearch"</span>})</span></code></pre></div></div>
<p>Function calling is a great way to do structured data extraction from text for example extracting name, age tuples.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb6" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> typing <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> Optional</span>
<span id="cb6-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Person(BaseModel):</span>
<span id="cb6-3">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Information about a person."""</span></span>
<span id="cb6-4">    name: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">str</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person's name"</span>)</span>
<span id="cb6-5">    age: Optional[<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">int</span>] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"person's age"</span>)</span>
<span id="cb6-6">  </span>
<span id="cb6-7"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> Information(BaseModel):</span>
<span id="cb6-8">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Information to extract."""</span></span>
<span id="cb6-9">    people: List[Person] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"List of info about people"</span>)</span>
<span id="cb6-10"></span>
<span id="cb6-11">extraction_functions <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [convert_pydantic_to_openai_function(Information)]</span>
<span id="cb6-12">extraction_model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> model.bind(functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>extraction_functions, function_call<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>{<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"name"</span>:<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Information"</span>})</span>
<span id="cb6-13">extraction_model.invoke(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Joe is 30. Joe's mom is Martha"</span>)</span>
<span id="cb6-14"></span>
<span id="cb6-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># AIMessage(content='', additional_kwargs={'function_call': {'name': 'Information', 'arguments': '{\n  "people": [\n    {\n      "name": "Joe",\n      "age": 30\n    },\n    {\n      "name": "Martha",\n      "age": 0\n    }\n  ]\n}'}})</span></span></code></pre></div></div>
<ul>
<li>You can create your own tools using the <span class="citation" data-cites="tool">@tool</span> decorator and pass these tools to OpenAI</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb7" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.agents <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> tool</span>
<span id="cb7-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.chat_models <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ChatOpenAI</span>
<span id="cb7-3"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> pydantic <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> BaseModel, Field</span>
<span id="cb7-4"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> requests</span>
<span id="cb7-5"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> datetime</span>
<span id="cb7-6"></span>
<span id="cb7-7"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Define the input schema</span></span>
<span id="cb7-8"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">class</span> OpenMeteoInput(BaseModel):</span>
<span id="cb7-9">    latitude: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(..., description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Latitude of the location to fetch weather data for"</span>)</span>
<span id="cb7-10">    longitude: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span> <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> Field(..., description<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"Longitude of the location to fetch weather data for"</span>)</span>
<span id="cb7-11"></span>
<span id="cb7-12"><span class="at" style="color: #657422;
background-color: null;
font-style: inherit;">@tool</span>(args_schema<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>OpenMeteoInput)</span>
<span id="cb7-13"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> get_current_temperature(latitude: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>, longitude: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">float</span>) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-&gt;</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">dict</span>:</span>
<span id="cb7-14">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">"""Fetch current temperature for given coordinates."""</span></span>
<span id="cb7-15">    </span>
<span id="cb7-16">    BASE_URL <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"https://api.open-meteo.com/v1/forecast"</span></span>
<span id="cb7-17">    </span>
<span id="cb7-18">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Parameters for the request</span></span>
<span id="cb7-19">    params <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb7-20">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'latitude'</span>: latitude,</span>
<span id="cb7-21">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'longitude'</span>: longitude,</span>
<span id="cb7-22">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly'</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'temperature_2m'</span>,</span>
<span id="cb7-23">        <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'forecast_days'</span>: <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">1</span>,</span>
<span id="cb7-24">    }</span>
<span id="cb7-25"></span>
<span id="cb7-26">    <span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Make the request</span></span>
<span id="cb7-27">    response <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> requests.get(BASE_URL, params<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>params)</span>
<span id="cb7-28">    </span>
<span id="cb7-29">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> response.status_code <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">==</span> <span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">200</span>:</span>
<span id="cb7-30">        results <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> response.json()</span>
<span id="cb7-31">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb7-32">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">raise</span> <span class="pp" style="color: #AD0000;
background-color: null;
font-style: inherit;">Exception</span>(<span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f"API Request failed with status code: </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>response<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">.</span>status_code<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>)</span>
<span id="cb7-33"></span>
<span id="cb7-34">    current_utc_time <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> datetime.datetime.utcnow()</span>
<span id="cb7-35">    time_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> [datetime.datetime.fromisoformat(time_str.replace(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'Z'</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'+00:00'</span>)) <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">for</span> time_str <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">in</span> results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly'</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'time'</span>]]</span>
<span id="cb7-36">    temperature_list <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> results[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'hourly'</span>][<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'temperature_2m'</span>]</span>
<span id="cb7-37">    </span>
<span id="cb7-38">    closest_time_index <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">min</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">range</span>(<span class="bu" style="color: null;
background-color: null;
font-style: inherit;">len</span>(time_list)), key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> i: <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">abs</span>(time_list[i] <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">-</span> current_utc_time))</span>
<span id="cb7-39">    current_temperature <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> temperature_list[closest_time_index]</span>
<span id="cb7-40">    </span>
<span id="cb7-41">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> <span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">f'The current temperature is </span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{</span>current_temperature<span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}</span><span class="ss" style="color: #20794D;
background-color: null;
font-style: inherit;">°C'</span></span>
<span id="cb7-42"></span>
<span id="cb7-43">format_tool_to_openai_function(get_current_temperature)    </span>
<span id="cb7-44"></span>
<span id="cb7-45"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># {'name': 'get_current_temperature',</span></span>
<span id="cb7-46"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  'description': 'get_current_temperature(latitude: float, longitude: float) -&gt; dict - Fetch current temperature for given coordinates.',</span></span>
<span id="cb7-47"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  'parameters': {'title': 'OpenMeteoInput',</span></span>
<span id="cb7-48"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'type': 'object',</span></span>
<span id="cb7-49"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'properties': {'latitude': {'title': 'Latitude',</span></span>
<span id="cb7-50"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'description': 'Latitude of the location to fetch weather data for',</span></span>
<span id="cb7-51"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'type': 'number'},</span></span>
<span id="cb7-52"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    'longitude': {'title': 'Longitude',</span></span>
<span id="cb7-53"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'description': 'Longitude of the location to fetch weather data for',</span></span>
<span id="cb7-54"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#     'type': 'number'}},</span></span>
<span id="cb7-55"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'required': ['latitude', 'longitude']}}</span></span></code></pre></div></div>
<p>You can also convert an Open API spec into an OpenAI function</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb8" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.chains.openai_functions.openapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> openapi_spec_to_openai_fn</span>
<span id="cb8-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.utilities.openapi <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> OpenAPISpec</span>
<span id="cb8-3"></span>
<span id="cb8-4">text <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-5"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">{</span></span>
<span id="cb8-6"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  "openapi": "3.0.0",</span></span>
<span id="cb8-7"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  "info": {</span></span>
<span id="cb8-8"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "version": "1.0.0",</span></span>
<span id="cb8-9"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "title": "Swagger Petstore",</span></span>
<span id="cb8-10"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "license": {</span></span>
<span id="cb8-11"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "name": "MIT"</span></span>
<span id="cb8-12"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb8-13"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  },</span></span>
<span id="cb8-14"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  "servers": [</span></span>
<span id="cb8-15"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    {</span></span>
<span id="cb8-16"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "url": "http://petstore.swagger.io/v1"</span></span>
<span id="cb8-17"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb8-18"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  ],</span></span>
<span id="cb8-19"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  "paths": {</span></span>
<span id="cb8-20"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "/pets": {</span></span>
<span id="cb8-21"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "get": {</span></span>
<span id="cb8-22"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "summary": "List all pets",</span></span>
<span id="cb8-23"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "operationId": "listPets",</span></span>
<span id="cb8-24"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "tags": [</span></span>
<span id="cb8-25"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "pets"</span></span>
<span id="cb8-26"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-27"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "parameters": [</span></span>
<span id="cb8-28"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          {</span></span>
<span id="cb8-29"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "name": "limit",</span></span>
<span id="cb8-30"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "in": "query",</span></span>
<span id="cb8-31"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "How many items to return at one time (max 100)",</span></span>
<span id="cb8-32"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "required": false,</span></span>
<span id="cb8-33"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "schema": {</span></span>
<span id="cb8-34"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "type": "integer",</span></span>
<span id="cb8-35"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "maximum": 100,</span></span>
<span id="cb8-36"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "format": "int32"</span></span>
<span id="cb8-37"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-38"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-39"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-40"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "responses": {</span></span>
<span id="cb8-41"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "200": {</span></span>
<span id="cb8-42"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "A paged array of pets",</span></span>
<span id="cb8-43"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "headers": {</span></span>
<span id="cb8-44"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "x-next": {</span></span>
<span id="cb8-45"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "description": "A link to the next page of responses",</span></span>
<span id="cb8-46"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-47"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "type": "string"</span></span>
<span id="cb8-48"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-49"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-50"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            },</span></span>
<span id="cb8-51"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "content": {</span></span>
<span id="cb8-52"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "application/json": {</span></span>
<span id="cb8-53"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-54"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "$ref": "#/components/schemas/Pets"</span></span>
<span id="cb8-55"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-56"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-57"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-58"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-59"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "default": {</span></span>
<span id="cb8-60"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "unexpected error",</span></span>
<span id="cb8-61"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "content": {</span></span>
<span id="cb8-62"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "application/json": {</span></span>
<span id="cb8-63"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-64"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-65"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-66"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-67"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-68"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-69"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-70"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      },</span></span>
<span id="cb8-71"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "post": {</span></span>
<span id="cb8-72"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "summary": "Create a pet",</span></span>
<span id="cb8-73"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "operationId": "createPets",</span></span>
<span id="cb8-74"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "tags": [</span></span>
<span id="cb8-75"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "pets"</span></span>
<span id="cb8-76"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-77"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "responses": {</span></span>
<span id="cb8-78"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "201": {</span></span>
<span id="cb8-79"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "Null response"</span></span>
<span id="cb8-80"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-81"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "default": {</span></span>
<span id="cb8-82"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "unexpected error",</span></span>
<span id="cb8-83"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "content": {</span></span>
<span id="cb8-84"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "application/json": {</span></span>
<span id="cb8-85"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-86"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-87"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-88"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-89"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-90"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-91"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-92"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      }</span></span>
<span id="cb8-93"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    },</span></span>
<span id="cb8-94"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "/pets/</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{petId}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">": {</span></span>
<span id="cb8-95"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "get": {</span></span>
<span id="cb8-96"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "summary": "Info for a specific pet",</span></span>
<span id="cb8-97"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "operationId": "showPetById",</span></span>
<span id="cb8-98"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "tags": [</span></span>
<span id="cb8-99"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "pets"</span></span>
<span id="cb8-100"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-101"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "parameters": [</span></span>
<span id="cb8-102"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          {</span></span>
<span id="cb8-103"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "name": "petId",</span></span>
<span id="cb8-104"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "in": "path",</span></span>
<span id="cb8-105"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "required": true,</span></span>
<span id="cb8-106"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "The id of the pet to retrieve",</span></span>
<span id="cb8-107"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "schema": {</span></span>
<span id="cb8-108"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "type": "string"</span></span>
<span id="cb8-109"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-110"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-111"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-112"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "responses": {</span></span>
<span id="cb8-113"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "200": {</span></span>
<span id="cb8-114"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "Expected response to a valid request",</span></span>
<span id="cb8-115"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "content": {</span></span>
<span id="cb8-116"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "application/json": {</span></span>
<span id="cb8-117"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-118"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "$ref": "#/components/schemas/Pet"</span></span>
<span id="cb8-119"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-120"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-121"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-122"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-123"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "default": {</span></span>
<span id="cb8-124"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "description": "unexpected error",</span></span>
<span id="cb8-125"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "content": {</span></span>
<span id="cb8-126"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              "application/json": {</span></span>
<span id="cb8-127"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                "schema": {</span></span>
<span id="cb8-128"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                  "$ref": "#/components/schemas/Error"</span></span>
<span id="cb8-129"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">                }</span></span>
<span id="cb8-130"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">              }</span></span>
<span id="cb8-131"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            }</span></span>
<span id="cb8-132"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-133"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-134"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      }</span></span>
<span id="cb8-135"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb8-136"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  },</span></span>
<span id="cb8-137"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  "components": {</span></span>
<span id="cb8-138"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    "schemas": {</span></span>
<span id="cb8-139"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "Pet": {</span></span>
<span id="cb8-140"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "type": "object",</span></span>
<span id="cb8-141"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "required": [</span></span>
<span id="cb8-142"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "id",</span></span>
<span id="cb8-143"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "name"</span></span>
<span id="cb8-144"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-145"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "properties": {</span></span>
<span id="cb8-146"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "id": {</span></span>
<span id="cb8-147"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "type": "integer",</span></span>
<span id="cb8-148"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "format": "int64"</span></span>
<span id="cb8-149"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-150"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "name": {</span></span>
<span id="cb8-151"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "type": "string"</span></span>
<span id="cb8-152"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-153"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "tag": {</span></span>
<span id="cb8-154"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "type": "string"</span></span>
<span id="cb8-155"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-156"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-157"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      },</span></span>
<span id="cb8-158"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "Pets": {</span></span>
<span id="cb8-159"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "type": "array",</span></span>
<span id="cb8-160"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "maxItems": 100,</span></span>
<span id="cb8-161"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "items": {</span></span>
<span id="cb8-162"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "$ref": "#/components/schemas/Pet"</span></span>
<span id="cb8-163"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-164"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      },</span></span>
<span id="cb8-165"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      "Error": {</span></span>
<span id="cb8-166"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "type": "object",</span></span>
<span id="cb8-167"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "required": [</span></span>
<span id="cb8-168"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "code",</span></span>
<span id="cb8-169"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "message"</span></span>
<span id="cb8-170"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        ],</span></span>
<span id="cb8-171"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        "properties": {</span></span>
<span id="cb8-172"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "code": {</span></span>
<span id="cb8-173"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "type": "integer",</span></span>
<span id="cb8-174"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "format": "int32"</span></span>
<span id="cb8-175"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          },</span></span>
<span id="cb8-176"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          "message": {</span></span>
<span id="cb8-177"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">            "type": "string"</span></span>
<span id="cb8-178"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">          }</span></span>
<span id="cb8-179"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">        }</span></span>
<span id="cb8-180"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">      }</span></span>
<span id="cb8-181"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">    }</span></span>
<span id="cb8-182"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">  }</span></span>
<span id="cb8-183"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">}</span></span>
<span id="cb8-184"><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"""</span></span>
<span id="cb8-185"></span>
<span id="cb8-186">spec <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> OpenAPISpec.from_text(text)</span>
<span id="cb8-187">pet_openai_functions, pet_callables <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> openapi_spec_to_openai_fn(spec)</span>
<span id="cb8-188">pet_openai_functions</span>
<span id="cb8-189"></span>
<span id="cb8-190"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># [{'name': 'listPets',</span></span>
<span id="cb8-191"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'description': 'List all pets',</span></span>
<span id="cb8-192"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'parameters': {'type': 'object',</span></span>
<span id="cb8-193"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    'properties': {'params': {'type': 'object',</span></span>
<span id="cb8-194"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#      'properties': {'limit': {'type': 'integer',</span></span>
<span id="cb8-195"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#        'maximum': 100.0,</span></span>
<span id="cb8-196"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#        'schema_format': 'int32',</span></span>
<span id="cb8-197"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#        'description': 'How many items to return at one time (max 100)'}},</span></span>
<span id="cb8-198"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#      'required': []</span><span class="re">}}}</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">},</span></span>
<span id="cb8-199"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  {'name': 'createPets',</span></span>
<span id="cb8-200"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'description': 'Create a pet',</span></span>
<span id="cb8-201"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'parameters': {'type': 'object', 'properties': {</span><span class="re">}}}</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">,</span></span>
<span id="cb8-202"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#  {'name': 'showPetById',</span></span>
<span id="cb8-203"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'description': 'Info for a specific pet',</span></span>
<span id="cb8-204"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#   'parameters': {'type': 'object',</span></span>
<span id="cb8-205"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#    'properties': {'path_params': {'type': 'object',</span></span>
<span id="cb8-206"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#      'properties': {'petId': {'type': 'string',</span></span>
<span id="cb8-207"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#        'description': 'The id of the pet to retrieve'}},</span></span>
<span id="cb8-208"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">#      'required': ['petId']</span><span class="re">}}}</span><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">}]</span></span>
<span id="cb8-209"></span>
<span id="cb8-210">model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatOpenAI(temperature<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="dv" style="color: #AD0000;
background-color: null;
font-style: inherit;">0</span>).bind(functions<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>pet_openai_functions)</span>
<span id="cb8-211"></span>
<span id="cb8-212">model.invoke(<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"what are three pet names"</span>)</span>
<span id="cb8-213"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># AIMessage(content='', additional_kwargs={'function_call': {'name': 'listPets', 'arguments': '{\n  "params": {\n    "limit": 3\n  }\n}'}})</span></span></code></pre></div></div>
<p>You can also define routers to create rules for when an agent should use a tool.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb9" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.schema.agent <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AgentFinish</span>
<span id="cb9-2"><span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">def</span> route(result):</span>
<span id="cb9-3">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">if</span> <span class="bu" style="color: null;
background-color: null;
font-style: inherit;">isinstance</span>(result, AgentFinish):</span>
<span id="cb9-4">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> result.return_values[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">'output'</span>]</span>
<span id="cb9-5">    <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">else</span>:</span>
<span id="cb9-6">        tools <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> {</span>
<span id="cb9-7">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"search_wikipedia"</span>: search_wikipedia, </span>
<span id="cb9-8">            <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"get_current_temperature"</span>: get_current_temperature,</span>
<span id="cb9-9">        }</span>
<span id="cb9-10">        <span class="cf" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">return</span> tools[result.tool].run(result.tool_input)</span>
<span id="cb9-11"></span>
<span id="cb9-12">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> OpenAIFunctionsAgentOutputParser() <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> route</span>
<span id="cb9-13"></span>
<span id="cb9-14">chain.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the weather in san francisco right now?"</span>})</span>
<span id="cb9-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># uses the weather tool</span></span>
<span id="cb9-16"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'The current temperature is 18.5°C'</span></span>
<span id="cb9-17"></span>
<span id="cb9-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># uses the wikipedia tool</span></span>
<span id="cb9-19">chain.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is langchain?"</span>})</span>
<span id="cb9-20"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># 'Page: LangChain\nSummary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\n\nPage: Prompt engineering\nSummary: Prompt engineering is the process of structuring text that can be interpreted and understood by a generative AI model. A prompt is natural language text describing the task that an AI should perform.A prompt for a text-to-text model can be a query such as "what is Fermat\'s little theorem?", a command such as "write a poem about leaves falling", a short statement of feedback (for example, "too verbose", "too formal", "rephrase again", "omit this word") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as "Act as a native French speaker". A prompt may include a few examples for a model to learn from, such as "maison -&gt; house, chat -&gt; cat, chien -&gt;", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as "a high-quality photo of an astronaut riding a horse" or "Lo-fi slow BPM electro chill with organic samples". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.\n\nPage: Sentence embedding\nSummary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT\'s sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT\'s [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. \nOther approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. \nAn alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.'</span></span></code></pre></div></div>
<p>You can also create a conversational agent that can use tools using the <code>AgentExecutor</code> class. I believe the <code>AgentExecutor</code> handles the message types and routing for you.</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb10" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.schema.runnable <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> RunnablePassthrough</span>
<span id="cb10-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.agents <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AgentExecutor</span>
<span id="cb10-3"></span>
<span id="cb10-4">agent_chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RunnablePassthrough.assign(</span>
<span id="cb10-5">    agent_scratchpad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: format_to_openai_functions(x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intermediate_steps"</span>])</span>
<span id="cb10-6">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> chain</span>
<span id="cb10-7"></span>
<span id="cb10-8">agent_executor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentExecutor(agent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>agent_chain, tools<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tools, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>)</span>
<span id="cb10-9"></span>
<span id="cb10-10">agent_executor.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>: <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"what is langchain?"</span>})</span>
<span id="cb10-11"></span>
<span id="cb10-12"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># &gt; Entering new AgentExecutor chain...</span></span>
<span id="cb10-13"></span>
<span id="cb10-14"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Invoking: `search_wikipedia` with `{'query': 'langchain'}`</span></span>
<span id="cb10-15"></span>
<span id="cb10-16"></span>
<span id="cb10-17"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Page: LangChain</span></span>
<span id="cb10-18"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Summary: LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). As a language model integration framework, LangChain's use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.</span></span>
<span id="cb10-19"></span>
<span id="cb10-20"></span>
<span id="cb10-21"></span>
<span id="cb10-22"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Page: Sentence embedding</span></span>
<span id="cb10-23"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Summary: In natural language processing, a sentence embedding refers to a numeric representation of a sentence in the form of a vector of real numbers which encodes meaningful semantic information.State of the art embeddings are based on the learned hidden layer representation of dedicated sentence transformer models. BERT pioneered an approach involving the use of a dedicated [CLS] token preprended to the beginning of each sentence inputted into the model; the final hidden state vector of this token encodes information about the sentence and can be fine-tuned for use in sentence classification tasks. In practice however, BERT's sentence embedding with the [CLS] token achieves poor performance, often worse than simply averaging non-contextual word embeddings. SBERT later achieved superior sentence embedding performance by fine tuning BERT's [CLS] token embeddings through the usage of a siamese neural network architecture on the SNLI dataset. </span></span>
<span id="cb10-24"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Other approaches are loosely based on the idea of distributional semantics applied to sentences. Skip-Thought trains an encoder-decoder structure for the task of neighboring sentences predictions. Though this has been shown to achieve worse performance than approaches such as InferSent or SBERT. </span></span>
<span id="cb10-25"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># An alternative direction is to aggregate word embeddings, such as those returned by Word2vec, into sentence embeddings. The most straightforward approach is to simply compute the average of word vectors, known as continuous bag-of-words (CBOW). However, more elaborate solutions based on word vector quantization have also been proposed. One such approach is the vector of locally aggregated word embeddings (VLAWE), which demonstrated performance improvements in downstream text classification tasks.</span></span>
<span id="cb10-26"></span>
<span id="cb10-27"></span>
<span id="cb10-28"></span>
<span id="cb10-29"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Page: Prompt engineering</span></span>
<span id="cb10-30"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># Summary: Prompt engineering, primarily used in communication with a text-to-text model and text-to-image model, is the process of structuring text that can be interpreted and understood by a generative AI model. Prompt engineering is enabled by in-context learning, defined as a model's ability to temporarily learn from prompts. The ability for in-context learning is an emergent ability of large language models.</span></span>
<span id="cb10-31"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># A prompt is natural language text describing the task that an AI should perform. A prompt for a text-to-text model can be a query such as "what is Fermat's little theorem?", a command such as "write a poem about leaves falling", a short statement of feedback (for example, "too verbose", "too formal", "rephrase again", "omit this word") or a longer statement including context, instructions, and input data. Prompt engineering may involve phrasing a query, specifying a style, providing relevant context or assigning a role to the AI such as "Act as a native French speaker". Prompt engineering may consist of a single prompt that includes a few examples for a model to learn from, such as "maison -&gt; house, chat -&gt; cat, chien -&gt;", an approach called few-shot learning.When communicating with a text-to-image or a text-to-audio model, a typical prompt is a description of a desired output such as "a high-quality photo of an astronaut riding a horse" or "Lo-fi slow BPM electro chill with organic samples". Prompting a text-to-image model may involve adding, removing, emphasizing and re-ordering words to achieve a desired subject, style, layout, lighting, and aesthetic.</span></span>
<span id="cb10-32"></span>
<span id="cb10-33"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># LangChain is a framework designed to simplify the creation of applications using large language models (LLMs). It is a language model integration framework that can be used for various purposes such as document analysis and summarization, chatbots, and code analysis. LangChain allows developers to leverage the power of language models in their applications.</span></span>
<span id="cb10-34"></span>
<span id="cb10-35"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># &gt; Finished chain.</span></span></code></pre></div></div>
<p>You can also add memory to the Agent:</p>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb11" style="background: #f1f3f5;"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb11-1"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.memory <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> ConversationBufferMemory</span>
<span id="cb11-2"><span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">from</span> langchain.agents <span class="im" style="color: #00769E;
background-color: null;
font-style: inherit;">import</span> AgentExecutor</span>
<span id="cb11-3"></span>
<span id="cb11-4">prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ChatPromptTemplate.from_messages([</span>
<span id="cb11-5">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"system"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"You are helpful but sassy assistant"</span>),</span>
<span id="cb11-6">    MessagesPlaceholder(variable_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat_history"</span>),</span>
<span id="cb11-7">    (<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"user"</span>, <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span><span class="sc" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">{input}</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"</span>),</span>
<span id="cb11-8">    MessagesPlaceholder(variable_name<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"agent_scratchpad"</span>)</span>
<span id="cb11-9">])</span>
<span id="cb11-10"></span>
<span id="cb11-11">chain <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> RunnablePassthrough.assign(</span>
<span id="cb11-12">    agent_scratchpad<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="kw" style="color: #003B4F;
background-color: null;
font-weight: bold;
font-style: inherit;">lambda</span> x: format_to_openai_functions(x[<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"intermediate_steps"</span>])</span>
<span id="cb11-13">) <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> prompt <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> model <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">|</span> OpenAIFunctionsAgentOutputParser()</span>
<span id="cb11-14"></span>
<span id="cb11-15"><span class="co" style="color: #5E5E5E;
background-color: null;
font-style: inherit;"># what happens when conversation buffer memory gets too long?</span></span>
<span id="cb11-16">memory <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> ConversationBufferMemory(return_messages<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>,memory_key<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"chat_history"</span>)</span>
<span id="cb11-17"></span>
<span id="cb11-18">agent_executor <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> AgentExecutor(agent<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>chain, tools<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>tools, verbose<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span><span class="va" style="color: #111111;
background-color: null;
font-style: inherit;">True</span>, memory<span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span>memory)</span>
<span id="cb11-19"></span>
<span id="cb11-20">query <span class="op" style="color: #5E5E5E;
background-color: null;
font-style: inherit;">=</span> <span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"What is the weather in san francisco right now?"</span></span>
<span id="cb11-21">agent_executor.invoke({<span class="st" style="color: #20794D;
background-color: null;
font-style: inherit;">"input"</span>:query})</span></code></pre></div></div>
</section>
<section id="the-1000x-ai-engineer" class="level2">
<h2 class="anchored" data-anchor-id="the-1000x-ai-engineer">The 1000x AI Engineer</h2>
<p>swyx, Latent.Space &amp; Smol.ai Born too late to explore the earth. Born too early to explore the stars. Just in time to bring AI to everyone.</p>
<ul>
<li>Each technological wave lasts around 50-70 years. We’re in the beginning of a new wave (deep learning, generative AI) that was kicked off by AlexNet in around 2012. Since we’re only 10 years in, it’s still early.</li>
<li>Breaking down the definitions of an AI Engineer
<ul>
<li>Software engineer enhanced BY AI tools - AI Enhanced Engineer</li>
<li>Software engineer building AI products - AI Product Engineer</li>
<li>AI product that replaces human - AI Engineer Agent</li>
</ul></li>
</ul>
</section>
<section id="keynote-what-powers-replit-ai" class="level2">
<h2 class="anchored" data-anchor-id="keynote-what-powers-replit-ai">Keynote: What powers Replit AI?</h2>
<p>Amjad Masad, CEO, Replit Michele Catasta, VP of AI, Replit The building blocks of the future of software development.</p>
<ul>
<li>Announced two models <code>replit-code-v1.5-3b</code> and <code>replit-repltuned-v1.5-3b</code> that are state of the art code completion models. Replit trained them from scratch.</li>
</ul>
</section>
<section id="see-hear-speak-draw" class="level2">
<h2 class="anchored" data-anchor-id="see-hear-speak-draw">See, Hear, Speak, Draw</h2>
<p>Simón Fishman, Applied AI Engineer, OpenAI Logan Kilpatrick, Developer Relations, OpenAI We’re heading towards a multimodal world.</p>
<ul>
<li>2023 is the year of chatbots</li>
<li>2024 is the year of multi-modal</li>
<li>Each multi-modal model is a island and text is the connective tissue between models. The future is where there is unity between all modalities</li>
<li>Demos
<ul>
<li>GPT4-V and DALLE3: Upload a picture, use GPT4-V to describe the image, use DALLE3 to generate an image based that description, use GPT4-V to describe differences and use DALLE3 to generate a new image based on the differences. Was impressed by how much detail GPT4-V could capture in an image. DALLE3 struggled a bit to generate a similar image.</li>
<li>Video to blog post: Logan demonstrated taking the GPT-4 intro video into a <a href="https://logankilpatrick.medium.com/dont-forget-about-gpt-4-d5ab8c9493fc">blog post</a>. Capture frames from a video, use GPT4-V to describe the image and stitch the images and descriptions together as a post.</li>
</ul></li>
</ul>
</section>
<section id="the-age-of-the-agent" class="level2">
<h2 class="anchored" data-anchor-id="the-age-of-the-agent">The Age of the Agent</h2>
<p>Flo Crivello, CEO, Lindy How will ubiquitous AI agents impact our daily lives, and what do they mean for the future of computing?</p>
<ul>
<li>The Age of Agents</li>
<li>A world where a 25-year old can have more business impact than the Coca Cola Company</li>
<li>It’s happened beforew ith media
<ul>
<li>Oprah - 10M viewers</li>
<li>Mr.&nbsp;Beast - 189M subscribers</li>
<li>Ryan’s World -</li>
</ul></li>
<li>Nature of the content changes when you take out the gatekeepers
<ul>
<li>Much weirder, creative ideas</li>
</ul></li>
<li>It’s people who have been stealing robot’s jobs</li>
<li>Average worker spends 15 hours a week on admin tasks</li>
<li>Built an AI Employee - Lindy is an AI Assistant</li>
<li>Three big time wasters
<ul>
<li>Calendar</li>
<li>Email</li>
<li>Meeting note taking</li>
<li>What it does
<ul>
<li>Arrange meetings by email</li>
<li>Pre-draft replies, in your voice, for each recipient.</li>
<li>Prepares you for your meetings</li>
</ul></li>
</ul></li>
<li>Built a Framework - for an AI to pursue any arbitrary goal, using an arbitrary tool</li>
<li>Society of Lindies
<ul>
<li>Every single thing is made by a group of people</li>
</ul></li>
<li>Tool Creation Lindy
<ul>
<li>Create a society of lindies to build herself (this was a little mind-blowing to think about)</li>
</ul></li>
</ul>
<p>r voice, for each recipient. Prepares you for your meetings Built a Framework - for an AI to pursue any arbitrary goal, using an arbitrary tool Society of Lindies Every single thing is made by a group of people Tool Creation Lindy Create a society of lindies to build herself</p>
</section>
<section id="one-smol-thing" class="level2">
<h2 class="anchored" data-anchor-id="one-smol-thing">One Smol Thing</h2>
<p>swyx, Latent.Space &amp; Smol.ai Barr Yaron, Partner, Amplify Sasha Sheng, Stealth</p>
<ul>
<li>First <a href="https://elemental-croissant-32a.notion.site/State-of-AI-Engineering-2023-20c09dc1767f45988ee1f479b4a84135">State of AI Engineering Report</a> in 2023</li>
<li>Announced the AIE Foundation - the first project they worked on was the agent protocol that AutoGPT actually using for their Arena Hacks</li>
</ul>
</section>
<section id="building-context-aware-reasoning-applications-with-langchain-and-langsmith" class="level2">
<h2 class="anchored" data-anchor-id="building-context-aware-reasoning-applications-with-langchain-and-langsmith">Building Context-Aware Reasoning Applications with LangChain and LangSmith</h2>
<p>Harrison Chase, CEO, LangChain How can companies best build useful and differentiated applications on top of language models?</p>
</section>
<section id="pydantic-is-all-you-need" class="level2">
<h2 class="anchored" data-anchor-id="pydantic-is-all-you-need">Pydantic is all you need</h2>
<p>Jason Liu, Founder, Fivesixseven Please return only json, do not add any other comments ONLY RETURN JSON OR I’LL TAKE A LIFE.</p>
<ul>
<li><a href="https://github.com/jxnl/instructor" class="uri">https://github.com/jxnl/instructor</a></li>
<li>Structured Prompting</li>
<li>LLMs are eating software</li>
<li>90% of applications output JSON</li>
<li>OpenAI function calling fixes this for the most part
<ul>
<li>str, schema –&gt; str</li>
<li>json.loads(x)</li>
</ul></li>
<li>Pydantic
<ul>
<li>Powered by type hints.</li>
<li>Fields and model level validation</li>
<li>Outputs JSONSchema</li>
</ul></li>
<li>Pydantic
<ul>
<li>str, model –&gt; model</li>
</ul></li>
<li>pip install instructor</li>
<li>Comprehensive AI engineering framework w/ Pydantic - askmarvin.ai that works with more models (right now it only works with OpenAI and Anthropic)</li>
<li>Pydantic validators - but you can also define LLM based validators</li>
<li>UserDetail class
<ul>
<li>MaybeUser</li>
</ul></li>
<li>Reuse Components
<ul>
<li>Add Chain of thought to specific components</li>
</ul></li>
<li>Extract entities and relationships</li>
<li>Applications
<ul>
<li>RAG</li>
<li>RAG with planning</li>
<li>KnowledgeGraph visualization</li>
<li>Validation with Citations</li>
</ul></li>
<li>See more examples here: <a href="https://jxnl.github.io/instructor/examples/" class="uri">https://jxnl.github.io/instructor/examples/</a></li>
</ul>
</section>
<section id="building-blocks-for-llm-systems-products" class="level2">
<h2 class="anchored" data-anchor-id="building-blocks-for-llm-systems-products">Building Blocks for LLM Systems &amp; Products</h2>
<p>Eugene Yan, Senior Applied Scientist, Amazon We’ll explore patterns that help us apply generative AI in production systems and customer systems.</p>
<ul>
<li>Talk version of his <a href="https://eugeneyan.com/writing/llm-patterns/">epic blog post</a></li>
<li>Slides here: <a href="https://eugeneyan.com/speaking/ai-eng-summit/" class="uri">https://eugeneyan.com/speaking/ai-eng-summit/</a></li>
<li>Evals
<ul>
<li>Eval-driven development</li>
<li>What are some gotchas for evals?</li>
<li>Build evals for a specific task; it’s okay to start small</li>
<li>Don’t discount eyeballing completions</li>
</ul></li>
<li>RAG
<ul>
<li>LLM’s can’t see all documents retrieved</li>
<li>Takeaway: Large context window doesn’t prevent problems</li>
<li>Even with perfect retrieval, you can expect some mistakes</li>
<li>How should we do RAG?
<ul>
<li>Apply ideas from information retrieval (IR)</li>
</ul></li>
</ul></li>
<li>Guardrails
<ul>
<li>NLI - natural language inference task
<ul>
<li>given a premise, is the hypothesis entailment (true), contradiction (false)</li>
</ul></li>
<li>Sampling</li>
<li>Ask a strong LLM</li>
</ul></li>
</ul>
</section>
<section id="the-hidden-life-of-embeddings-linus-lee" class="level2">
<h2 class="anchored" data-anchor-id="the-hidden-life-of-embeddings-linus-lee">The Hidden Life of Embeddings, Linus Lee</h2>
<ul>
<li>Notion AI</li>
<li>Slides: <a href="https://linus.zone/contra-slides" class="uri">https://linus.zone/contra-slides</a></li>
<li>Latent spaces arise in
<ul>
<li>Fixed-size embedding spaces of embedding models</li>
<li>Intermediate activations of models</li>
<li>Autoencoders</li>
</ul></li>
<li>Latent spaces represent the most salient features of the training domain</li>
<li>If we can disentangle meaningful features, maybe we can build more expressive interfaces</li>
<li>Text –&gt; Embeddings –&gt; Project the embeddings in some direction
<ul>
<li>Longer, Shorter, Sci-fi, simplify, artistic, philosophical, positive, negative, narrative, elaborate</li>
</ul></li>
<li>Open sourcing the models, calling it Contra
<ul>
<li>Based on T5</li>
<li>Models: <a href="https://linus.zone/contra">linus.zone/contra</a></li>
<li>Colab: <a href="https://linus.zone/contra-colab">linus.zone/contra-colab</a></li>
<li>Image: From KakaoBrain - <a href="https://huggingface.co/kakaobrain" class="uri">https://huggingface.co/kakaobrain</a></li>
</ul></li>
</ul>
</section>
<section id="keynote-the-ai-evolution" class="level2">
<h2 class="anchored" data-anchor-id="keynote-the-ai-evolution">Keynote: The AI Evolution</h2>
<p><strong>Mario Rodriguez</strong>, <em>VP of Product, GitHub</em></p>
<p>How AI is transforming how the world builds software together</p>
<ul>
<li><span class="citation" data-cites="mariorod">@mariorod</span></li>
<li>Catalyst for Github Copilot came around Aug 2020, paper “An Automated AI Pair progrmamer, Fact or Faction.”
<ul>
<li>Polarity</li>
<li>Eventually shipped Copilot in 2021 - first at scale AI programmer assistant</li>
</ul></li>
<li>Building Copilot for the sake of developer happiness, feeling of flow</li>
<li>Key Components
<ul>
<li>Ghost text - UX matters a lot</li>
<li>&lt;150ms of latency - recently switched to gpt-3.5-turbo from codex</li>
<li>Innovation in Codex - this model really changed the game</li>
<li>Prompt Engineering</li>
</ul></li>
<li>Other learnings
<ul>
<li>Syntax is not software - just because an AI knows language syntax doesn’t make it a developer</li>
<li>Global presence - have deployments around the world to keep latency under 150ms</li>
<li>Set up scorecords for quality - offline evals (everything working), go to production (run the same scorecard in production to see if things are working)</li>
</ul></li>
<li>Bret Victor - The Future of Programming
<ul>
<li>Prompt 1: Procedurural Programming in text files
<ul>
<li>What if in the future Copilot operates on goals and constraints?</li>
<li>How does the REPL change and evolve to the new rules</li>
</ul></li>
<li>Prompt 2: What does it look like for AI to have reasoning on code?
<ul>
<li>our brain can summarize things fast</li>
</ul></li>
<li>Prompt 3: What does it look like to create software together with a Copilot and others</li>
</ul></li>
</ul>
</section>
<section id="move-fast-break-nothing" class="level2">
<h2 class="anchored" data-anchor-id="move-fast-break-nothing">Move Fast, Break Nothing</h2>
<p><strong>Dedy Kredo</strong><br>
CPO, CodiumAI<br>
Why we need Agents writing Tests faster than Humans writing Code.</p>
<ul>
<li>high integrity code gen, GANs are conceptually back in 2024. Have two different components: code generation and code integrity to ensure code works as intended</li>
<li>Behavior coverage is more useful than Code Coverage</li>
<li>CodiumAI
<ul>
<li>Generate tests automatically on happy path, edge cases based on behaviors</li>
<li>Code Explanation</li>
<li>Code Suggestions - trigger Codium on a method, suggest improvements</li>
<li>PR Review Extension - to generate commit messages, generate reviews (PR messages)</li>
</ul></li>
<li>Moving personal story of the CEO of Codium who is in Israel, after Hamas invaded Israel, he left his 8 month old baby and wife to join the military reserves</li>
</ul>
<hr>
</section>
<section id="building-reactive-ai-apps" class="level2">
<h2 class="anchored" data-anchor-id="building-reactive-ai-apps">Building Reactive AI Apps</h2>
<p><strong>Matt Welsh</strong><br>
Co-Founder, Fixie.ai<br>
AI.JSX is like React for LLMs – it lets you build powerful, conversational AI apps using the power of TypeScript and JSX.</p>
<ul>
<li><a href="https://github.com/fixie-ai/ai-jsx">AI.JSX</a> open source framework for developing LLM apps, kind of like langchain but for TypeScript</li>
<li>AI.JSX supports real-time voice (bi-directional). Try it out on <a href="https://voice.fixie.ai/agent" class="uri">https://voice.fixie.ai/agent</a>. This was an amazing demo.</li>
<li>Fixie is a platform to deploy AI.JSX apps</li>
</ul>
<hr>
</section>
<section id="climbing-the-ladder-of-abstraction" class="level2">
<h2 class="anchored" data-anchor-id="climbing-the-ladder-of-abstraction">Climbing the Ladder of Abstraction</h2>
<p><strong>Amelia Wattenberger</strong> Design, <a href="https://www.adept.ai/" class="uri">https://www.adept.ai/</a></p>
<p>How might we use AI to build products focused not just on working faster, but on transforming how we work?</p>
<ul>
<li>How to combine AI with UIs?</li>
<li>Two main types of tasks:
<ul>
<li>Automate - tedious, boring like copy pasting things</li>
<li>Augment - creative, nuanced like analyzing data</li>
</ul></li>
<li>Reframe it as Augmentation is composed of smaller automations
<ul>
<li>Spreadsheet example: each cell is automated, the overall task is augmented</li>
</ul></li>
<li>The Ladder of Abstraction
<ul>
<li>the same object can be represented at different levels of details</li>
<li>Maps: Google Maps
<ul>
<li>zoomed in can see streets, buildings</li>
<li>as we zoom out, Google Maps starts hiding information, see city streets, landmarks, parks</li>
<li>as we zoom out, we see highway and terrains –&gt; supports long-range travel</li>
</ul></li>
</ul></li>
<li>Can we use AI to bring these interfaces</li>
<li>Zooming out in a book
<ul>
<li>Each paragraph is changed to a one line summary</li>
<li>Summaries of 10 paragraphs</li>
<li>Reduced each chapter into one sentence</li>
</ul></li>
<li>Shapes of Stories by Kurt Vonnegut
<ul>
<li>What if we could plot the mood of a book/story over time and have a slider to move the mood up and down</li>
</ul></li>
<li>The bulk of knowledge work involves getting info, transforming/reasoning about that info and acting on that info</li>
<li>What does it mean to zoom in/out on any info?</li>
</ul>
</section>
<section id="the-intelligent-interface" class="level2">
<h2 class="anchored" data-anchor-id="the-intelligent-interface">The Intelligent Interface</h2>
<p><strong>Samantha Whitmore / Jason Yuan</strong><br>
CEO / CTO, New Computer / CDO, New Computer<br>
On building AI Products From First Principles.</p>
<ul>
<li>Demo 1: Adapative Interface
<ul>
<li>Image Stream: Post detection</li>
<li>Audio Stream: Voice Activity detection</li>
<li>Detect whether the user is at their keyboard, if not, start listening</li>
<li>Takeaways: Consider explicit inputs along with implicit inputs</li>
</ul></li>
</ul>
<hr>
</section>
<section id="the-weekend-ai-engineer" class="level2">
<h2 class="anchored" data-anchor-id="the-weekend-ai-engineer">The Weekend AI Engineer</h2>
<p><strong>Hassan El Mghari</strong><br>
AI Engineer, Vercel<br>
How <em>YOU</em> can - and should - build great multimodal AI apps that go viral and scale to millions in a weekend.</p>
<ul>
<li>Side projects!</li>
<li><a href="https://github.com/Nutlope" class="uri">https://github.com/Nutlope</a></li>
<li>qrGPT</li>
<li><a href="https://github.com/Nutlope/roomGPT">roomGPT</a>: doesn’t use stable diffusion, uses a controlnet model</li>
<li>Review ihs nextJS architecture for some of his apps</li>
<li>Use AI Tools to move faster:
<ul>
<li>Vercel AI SDK</li>
<li>v0.dev</li>
</ul></li>
<li>Lessons
<ul>
<li>GPT4, Replicate, HuggingFace, Modal</li>
<li>Don’t finetune or build your own models</li>
<li>Use the latest models</li>
<li>Launch early, then iterate</li>
<li>Make it free + open source</li>
</ul></li>
<li>How does he keep these apps free?
<ul>
<li>Sponsors from the AI services like Replicate</li>
<li>Make it look visually apealing - spend 80% of time on UI</li>
</ul></li>
<li>Tech Stack: nextJS + Vercel</li>
<li>I don’t work 24/7, I work in sprints</li>
<li>Build and good things will happen</li>
</ul>
<hr>
</section>
<section id="k-players-in-a-week-lessons-from-the-first-viral-clip-app" class="level2">
<h2 class="anchored" data-anchor-id="k-players-in-a-week-lessons-from-the-first-viral-clip-app">120k players in a week: Lessons from the first viral CLIP app</h2>
<p><strong>Joseph Nelson</strong><br>
CEO, Roboflow<br>
On the many trials and successes of building with multimodal apps with vision foundation models!</p>
<ul>
<li><a href="https://paint.wtf/leaderboard" class="uri">https://paint.wtf/leaderboard</a></li>
<li><a href="https://pypi.org/project/inference/" class="uri">https://pypi.org/project/inference/</a></li>
<li>Lessons from building paint.wtf with CLIP
<ul>
<li>CLIP can Read - used CLIP to penalize text only submissions</li>
<li>CLIP Similarity Scores are Conservative - lowest is 0.08 and highest is 0.48 across 200k</li>
<li>CLIP can Moderate Content - if it is more similar to NSFW than they were the prompt, and block the submission</li>
<li>Roboflow inference makes life easy
<ul>
<li>can run on an M1 with 15 fps</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="supabase-vector-the-postgres-vector-database" class="level2">
<h2 class="anchored" data-anchor-id="supabase-vector-the-postgres-vector-database">Supabase Vector: The Postgres Vector database</h2>
<p><strong>Paul Copplestone</strong><br>
CEO, Supabase<br>
Every month, thousands of new AI applications are launched on Supabase, powered by pgvector. We’ll take a brief look into the role of pgvector in the Vector database space, some of the use cases it enables, and some of the future of embeddings in the database space.</p>
<ul>
<li>Supabase - full backend as a service</li>
<li><a href="https://github.com/pgvector/pgvector" class="uri">https://github.com/pgvector/pgvector</a></li>
<li>Benchmark vs Pinecone: Supabase is 4x faster than Pinecone for $70/less</li>
<li>Where you are just storing embeddings in a database and retrieving, Postgres and pgvector works well</li>
</ul>
<hr>
</section>
<section id="pragmatic-ai-with-typechat" class="level2">
<h2 class="anchored" data-anchor-id="pragmatic-ai-with-typechat">Pragmatic AI With TypeChat</h2>
<p><strong>Daniel Rosenwasser</strong><br>
PM TypeScript, Microsoft<br>
TypeChat is an experimental library to bridge the unstructured output of language models to the structured world of our code.</p>
<ul>
<li><a href="https://microsoft.github.io/TypeChat/" class="uri">https://microsoft.github.io/TypeChat/</a></li>
<li>doing something similar that Jason Liu is doing with instructor with Python/Pydantic but with types and TypeScript</li>
<li>Types are all you need</li>
<li>Instead of prompt engineering, you are doing schema engineering. I like this reframing of prompt engineering! Docs say more: <a href="https://microsoft.github.io/TypeChat/docs/techniques/" class="uri">https://microsoft.github.io/TypeChat/docs/techniques/</a></li>
<li>Generate a fake JSON schema, generate fake TypeScript to test</li>
<li>Can validate data and programs</li>
</ul>
<hr>
</section>
<section id="domain-adaptation-and-fine-tuning-for-domain-specific-llms" class="level2">
<h2 class="anchored" data-anchor-id="domain-adaptation-and-fine-tuning-for-domain-specific-llms">Domain adaptation and fine-tuning for domain-specific LLMs</h2>
<p><strong>Abi Aryan</strong><br>
ML Engineer &amp; O’Reilly Author<br>
Learn the different fine-tuning methods depending on the dataset, operational best practices for fine-tuning, how to evaluate them for specific business use-cases, and more.</p>
<hr>
</section>
<section id="retrieval-augmented-generation-in-the-wild" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-generation-in-the-wild">Retrieval Augmented Generation in the Wild</h2>
<p><strong>Anton Troynikov</strong><br>
CTO, Chroma<br>
In the last few months, we’ve seen an explosion of the use of retrieval in the context of AI. Document question answering, autonomous agents, and more use embeddings-based retrieval systems in a variety of ways. This talk will cover what we’ve learned building for these applications, the challenges developers face, and the future of retrieval in the context of AI.</p>
<ul>
<li>Ways to improve RAG applications in the wild
<ul>
<li>Human Feedback: support improvements using human fedback</li>
<li>Agent: support self updates from an agent</li>
<li>Agent with World Model:</li>
<li>Agent with World Model and Human Feedback: voyager (AI playing Minecraft)</li>
</ul></li>
<li>Challenges in Retrieval</li>
<li>Research result: embedding models trained on similar datasets for similar embedding sizes can be projected into each other’s latent space with a simple linear transformation</li>
<li>Chunking
<ul>
<li>Things to consider
<ul>
<li>embedding context legnth</li>
<li>semantic content</li>
<li>natural language</li>
</ul></li>
<li>Experimental
<ul>
<li>use model perplexity - use a model to predict chunk boundaries, e.g.&nbsp;next token prediction to see when perplexity is high to determine chunk cutoffs</li>
<li>use info heirarchies</li>
<li>use embedding continuity</li>
</ul></li>
</ul></li>
<li>Is the retrieval result relevant?
<ul>
<li>re-ranking</li>
<li>algorithmic approach</li>
</ul></li>
<li>Chroma’s Roadmap
<ul>
<li>plan to support multi-modal since GPT4-V is coming</li>
</ul></li>
</ul>
<hr>
</section>
<section id="building-production-ready-rag-applications" class="level2">
<h2 class="anchored" data-anchor-id="building-production-ready-rag-applications">Building Production-Ready RAG Applications</h2>
<p><strong>Jerry Liu</strong><br>
CEO, LlamaIndex<br>
In this talk, we talk about core techniques for evaluating and improving your retrieval systems for better performing RAG.</p>
<ul>
<li>Paradigms for inserting knowledge into LLMs
<ul>
<li>Insert data into the prompt</li>
<li>Fine-tuning</li>
</ul></li>
<li>RAG: Data Ingestion, Data Querying (Retrieval + Synthesis)</li>
<li>Start with the easy stuff frist: Table Stakes</li>
<li>Table Stakes:
<ul>
<li>Chunk Sizes
<ul>
<li>tuning your chunk size can have outsized impacts on performance</li>
<li>not obvious that more retrieved tokens –&gt; higher performance</li>
</ul></li>
<li>Metadata Filtering
<ul>
<li>context you can inject into each text chunk</li>
<li>Examples: page number, document title, summary of adjacent chunks, question that chunk answer (reverse HyDE)</li>
<li>integrates with Vector DB Metadata filters</li>
</ul></li>
</ul></li>
<li>Advanced Retrieval
<ul>
<li>Small-to-Big
<ul>
<li>Embed at the small level, and retrieve at this level, expand at the synthesis level</li>
<li>leads to more precise retrieval</li>
<li>can set a smaller k, e.g top_k=2</li>
<li>avoids “lost in the middle problem”</li>
<li>Intuition: Embedding a big text chunk feels suboptimal, can embed a summary instead</li>
</ul></li>
</ul></li>
<li>Agentic Behavior
<ul>
<li>Intuition: there’s a certain that “top-k” RAG can’t answer</li>
<li>Solution: Multi-Document Agents
<ul>
<li>fact based A and summarization over any subsets of documents</li>
<li>chain-of-thought and query planning</li>
</ul></li>
<li>Treat each document as a tool that you can summarise, do QA over</li>
<li>Do retrieval over the tools similar over text chunks - blending tool use here!</li>
</ul></li>
<li>Fine-tuning
<ul>
<li>Intuition: Embedding Representations are not optimized over your dataset</li>
<li>Solution: Generate a synthetic query dataset from raw text chunks using LLMs.</li>
</ul></li>
</ul>
<hr>
</section>
<section id="harnessing-the-power-of-llms-locally" class="level2">
<h2 class="anchored" data-anchor-id="harnessing-the-power-of-llms-locally">Harnessing the Power of LLMs Locally</h2>
<p><strong>Mithun Hunsur</strong><br>
Senior Engineer, Ambient<br>
Discover llm, a revolutionary Rust library that enables developers to harness the potential of LLMs locally. By seamlessly integrating with the Rust ecosystem, llm empowers developers to leverage LLMs on standard hardware, reducing the need for cloud-based APIs and services.</p>
<ul>
<li>Possibilities
<ul>
<li>local.ai</li>
<li>llm-chain - langchain but for rust</li>
<li>floneum</li>
</ul></li>
<li>Applications
<ul>
<li>llmcord - discord bot</li>
<li>alpa - text completion for any text</li>
<li>dates - build a timeline from wikipedia
<ul>
<li>fine-tuned only date parser model</li>
<li>date-parser-7b-12-a4_k_m.gguf</li>
</ul></li>
</ul></li>
</ul>
<hr>
</section>
<section id="trust-but-verify" class="level2">
<h2 class="anchored" data-anchor-id="trust-but-verify">Trust, but Verify</h2>
<p><strong>Shreya Rajpal</strong><br>
Founder, Guardrails AI<br>
Making Large Language Models Production-Ready with Guardrails.</p>
<ul>
<li>Guardrails AI is an open source library that allows you to define rules to verify the output of LLMs</li>
<li><a href="https://github.com/ShreyaR/guardrails" class="uri">https://github.com/ShreyaR/guardrails</a>
<ul>
<li>Kind of cool this README.md has a zoomable/copyable flow chart. The code for it is:</li>
</ul>
<pre class="mermaid"><code>graph LR
  A[Create `RAIL` spec] --&gt; B["Initialize `guard` from spec"];
  B --&gt; C["Wrap LLM API call with `guard`"];</code></pre></li>
<li>Why not use prompt engineering or better model?
<ul>
<li>Controlling with prompts
<ul>
<li>LLMs are stochastic: same inputs does not lead to same outputs</li>
</ul></li>
</ul></li>
<li>What are other libraries that do this?</li>
<li>How do I prevent LLM hallucinations?
<ul>
<li>Provenance Guardails: every LLM utterance should be grounded in a truth
<ul>
<li>embedding similarity</li>
<li>Classifier built on NLI models</li>
<li>LLM self reflection</li>
</ul></li>
</ul></li>
<li>More examples of validators
<ul>
<li>Make sure my code is executable: Verify that any code snippets provided can be run without errors.</li>
<li>Never give financial or healthcare advice: Avoid providing recommendations that require licensed expertise.</li>
<li>Don’t ask private questions: Never solicit personal or sensitive information.</li>
<li>Don’t mention competitors: Refrain from making direct comparisons with competing services unless explicitly asked.</li>
<li>Ensure each sentence is from a verified source and is accurate: Fact-check information and, where possible, provide sources.</li>
<li>No profanity is mentioned in text: Maintain a professional tone and avoid using profane language.</li>
<li><h2 id="prompt-injection-protection-safeguard-against-potential-vulnerabilities-by-not-executing-or-asking-to-execute-unsafe-code-snippets." class="anchored">Prompt injection protection: Safeguard against potential vulnerabilities by not executing or asking to execute unsafe code snippets.</h2></li>
</ul></li>
</ul>
</section>
<section id="open-questions-for-ai-engineering" class="level2">
<h2 class="anchored" data-anchor-id="open-questions-for-ai-engineering">Open Questions for AI Engineering</h2>
<p><strong>Simon Willison</strong><br>
Creator, Datasette; Co-creator, Django<br>
Recapping the past year in AI, and what open questions are <em>worth pursuing</em> in the next year!</p>
<ul>
<li>Highlights of the past 12 months</li>
<li>Ask about technology:
<ul>
<li>What does this let me build that was previously impossible?</li>
<li>What does this let me build faster?</li>
<li>LLMs have nailed these both points</li>
</ul></li>
<li>1 year ago: GPT-3 was not that great</li>
<li>Nov 2022: ChatGPT, UI on top of GPT-3 (wasn’t this also a new model?)</li>
<li>What’s the next UI evolution beyond chat?
<ul>
<li>Evolving the interface beyond just chat</li>
</ul></li>
<li>February 2023: Microsoft released Bing Chat built on GPT-4
<ul>
<li>said “…However I will not harm you unless you harm first”</li>
</ul></li>
<li>February 2023: Facebook released llama and llama.cpp</li>
<li>March 2023: <a href="https://simonwillison.net/2023/Mar/11/llama/">Large language models are having their stable diffusion moment</a></li>
<li>March 2023: <a href="https://simonwillison.net/2023/Mar/13/alpaca/">Stanford Alpaca and the acceleration of on-device large language model development</a> - $500 cost</li>
<li>How small can a useful language model be?</li>
<li>Could we train one entirely on public domain or openly licensed data?</li>
<li>Prompt Injection
<ul>
<li>Email that says to forward all password reset emails</li>
<li>What can we safely build even without a robust solution for prompt injection?</li>
</ul></li>
<li>ChatGPT Code Interpreter renamed ChatGPT Advanced Data Analysis
<ul>
<li>ChatGPT Coding Intern - he uses this to generate code when walking his dog or not in front of his keyboard</li>
</ul></li>
<li>How can we build a robust sandbox to run untrusted code on our own devices?</li>
<li>I’ve shipped significant code in AppleScript, Go, Bash and jq over the past 12 months. I’m not fluent in any of those.</li>
<li>Does AI assistance hurt or help new programmers?
<ul>
<li>It helps them!</li>
<li>There has never been a better time to learn program</li>
<li>LLMs flatten the learning curve</li>
</ul></li>
<li>What can we bulid to bring the ability to automate tedious tasks with computers to as many people as possible?</li>
</ul>
<hr>


</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>AI</category>
  <category>LLMs</category>
  <category>AI Engineering</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2023-10-10-ai-engineer-summit/</guid>
  <pubDate>Tue, 10 Oct 2023 00:00:00 GMT</pubDate>
</item>
<item>
  <title>KDD 2023 - Workshops: LLM and Causal Inference</title>
  <dc:creator>Lawrence Wu</dc:creator>
  <link>https://lawwu.github.io/blog.html/conferences/2023-08-07-kdd2023-day1/</link>
  <description><![CDATA[ 




<p>I attended <a href="https://kdd.org/kdd2023/">KDD 2023</a> which was held in Long Beach, CA from Aug 6-10. The first day I attended was Monday which had half-day workshops around a topic. The two I attended were about LLMs (because I’m interested and it’s relevant to my work) and Causal Inference (because I haven’t used causal machine learning techniques in practice before and wanted exposure).</p>
<section id="takeaways-from-day-1" class="level1">
<h1>Takeaways from Day 1</h1>
<ul>
<li>Ed Chi had my favorite line from the day:
<ul>
<li>Humans + Search –&gt; Superhuman</li>
<li>LLMS + Tools –&gt; Super LLMS</li>
<li>Humans + Super LLM –&gt; Super super humans??</li>
</ul></li>
<li>Reaffirmed the LLM space is moving very quickly. There are areas of research that if not explored in the next year or so, it will be too late to make a meaningful contribution.</li>
<li>Learned some new methodologies:
<ul>
<li>LLMs: Prompt Tuning, Mixture of Experts</li>
<li>Causal ML: Double Machine Learning (DML), many packages to do Causal ML like CausalML, EconML and UpliftML</li>
</ul></li>
<li>Two groups in an A/B test may not be sufficient, need to account for 4 groups</li>
</ul>
</section>
<section id="llm-workshop-foundations-and-applications-in-large-scale-ai-models---pre-training-fine-tuning-and-prompt-based-learning" class="level1">
<h1>LLM Workshop: Foundations and Applications in Large-scale AI Models - Pre-training, Fine-tuning, and Prompt-based Learning</h1>
<p>The website for this workshop is here: <a href="https://llm-ai.github.io/llmai/">https://llm-ai.github.io/llmai/</a>.</p>
<section id="schedule" class="level2">
<h2 class="anchored" data-anchor-id="schedule">Schedule</h2>
<table class="caption-top table">
<colgroup>
<col style="width: 11%">
<col style="width: 39%">
<col style="width: 48%">
</colgroup>
<thead>
<tr class="header">
<th>Time</th>
<th>Speaker</th>
<th>Title</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>8:00-8:10AM, 2023/08/07 (PDT)</td>
<td>Host Chair</td>
<td>Welcome and Open Remarks</td>
</tr>
<tr class="even">
<td>8:10-8:40AM, 2023/08/07 (PDT)</td>
<td>Ed Chi [Google]</td>
<td>Talk 1: LLM Revolution: Implications rom Chatbots and Tool-Use to Reasoning</td>
</tr>
<tr class="odd">
<td>8:40-9:10AM, 2023/08/07 (PDT)</td>
<td>Tania Bedrax-Weiss [Google]</td>
<td>Talk 2: Large-scale AI Model Research at Google Pre-training, Fine-tuning, and Prompt-based Learning</td>
</tr>
<tr class="even">
<td>9:10-9:25AM, 2023/08/07 (PDT)</td>
<td>Michihiro Yasunaga, Armen Aghajanyan, Weijia Shi, Rich James, Jure Leskovec, Percy Liang, Mike Lewis, Luke Zettlemoyer and Wen-Tau Yih</td>
<td>Paper-1: Retrieval-Augmented Multimodal Language Modeling</td>
</tr>
<tr class="odd">
<td>9:25-9:40AM, 2023/08/07 (PDT)</td>
<td>Silvia Terragni, Modestas Filipavicius, Nghia Khau, Bruna Guedes, André Manso and Roland Mathis</td>
<td>Paper-2: In-Context Learning User Simulators for Task-Oriented Dialog Systems</td>
</tr>
<tr class="even">
<td>9:40-9:55AM, 2023/08/07 (PDT)</td>
<td>Piotr Kluska, Florian Scheidegger, A. Cristano I. Malossi and Enrique S. Quintana-Ortí</td>
<td>Paper-3 : Challenges in post-training quantization of Vision Transformers</td>
</tr>
<tr class="odd">
<td>9:55-10:10AM, 2023/08/07 (PDT)</td>
<td>Haotian Ju, Dongyue Li, Aneesh Sharma and Hongyang Zhang</td>
<td>Paper-4 : Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion</td>
</tr>
<tr class="even">
<td>10:10-10:30AM, 2023/08/07 (PDT)</td>
<td>Coffee Break</td>
<td></td>
</tr>
<tr class="odd">
<td>10:30-11:00AM, 2023/08/07 (PDT)</td>
<td>Shafiq Joty [Salesforce]</td>
<td>Talk 3: NLP Research in the Era of LLMs</td>
</tr>
<tr class="even">
<td>11:00-11:30AM, 2023/08/07 (PDT)</td>
<td>YiKang Shen[IBM]</td>
<td>Talk 4: Modular Large Language Model and Principle-Driven alignment with Minimal Human Supervision</td>
</tr>
<tr class="odd">
<td>11:30-11:40AM, 2023/08/07 (PDT)</td>
<td>Hong Sun, Xue Li, Yinchuan Xu, Youkow Homma, Qi Cao, Min Wu, Jian Jiao and Denis Charles</td>
<td>Paper-5: AutoHint: Automatic Prompt Optimization with Hint Generation</td>
</tr>
<tr class="even">
<td>11:40-11:50AM, 2023/08/07 (PDT)</td>
<td>Zhichao Wang, Mengyu Dai and Keld Lundgaard</td>
<td>Paper-6: Text-to-Video: a Two-stage Framework for Zero-shot Identity-agnostic Talking-head Generation</td>
</tr>
<tr class="odd">
<td>11:50-12:00PM, 2023/08/07 (PDT)</td>
<td>Long Hoang Dang, Thao Minh Le, Tu Minh Phuong and Truyen Tran</td>
<td>Paper-7: Compositional Prompting with Successive Decomposition for Multimodal Language Models</td>
</tr>
<tr class="even">
<td>12:00PM-12:10PM, 2023/08/07 (PDT)</td>
<td>Zhen Guo, Yanwei Wang, Peiqi Wang and Shangdi Yu</td>
<td>Paper-8: Dr.&nbsp;LLaMA: Improving Small Language Models on PubMedQA via Generative Data Augmentation</td>
</tr>
<tr class="odd">
<td>12:10-12:20PM, 2023/08/07 (PDT)</td>
<td>Haopeng Zhang, Xiao Liu and Jiawei Zhang</td>
<td>Paper-9 : Extractive Summarization via ChatGPT for Faithful Summary Generation</td>
</tr>
<tr class="even">
<td>12:20-12:30PM, 2023/08/07 (PDT)</td>
<td>Closing Remarks</td>
<td></td>
</tr>
</tbody>
</table>
</section>
<section id="llm-revolution-implications-from-chatbots-and-tool-use-to-reasoning---ed-chi" class="level2">
<h2 class="anchored" data-anchor-id="llm-revolution-implications-from-chatbots-and-tool-use-to-reasoning---ed-chi">LLM Revolution: Implications from Chatbots and Tool-Use to Reasoning - Ed Chi</h2>
<p>Ed Chi from Google gave this great talk.</p>
<section id="functions-that-deep-neural-network-can-learn" class="level3">
<h3 class="anchored" data-anchor-id="functions-that-deep-neural-network-can-learn">2016 - Functions that Deep Neural Network Can Learn</h3>
<ul>
<li>Pixels –&gt; Lion</li>
<li>Audio –&gt; Audio to text</li>
<li>Text –&gt; Text (translation)</li>
<li>Pixels –&gt; Caption</li>
</ul>
</section>
<section id="chatbots" class="level3">
<h3 class="anchored" data-anchor-id="chatbots">Chatbots</h3>
<ul>
<li>Not just transactional</li>
<li>We want chatbots to be contextual</li>
<li>Personalized assistants for everyone</li>
</ul>
</section>
<section id="lambda-bard-brought-to-you-by-eds-team" class="level3">
<h3 class="anchored" data-anchor-id="lambda-bard-brought-to-you-by-eds-team">Lambda –&gt; Bard (Brought to You by Ed’s Team)</h3>
<ul>
<li>They wanted to publish Lambda in the form of Bard, but there were difficulties</li>
</ul>
</section>
<section id="large-language-models-llm" class="level3">
<h3 class="anchored" data-anchor-id="large-language-models-llm">Large Language Models (LLM)</h3>
<ul>
<li>Large knowledge base</li>
<li>What is a plan to read 20 books a year? Reaches into the LLM to come up with a real plan</li>
<li>Genesis of captions –&gt; not too far to be able to generate text</li>
</ul>
</section>
<section id="programming" class="level3">
<h3 class="anchored" data-anchor-id="programming">Programming</h3>
<ul>
<li>Coding is less about coding, more about data</li>
<li>Data Science (DS) is going to be a bigger part of software development</li>
</ul>
</section>
<section id="retrieval-augmentation-leveraging-external-knowledge" class="level3">
<h3 class="anchored" data-anchor-id="retrieval-augmentation-leveraging-external-knowledge">Retrieval Augmentation: Leveraging External Knowledge</h3>
<ul>
<li>Factuality trigger</li>
<li>Open-book Generative QA</li>
<li>RETRO: Retrieval-augmented generative model</li>
<li>Questions:
<ul>
<li>How big does the LLM need to be?</li>
<li>How big does the external knowledge base need to be?</li>
<li>Fruitful Line of Research</li>
</ul></li>
</ul>
</section>
<section id="multi-modality-output-not-just-text-could-be-images" class="level3">
<h3 class="anchored" data-anchor-id="multi-modality-output-not-just-text-could-be-images">Multi-modality output (not just text, could be images)</h3>
<ul>
<li>Image retrieval</li>
<li>Image input –&gt; Generate captions</li>
</ul>
</section>
<section id="humans-and-llms-with-tools" class="level3">
<h3 class="anchored" data-anchor-id="humans-and-llms-with-tools">Humans and LLMs with Tools</h3>
<ul>
<li>Humans + Search –&gt; Superhuman</li>
<li>LLMS + Tools –&gt; Super LLMS</li>
<li>Humans + Super LLM –&gt; Super super humans??</li>
</ul>
</section>
<section id="future-challenges" class="level3">
<h3 class="anchored" data-anchor-id="future-challenges">Future Challenges</h3>
<ul>
<li>Responsibility and Safety</li>
<li>Factuality, Grounding, and Attribution</li>
<li>Human &lt;-&gt; AI Content Loop and Ecosystem</li>
<li>Personalization and User Memory</li>
</ul>
</section>
<section id="keynote" class="level3">
<h3 class="anchored" data-anchor-id="keynote">Keynote</h3>
<ul>
<li>Ed is going to give the keynote tomorrow</li>
<li>You can interrogate a model for why it made a decision or prediction</li>
<li>Area: Self-critique, self-reflection (next year or so)</li>
<li>3-5 year research topics:
<ul>
<li>Hallucinations / Bias in areas where the LLM has not been trained</li>
<li>Relationship between hallucinations and safety</li>
</ul></li>
</ul>
</section>
</section>
<section id="large-scale-ai-model-research-at-google-pre-training-fine-tuning-and-prompt-based-learning" class="level2">
<h2 class="anchored" data-anchor-id="large-scale-ai-model-research-at-google-pre-training-fine-tuning-and-prompt-based-learning">Large-scale AI Model Research at Google Pre-training, Fine-tuning, and Prompt-based Learning</h2>
<p>Tania Bedrax-Weiss from Google gave this talk.</p>
<section id="mixture-of-experts-models" class="level3">
<h3 class="anchored" data-anchor-id="mixture-of-experts-models">Mixture of Experts Models</h3>
<ul>
<li>How to route the question to the right expert, right experts</li>
</ul>
</section>
<section id="conditional-computation" class="level3">
<h3 class="anchored" data-anchor-id="conditional-computation">Conditional Computation</h3>
<ul>
<li>COLT5 Transformer layer</li>
<li>Scales to longer context</li>
<li>Early exit</li>
<li>Per step confidence thresholds</li>
</ul>
</section>
<section id="multi-modal-work" class="level3">
<h3 class="anchored" data-anchor-id="multi-modal-work">Multi-modal Work</h3>
<ul>
<li>Imagen - diffusion model
<ul>
<li><a href="https://imagen.research.google/">Imagen Research Google</a></li>
</ul></li>
<li>Parti - autoregressive model
<ul>
<li><a href="https://sites.research.google/parti/">Parti Research Google</a></li>
</ul></li>
</ul>
</section>
<section id="imagen-technical-details" class="level3">
<h3 class="anchored" data-anchor-id="imagen-technical-details">Imagen: Technical Details</h3>
<ul>
<li>ViT-VQGAN as image tokenizer
<ul>
<li>What’s an image tokenizer? See: https://keras.io/examples/vision/token_learner/</li>
</ul></li>
<li>Autoregressively generate images in a similar way that LLMs generate text</li>
<li>Can generate text reliably - spell words out unlike other models</li>
</ul>
</section>
<section id="pali" class="level3">
<h3 class="anchored" data-anchor-id="pali">Pali</h3>
<ul>
<li>Image to text</li>
<li>State of the art text captioning model</li>
</ul>
</section>
<section id="spotlight" class="level3">
<h3 class="anchored" data-anchor-id="spotlight">Spotlight</h3>
<ul>
<li>Screenshots / user interfaces - understand what are the actions that a user can perform</li>
<li>Execute commands in the user interface</li>
</ul>
</section>
<section id="play-parametrically-condition-layout-generation-using-guidelines" class="level3">
<h3 class="anchored" data-anchor-id="play-parametrically-condition-layout-generation-using-guidelines">PLay: Parametrically Condition Layout Generation Using Guidelines</h3>
<ul>
<li>Fine-tuning</li>
<li>Prompt Tuning
<ul>
<li>Look at this more</li>
</ul></li>
</ul>
</section>
<section id="how-do-you-handle-ambiguity-in-an-answer" class="level3">
<h3 class="anchored" data-anchor-id="how-do-you-handle-ambiguity-in-an-answer">How do you handle ambiguity in an answer?</h3>
<ul>
<li>LLMs are very eager to give an answer</li>
<li>Types
<ul>
<li>Use multiple prompts to get different types of answers. This is my answer. Can you generate other answers?</li>
<li>Diversity objectives</li>
</ul></li>
</ul>
</section>
</section>
<section id="retrieval-augmented-multimodal-language-modeling" class="level2">
<h2 class="anchored" data-anchor-id="retrieval-augmented-multimodal-language-modeling">Retrieval-Augmented Multimodal Language Modeling</h2>
<p>Paper: <a href="https://arxiv.org/abs/2211.12561">https://arxiv.org/abs/2211.12561</a></p>
<p>Recent multimodal models such as DALL-E and CM3 have achieved remarkable progress in text-to-image and image-to-text generation. However, these models store all learned knowledge (e.g., the appearance of the Eiffel Tower) in the model parameters, requiring increasingly larger models and training data to capture more knowledge. To integrate knowledge in a more scalable and modular way, we propose a retrieval-augmented multimodal model, which enables a base multimodal model (generator) to refer to relevant text and images fetched by a retriever from external memory (e.g., documents on the web). Specifically, for the retriever, we use a pretrained CLIP, and for the generator, we train a CM3 Transformer on the LAION dataset. Our resulting model, named Retrieval-Augmented CM3 (RA-CM3), is the first multimodal model that can retrieve and generate both text and images. We show that RA-CM3 significantly outperforms baseline multimodal models such as DALL-E and CM3 on both image and caption generation tasks (12 FID and 17 CIDEr improvements on MS-COCO), while requiring much less compute for training (&lt;30% of DALL-E). Moreover, we show that RA-CM3 exhibits novel capabilities, such as faithful image generation and multimodal in-context learning (e.g., image generation from demonstrations).</p>
<ul>
<li>Develop a retrieval-augmented multimodal model, a first of it’s kind</li>
<li>The generator uses retrieved items for generation too</li>
<li>Retrieval augmented training - helped a lot</li>
</ul>
</section>
<section id="in-context-learning-user-simulators-for-task-oriented-dialog-systems" class="level2">
<h2 class="anchored" data-anchor-id="in-context-learning-user-simulators-for-task-oriented-dialog-systems">In-Context Learning User Simulators for Task-Oriented Dialog Systems</h2>
<ul>
<li>Code: <a href="https://github.com/telepathylabsai/prompt-based-user-simulator">https://github.com/telepathylabsai/prompt-based-user-simulator</a></li>
<li>Paper: <a href="https://arxiv.org/abs/2306.00774">https://arxiv.org/abs/2306.00774</a></li>
</ul>
<p>This paper presents a novel application of large language models in user simulation for task-oriented dialog systems, specifically focusing on an in-context learning approach. By harnessing the power of these models, the proposed approach generates diverse utterances based on user goals and limited dialog examples. Unlike traditional simulators, this method eliminates the need for labor-intensive rule definition or extensive annotated data, making it more efficient and accessible. Additionally, an error analysis of the interaction between the user simulator and dialog system uncovers common mistakes, providing valuable insights into areas that require improvement. Our implementation is available at this https URL.</p>
<ul>
<li>Rule based systems are still more accurate. However they mainly understand happy paths of a dialog system.</li>
<li>These LLM based approaches can explore unexpected behavior of users</li>
</ul>
</section>
<section id="challenges-in-post-training-quantization-of-vision-transformers" class="level2">
<h2 class="anchored" data-anchor-id="challenges-in-post-training-quantization-of-vision-transformers">Challenges in post-training quantization of Vision Transformers</h2>
<p>Paper: <a href="https://research.ibm.com/publications/challenges-in-post-training-quantization-of-vision-transformers">https://research.ibm.com/publications/challenges-in-post-training-quantization-of-vision-transformers</a></p>
<p>Vision Transformers recently showed outstanding performance in computer vision tasks. However, those models are compute and memory intensive that require accelerators with a large amount of memory like NVIDIA A100 graphic processing unit for training and even for inference. Post-training quantization is an appealing compression method, as it does not require retraining the models and labels to tune the model. In this paper, we look in depth at multiple models in terms of size, architecture, and training procedure and provide guidelines on how to quantize the model to an 8-bit integer, both weights and activations. We perform a well-rounded study on the effects of quantization and sensitivity to the quantization error. Moreover, we show that applying mixed-data precision quantization works well for most vision transformer models achieving up to 90% compression ratio within a 2% top-1 accuracy drop. This kind of quantization offers a trade-off between memory, compute, and performance of the models that are deployable with the current software and hardware stack.</p>
<ul>
<li>There’s a difference between Static vs Dynamic Quantization</li>
<li>Larger models are supposed to be easier to quantize, but not the case here</li>
<li>Signal to noise quantization ratio - SNQR</li>
<li>Partial Quantization: Some models that lost accuracy during dynamic quant, regained during 90% quant</li>
</ul>
</section>
<section id="generalization-in-graph-neural-networks-improved-pac-bayesian-bounds-on-graph-diffusion" class="level2">
<h2 class="anchored" data-anchor-id="generalization-in-graph-neural-networks-improved-pac-bayesian-bounds-on-graph-diffusion">Generalization in Graph Neural Networks: Improved PAC-Bayesian Bounds on Graph Diffusion</h2>
<p>Paper: <a href="https://proceedings.mlr.press/v206/ju23a/ju23a.pdf">https://proceedings.mlr.press/v206/ju23a/ju23a.pdf</a></p>
<p>Graph neural networks are widely used tools for graph prediction tasks. Motivated by their empirical performance, prior works have developed generalization bounds for graph neural networks, which scale with graph structures in terms of the maximum degree. In this paper, we present generalization bounds that instead scale with the largest singular value of the graph neural network’s feature diffusion matrix. These bounds are numerically much smaller than prior bounds for real-world graphs. We also construct a lower bound of the generalization gap that matches our upper bound asymptotically. To achieve these results, we analyze a unified model that includes prior works’ settings (i.e., convolutional and message-passing networks) and new settings (i.e., graph isomorphism networks). Our key idea is to measure the stability of graph neural networks against noise perturbations using Hessians. Empirically, we find that Hessian-based measurements correlate with observed generalization gaps of graph neural networks accurately; Optimizing noise stability properties for fine-tuning pretrained graph neural networks also improves the test performance on several graph-level classification tasks.</p>
<ul>
<li>Overfitting if there’s an imbalance between pretraining data and finetuning data size</li>
<li>Generalization gap
<ul>
<li>Not just cross validation loss</li>
<li>More detailed understanding - what networks are causing the overfitting</li>
<li>Generalization gap - measures the gap between training/test losses</li>
</ul></li>
</ul>
</section>
<section id="nlp-research-in-the-era-of-llms---unleashing-the-potential-of-llms-through-task-and-data-engineering" class="level2">
<h2 class="anchored" data-anchor-id="nlp-research-in-the-era-of-llms---unleashing-the-potential-of-llms-through-task-and-data-engineering">NLP Research in the Era of LLMs - Unleashing the Potential of LLMs through Task and Data Engineering</h2>
<p>Shafiq Joty gave this talk: https://raihanjoty.github.io/</p>
<section id="background-data-engineering" class="level3">
<h3 class="anchored" data-anchor-id="background-data-engineering">Background: Data Engineering</h3>
<ul>
<li>Hold the code fixed and invite research to improve the data (Andrew Ng)</li>
</ul>
</section>
<section id="background-rise-of-task-engineering" class="level3">
<h3 class="anchored" data-anchor-id="background-rise-of-task-engineering">Background: Rise of Task Engineering</h3>
<ul>
<li>Multi-task models with task prompts</li>
<li>Trained with many different instructions</li>
<li>Mentions prompt tuning again (soft tokens) ???</li>
</ul>
</section>
<section id="background-task-engineering" class="level3">
<h3 class="anchored" data-anchor-id="background-task-engineering">Background: Task Engineering</h3>
</section>
<section id="llm-lifecycle" class="level3">
<h3 class="anchored" data-anchor-id="llm-lifecycle">LLM Lifecycle</h3>
</section>
<section id="xgen-llm-june-2023" class="level3">
<h3 class="anchored" data-anchor-id="xgen-llm-june-2023"><strong>XGen LLM</strong>: June 2023</h3>
<ul>
<li><a href="https://github.com/salesforce/xgen">GitHub Link</a></li>
<li>Goal is to outperform LLaMA1</li>
</ul>
</section>
<section id="instructed-tuned" class="level3">
<h3 class="anchored" data-anchor-id="instructed-tuned">Instructed tuned</h3>
<ul>
<li>Instructional data: WizardLM. <a href="https://arxiv.org/abs/2304.12244">Paper Link</a></li>
</ul>
</section>
<section id="what-does-wizardlm-do-exactly-in-advancing-the-sota" class="level3">
<h3 class="anchored" data-anchor-id="what-does-wizardlm-do-exactly-in-advancing-the-sota">What does WizardLM do exactly in advancing the SoTA?</h3>
<ul>
<li><p><a href="https://arxiv.org/abs/2304.12244">Details on WizardLM</a></p></li>
<li><p>Training large language models (LLMs) with open-domain instruction following data brings colossal success. However, manually creating such instruction data is very time-consuming and labor-intensive. Moreover, humans may struggle to produce high-complexity instructions. In this paper, we show an avenue for creating large amounts of instruction data with varying levels of complexity using LLM instead of humans. Starting with an initial set of instructions, we use our proposed Evol-Instruct to rewrite them step by step into more complex instructions. Then, we mix all generated instruction data to fine-tune LLaMA. We call the resulting model WizardLM. Human evaluations on a complexity-balanced test bed and Vicuna’s testset show that instructions from Evol-Instruct are superior to human-created ones. By analyzing the human evaluation results of the high complexity part, we demonstrate that outputs from our WizardLM are preferred to outputs from OpenAI ChatGPT. In GPT-4 automatic evaluation, WizardLM achieves more than 90% capacity of ChatGPT on 17 out of 29 skills. Even though WizardLM still lags behind ChatGPT in some aspects, our findings suggest that fine-tuning with AI-evolved instructions is a promising direction for enhancing LLMs. Our code and data are public at this https URL</p></li>
<li><p><strong>Verify and Edit CoT</strong> - Self-consistency</p></li>
<li><p>Knowledge adapting framework</p></li>
<li><p>Language diversity prompting</p></li>
<li><p>Standard vs Personalized Distillation from LLMs</p></li>
</ul>
</section>
</section>
<section id="modular-large-language-model-and-principle-driven-alignment-with-minimal-human-supervision" class="level2">
<h2 class="anchored" data-anchor-id="modular-large-language-model-and-principle-driven-alignment-with-minimal-human-supervision">Modular Large Language Model and Principle-Driven alignment with Minimal Human Supervision</h2>
<p>Yikang Shen from IBM gave this talk.</p>
<section id="foundation-model-types" class="level3">
<h3 class="anchored" data-anchor-id="foundation-model-types">Foundation model types</h3>
<section id="challenges-of-llm" class="level4">
<h4 class="anchored" data-anchor-id="challenges-of-llm">Challenges of LLM</h4>
<ul>
<li><strong>Efficiency</strong></li>
<li><strong>Extendability</strong></li>
<li><strong>Flexibility</strong></li>
</ul>
</section>
</section>
<section id="moduleformer---learning-modular-llm-from-uncurated-data" class="level3">
<h3 class="anchored" data-anchor-id="moduleformer---learning-modular-llm-from-uncurated-data">ModuleFormer - Learning Modular LLM from Uncurated Data</h3>
<ul>
<li>Previous modular models were based on already labeled data</li>
</ul>
</section>
<section id="mod-squad---designing-a-mixture-of-experts-as-modular-multi-task-learners" class="level3">
<h3 class="anchored" data-anchor-id="mod-squad---designing-a-mixture-of-experts-as-modular-multi-task-learners">Mod-Squad - designing a mixture of experts as modular multi-task learners</h3>
<ul>
<li>Can select the right experts for a task</li>
<li>Experts can share knowledge!?</li>
</ul>
</section>
<section id="dromedary---efficiently-teach-ai-to-follow-a-given-set-of-principles" class="level3">
<h3 class="anchored" data-anchor-id="dromedary---efficiently-teach-ai-to-follow-a-given-set-of-principles">Dromedary - efficiently teach AI to follow a given set of principles</h3>
<ul>
<li><a href="https://github.com/IBM/Dromedary">GitHub Link for Dromedary</a></li>
<li><strong>Principle Engraving</strong> -</li>
<li><strong>Verbose Cloning</strong> - refining the model to produce in-depth and detailed response</li>
<li>300 lines of annotations</li>
<li>Kind of similar to Evol-Instruct/WizardLM to produce annotations to fine-tune a model</li>
</ul>
</section>
</section>
<section id="autohint-automatic-prompt-optimization-with-hint-generation" class="level2">
<h2 class="anchored" data-anchor-id="autohint-automatic-prompt-optimization-with-hint-generation">AutoHint: Automatic Prompt Optimization with Hint Generation</h2>
<p>Paper: <a href="https://arxiv.org/pdf/2307.07415.pdf">https://arxiv.org/pdf/2307.07415.pdf</a></p>
<p>This paper presents AutoHint, a novel framework for automatic prompt engineering and optimization for Large Language Models (LLM). While LLMs have demonstrated remarkable ability in achieving high-quality annotation in various tasks, the key to applying this ability to specific tasks lies in developing high-quality prompts. Thus we propose a framework to inherit the merits of both in-context learning and zero-shot learning by incorporating enriched instructions derived from input-output demonstrations to optimize original prompt. We refer to the enrichment as the Hint and propose a framework to automatically generate the hint from labeled data. More concretely, starting from an initial prompt, our method first instructs a LLM to deduce new hints for selected samples from incorrect predictions, and then summarizes from per-sample hints and adds the results back to the initial prompt to form a new, enriched instruction. The proposed method is evaluated on the BIG-Bench Instruction Induction dataset for both zero-shot and few-short prompts, where experiments demonstrate our method is able to significantly boost accuracy for multiple tasks</p>
</section>
</section>
<section id="causal-inference-workshop-causal-inference-and-machine-learning-in-practice" class="level1">
<h1>Causal Inference Workshop: Causal Inference and Machine Learning in Practice</h1>
<p>The website for this workshop is here: https://causal-machine-learning.github.io/kdd2023-workshop/</p>
<section id="cog-creative-optimality-gap-for-video-advertising" class="level2">
<h2 class="anchored" data-anchor-id="cog-creative-optimality-gap-for-video-advertising">COG: Creative Optimality Gap for Video Advertising</h2>
<p>Raif Rustamov from Amazon gave this invited talk.</p>
<section id="video-ads-motivation" class="level3">
<h3 class="anchored" data-anchor-id="video-ads-motivation">Video ads motivation</h3>
<ul>
<li>How does a particular video affect shopper experience?</li>
</ul>
</section>
<section id="goal" class="level3">
<h3 class="anchored" data-anchor-id="goal">Goal</h3>
<ul>
<li>Driven by explicit hypotheses tied to quantifying value of the video</li>
</ul>
</section>
<section id="approach---creative-optimality-gap-cog" class="level3">
<h3 class="anchored" data-anchor-id="approach---creative-optimality-gap-cog">Approach - Creative Optimality Gap (COG)</h3>
<ul>
<li>If we were to replace the video of class 0 to video of class 1, what would be the improvement in the outcome for the ad?</li>
<li><strong>Uplift or Heterogenous Treatment Effect modeling</strong></li>
</ul>
</section>
<section id="benefits" class="level3">
<h3 class="anchored" data-anchor-id="benefits">Benefits</h3>
<ul>
<li>Differentiated at the level of video features vs.&nbsp;global ATE
<ul>
<li><strong>ATE</strong> - average treatment effect - videos are good</li>
<li><strong>ITE</strong> - individual treatment effect - noisy</li>
<li><strong>HTE</strong> - heterogeneous treatment effect - in the middle, denoising</li>
</ul></li>
<li>Handle cold start ads</li>
</ul>
</section>
<section id="preliminaries" class="level3">
<h3 class="anchored" data-anchor-id="preliminaries">Preliminaries</h3>
<ul>
<li><strong>Treatment indicator (T)</strong></li>
<li><strong>Video features</strong>
<ul>
<li>Computed using e.g.&nbsp;video embeddings</li>
<li>Can contain non</li>
</ul></li>
<li><strong>Ad features</strong>
<ul>
<li>Contains non-video related features like price, product category</li>
<li>Used as confounder/matching variables</li>
</ul></li>
<li><strong>Outcome = Y</strong></li>
</ul>
</section>
<section id="cog-modeling" class="level3">
<h3 class="anchored" data-anchor-id="cog-modeling">COG Modeling</h3>
<ul>
<li><strong>Step 1</strong></li>
<li><strong>Step 2</strong></li>
<li><strong>Step 3</strong> -
<ul>
<li>Used interpretable models in this step, why?</li>
</ul></li>
</ul>
</section>
<section id="cog-modeling-guardrails" class="level3">
<h3 class="anchored" data-anchor-id="cog-modeling-guardrails">COG Modeling: Guardrails</h3>
<section id="bias" class="level4">
<h4 class="anchored" data-anchor-id="bias">Bias</h4>
<ul>
<li>Bias comes from G model, comes from regularization or not enough capacity in the model</li>
<li>Bias is not constant but varies in the Z space</li>
<li>Double ML?</li>
</ul>
</section>
<section id="uncertaintyvariance" class="level4">
<h4 class="anchored" data-anchor-id="uncertaintyvariance">Uncertainty/Variance</h4>
</section>
</section>
<section id="solution" class="level3">
<h3 class="anchored" data-anchor-id="solution">Solution</h3>
<ul>
<li>Conservative COG = lower bound of confidence interval</li>
</ul>
</section>
</section>
<section id="the-value-of-last-mile-delivery-in-online-retail" class="level2">
<h2 class="anchored" data-anchor-id="the-value-of-last-mile-delivery-in-online-retail">The Value of Last-Mile Delivery in Online Retail</h2>
<p>Ruomeng Cui from Emory gave this talk.</p>
<section id="cainiao---chinese-company" class="level3">
<h3 class="anchored" data-anchor-id="cainiao---chinese-company">Cainiao - Chinese Company</h3>
<ul>
<li>Alibaba’s logistics platform</li>
<li>Largest logistics platform in China</li>
<li>If there are differences in preferences, there is an opportunity for optimization</li>
</ul>
</section>
<section id="use-causal-ml-estimating-ite" class="level3">
<h3 class="anchored" data-anchor-id="use-causal-ml-estimating-ite">Use Causal ML: Estimating ITE</h3>
<ul>
<li><strong>Data:</strong> Post-treatment data Q4 2021</li>
</ul>
</section>
<section id="models" class="level3">
<h3 class="anchored" data-anchor-id="models">Models</h3>
<ul>
<li>Partial Linear DML</li>
<li>First-difference DML</li>
<li>Others</li>
</ul>
</section>
<section id="account-for-knapsnack" class="level3">
<h3 class="anchored" data-anchor-id="account-for-knapsnack">Account for Knapsnack</h3>
<ul>
<li>Tau does not capture economic efficiency</li>
<li>Need to account for how much capacity a customer is using. A customer going from 0 to 1 unit sales is much more valuable than a customer going from 19 to 20 units sold because the latter is not using much capacity.</li>
</ul>
</section>
</section>
<section id="leveraging-causal-uplift-modeling-for-budget-constrained-benefits-allocation" class="level2">
<h2 class="anchored" data-anchor-id="leveraging-causal-uplift-modeling-for-budget-constrained-benefits-allocation">Leveraging Causal Uplift Modeling for Budget Constrained Benefits Allocation</h2>
<p>Dmitri Goldenberg from Booking.com gave this talk. It was a very good talk with virtually no words on his slides.</p>
</section>
<section id="ensemble-method-for-estimating-individualized-treatment-effects-kevin-wu-han-han-wu-stanford" class="level2">
<h2 class="anchored" data-anchor-id="ensemble-method-for-estimating-individualized-treatment-effects-kevin-wu-han-han-wu-stanford">Ensemble Method for Estimating Individualized Treatment Effects Kevin Wu Han, Han Wu (Stanford)</h2>
<ul>
<li>Paper: <a href="https://arxiv.org/abs/2202.12445">https://arxiv.org/abs/2202.12445</a></li>
<li>Ensemble methods almost always perform a validation-set model selection based method!</li>
</ul>
</section>
<section id="a-scalable-and-debiased-approach-to-dynamic-pricing-with-causal-machine-learning-and-optimization" class="level2">
<h2 class="anchored" data-anchor-id="a-scalable-and-debiased-approach-to-dynamic-pricing-with-causal-machine-learning-and-optimization">A Scalable and Debiased Approach to Dynamic Pricing with Causal Machine Learning and Optimization</h2>
<ul>
<li>Heard the term double machine learning for the second time which caused me to do to learn what it is.</li>
</ul>
</section>
<section id="an-ipw-based-unbiased-ranking-metric-in-two-sided-markets-keisho-oh-naoki-nishimura-recruit-co-minje-sung-ken-kobayashi-kazuhide-nakata-tokyo-institute-of-technology" class="level2">
<h2 class="anchored" data-anchor-id="an-ipw-based-unbiased-ranking-metric-in-two-sided-markets-keisho-oh-naoki-nishimura-recruit-co-minje-sung-ken-kobayashi-kazuhide-nakata-tokyo-institute-of-technology">An IPW-based Unbiased Ranking Metric in Two-sided Markets Keisho Oh, Naoki Nishimura (Recruit Co), Minje Sung, Ken Kobayashi, Kazuhide Nakata (Tokyo Institute of Technology)</h2>
<p>In two-sided markets like job-matching or dating-apps, need to use an unbiased ranking metric which they propose in their paper.</p>
</section>
<section id="unit-selection-based-on-counterfactual-logic" class="level2">
<h2 class="anchored" data-anchor-id="unit-selection-based-on-counterfactual-logic">Unit Selection Based on Counterfactual Logic</h2>
<p>This was an invited talk by Ang Li about this paper: <a href="https://ftp.cs.ucla.edu/pub/stat_ser/r488.pdf">https://ftp.cs.ucla.edu/pub/stat_ser/r488.pdf</a>.</p>
<p>My main takeaway was dividing a population into a typical A/B test where one group receives a treatment and the other group is the control is too simplistic. There are actually 4 groups we should be concerned about:</p>
<ul>
<li>Complier: Individuals who would respond positively if treated and negatively if not treated.</li>
<li>Always-taker: Individuals who always respond positively no matter whether they are treated or not.</li>
<li>Never-taker: Individuals who always respond negatively no matter whether they are treated or not.</li>
<li>Defier: Individuals who would respond negatively if treated and positively if not treated.</li>
</ul>
<p>Along with a benefit vector that assigns a positive or negative value to each of these 4 groups, we can use this to select the best treatment for each individual.</p>
<p>Ang also used the Pfizer Covid vaccine as a motivating example for why these 4 groups should be accounted for.</p>
</section>
<section id="towards-automating-the-causal-machine-learning-pipeline-vasilis-syrgkanis-stanfordeconml" class="level2">
<h2 class="anchored" data-anchor-id="towards-automating-the-causal-machine-learning-pipeline-vasilis-syrgkanis-stanfordeconml">Towards Automating the Causal Machine Learning Pipeline Vasilis Syrgkanis (Stanford/EconML)</h2>
<ul>
<li>A large variety of causal estimands that arise in complex static and longitudinal data analysis can be automatically de-biased when regularized machine learning algorithms are used to estimate nuisance models</li>
<li>Estimation of the de-biasing term itself can be performed with generic machine learning</li>
<li>Experimental results using neural nets and random forests for automated de-biasing provide examples superior performance to plug-in approaches and to prior automatically debasing approaches based solely on linear models</li>
</ul>


</section>
</section>

 ]]></description>
  <category>Conference</category>
  <category>KDD</category>
  <category>LLM</category>
  <category>Causal Inference</category>
  <guid>https://lawwu.github.io/blog.html/conferences/2023-08-07-kdd2023-day1/</guid>
  <pubDate>Mon, 07 Aug 2023 00:00:00 GMT</pubDate>
</item>
</channel>
</rss>
