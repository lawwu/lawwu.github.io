[
  {
    "objectID": "ai_resources.html",
    "href": "ai_resources.html",
    "title": "AI/ML/NLP Resources",
    "section": "",
    "text": "Maintaining a ml_timeline, inspired by @osanseviero"
  },
  {
    "objectID": "ai_resources.html#podcasts",
    "href": "ai_resources.html#podcasts",
    "title": "AI/ML/NLP Resources",
    "section": "Podcasts",
    "text": "Podcasts\n\nDeepPapers - Deep Papers is a podcast series featuring deep dives on today’s seminal AI papers and research"
  },
  {
    "objectID": "ai_resources.html#youtube",
    "href": "ai_resources.html#youtube",
    "title": "AI/ML/NLP Resources",
    "section": "YouTube",
    "text": "YouTube\n\n@lexfridman - and associated transcripts\n@AndrejKarpathy\n@jamesbriggs\n@ai-explained-"
  },
  {
    "objectID": "ai_resources.html#twitter",
    "href": "ai_resources.html#twitter",
    "title": "AI/ML/NLP Resources",
    "section": "Twitter",
    "text": "Twitter\n\n@jeremyphoward\n@radekosmulski\n@omarsar0"
  },
  {
    "objectID": "ai_resources.html#newsletters",
    "href": "ai_resources.html#newsletters",
    "title": "AI/ML/NLP Resources",
    "section": "Newsletters",
    "text": "Newsletters\n\nDavis Summarizes Papers\nData Science Programming News - Run by Eric J Ma"
  },
  {
    "objectID": "ai_resources.html#libraries-tools",
    "href": "ai_resources.html#libraries-tools",
    "title": "AI/ML/NLP Resources",
    "section": "Libraries / Tools",
    "text": "Libraries / Tools\n\nGithub Copilot - I use Copilot in my IDE, VS Code and it’s dramatically improved my producitivity (10-20%?). More than that it makes coding less tedious and lowers the activiation energy for coding tasks. For example generating docstrings is trivial (and happens much more frequently!). And because the recommendations are inline, the developer’s ‘flow’ is not broken. I also moved from Jupyter Notebooks in a browser to using Jupyter in VS Code. Radek Omulski has a blog post for how to set this up.\nLangChain - Building applications with LLMs through composability\nllama_index - LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM’s with external data.\nstreamlit - Python framework for buliding UIs. I’ve used this a lot for data science demos. Resources to inspire you: awesome-streamlit and Streamlit’s gallery\ngradio - similar to Streamlit but more for ML/NLP models.\nmarvin - Meet Marvin: a batteries-included library for building AI-powered software. Marvin’s job is to integrate AI directly into your codebase by making it look and feel like any other function."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Lawrence Wu",
    "section": "",
    "text": "Staying Human in the Age of LLMs\n\n\n\n\n\n\n\nLLMs\n\n\nWork\n\n\nGPT\n\n\n\n\n\n\n\n\n\n\n\nMay 28, 2023\n\n\n3 min\n\n\n\n\n\n\n\n\nLarge Language Models, Work and the Future of Jobs\n\n\n\n\n\n\n\nLLMs\n\n\nWork\n\n\nGPT\n\n\nOpenAI\n\n\n\n\n\n\n\n\n\n\n\nMay 5, 2023\n\n\n6 min\n\n\n\n\n\n\n\n\nGPT Related Papers, Code, and News\n\n\n\n\n\n\n\nGPT\n\n\nOpenAI\n\n\n\n\n\n\n\n\n\n\n\nApr 4, 2023\n\n\n4 min\n\n\n\n\n\n\n\n\nUseful Applications (mostly for Mac)\n\n\n\n\n\n\n\nProductivity\n\n\nDeveloper Tools\n\n\n\n\n\n\n\n\n\n\n\nMar 24, 2023\n\n\n4 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lawrence Wu",
    "section": "",
    "text": "Hi! My name is Lawrence and I’m a data scientist who loves deriving insight and value from data. I enjoy building machine learning and NLP solutions that make a difference. Currently I’m a Principal Data Scientist at UKG. Prior to that, I’ve held data science positions at Medidata, PIMCO, Payoff and Allianz. Prior to getting into data science, I was an actuary.\nOn this site I keep a technical blog and resume."
  },
  {
    "objectID": "posts/2023-04-04-gpt4/index.html",
    "href": "posts/2023-04-04-gpt4/index.html",
    "title": "GPT Related Papers, Code, and News",
    "section": "",
    "text": "There’s seemingly a firehose of development in the last month or so. I’ve been trying to keep up with the latest developments in GPT and related models. Here’s a list of papers, code, and news that I’ve found interesting. This is mainly for myself to have a reference, but I hope it’s useful to others as well. I was largely inspired by @osanseviero who created ml_timeline.\n\nPapers\n\n2022-08-21 - Emergent Abilities of Large Language Models (paper, blog)\n2023-03-13 - Alpaca – Stanford’s CRFM group released a 1.5B parameter GPT-3 like model. They were the first to demonstrate you can get GPT-like performance using only 52k instruction-following data points. On the self-instruct evaluation set, Alpaca shows many behaviors similar to OpenAI’s text-davinci-003, but is also surprisingly small and easy/cheap to reproduce. I think one reason OpenAI dropped their pricing by 90% with GPT-4 is because they wanted to achieve wide distribution of their model.\n2023-03-15 - GPT-4 Technical Paper (paper) - highlights some of the amazing improvements GPT-4 has made over GPT-3\n2023-03-27 - GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models (paper) – Paper that identifies the occupations that have the highest exposure to automation by GPT. In related news, ResumeBuilder found 1 in 4 companies have already replaced workers with ChatGPT\n2023-03-22 - Sparks of Artificial General Intelligence (paper)\n2023-03-20 – Reflexion: an autonomous agent with dynamic memory and self-reflection (paper). A related post.\n2023-03-23 - AI Explained – GPT4 can improve itself (video) - Intro to Reflexion and HuggingGPT\n2023-03-30 - HuggingGPT: Solving AI Tasks with ChatGPT and its Friends in HuggingFace (paper, code) - Using a LLM as brain, HuggingGPT identifies what HuggingFace models to use to solve tasks. Notably Microsoft is calling this JARVIS.\n\n\n\nLibraries / Tools\n\nGithub Copilot - I use Copilot in my IDE, VS Code and it’s dramatically improved my producitivity (10-20%?). More than that it makes coding less tedious and lowers the activiation energy for coding tasks. For example generating docstrings is trivial (and happens much more frequently!). And because the recommendations are inline, the developer’s ‘flow’ is not broken. I also moved from Jupyter Notebooks in a browser to using Jupyter in VS Code. Radek Omulski has a blog post for how to set this up. I do plan to try GenAI as well. I tried GenAI and it basically automatically sends all errors to ChatGPT and provides suggested corrected syntax to try in line in your Jupyter notebook. It actually can be a nice complement to Copilot.\nLangChain - Building applications with LLMs through composability\nllama_index - LlamaIndex (GPT Index) is a project that provides a central interface to connect your LLM’s with external data.\nGenAI - generative AI tooling for IPython\nmarvin - Meet Marvin: a batteries-included library for building AI-powered software. Marvin’s job is to integrate AI directly into your codebase by making it look and feel like any other function.\n\n\n\nPrompt Engineering\nPrompt engineering is the process of creating prompts for LLMs. Essentially optimizing the input into LLMs.\n\nWhat is Prompt Engineering - like how Googling became a skill (aka “Google-fu”), I think Prompt Engineering is an important skill to develop\nawesome-chatgpt-prompts - A curated list of awesome ChatGPT prompts. I like “Act as a Linux Terminal” prompt.\nPrompt Engineering Guide - “Motivated by the high interest in developing with LLMs, we have created this new prompt engineering guide that contains all the latest papers, learning guides, lectures, references, and tools related to prompt engineering.” Code: repo.\n\n\n\nOutput Parsers\nWhere prompt engineering works on the input to LLMs, output parsers work on the output.\n\nOutput Parsers - LangChain calls this “Output Parsers”. LangChain can return a list, JSON, any Python type (using Pydantic) and two other ways of handling outputs: OutputFixingParser and RetryOutputParser\nEnforcing AI Format - Marvin calls this “Enforcing AI format”. Marvin can return a string, list of dicts, JSON or really any Python type (using Pydantic)\n\n\n\nPredictions\n\n2023-04-01 - @AllenDowney predicts “The great majority of coding will be LLM-assisted, starting now.” (tweet, blog)"
  },
  {
    "objectID": "posts/2023-05-05-llm-work-jobs/index.html",
    "href": "posts/2023-05-05-llm-work-jobs/index.html",
    "title": "Large Language Models, Work and the Future of Jobs",
    "section": "",
    "text": "Last month, Allen Downey showcased the power of ChatGPT by using it to solve every problem in his Think Python books. As a result, he encouraged everyone who writes code to use LLM-assistance in their development. This inspired me to further explore the capabilities of GPT-4 and its potential effects on work and productivity.\nLarge Language Models (LLMs) like ChatGPT are already transforming the way we work. Even in my work as a data scientist, ChatGPT (actually GPT-4) has dramatically affected how I work and my daily tasks. Just a quick listing out of some of the prompts I’ve sent to GPT-4 in the last month:\n\nExtracting features from pairs of resumes and job descriptions in JSON\nCopy pasted a Linux error OSError: [Errno 28] inotify watch limit reached and GPT-4 explained what the error was and how to fix it (unprompted)\nWhat factors to consider what going from a individual contributor to a manager role\nCopy pasted a SQL query to debug it\nHow to make a tensor of 0’s of a data type Long and Int\nIn PyTorch what does batch_first=False do?\nHelp writing a MLOps Python wrapper package that wraps Vertex AI Pipelines\nCopy and pasted\n\n187 packages can be updated.\n27 updates are security updates.\nAnd it responded with commands for how to update package lists, upgrade packages and do a distribution upgrade too\n\nReformat JSON dictionaries\nHelping to write unit tests\n\nIt’s difficult to quantify how much time GPT-4 has saved me, which it certainly has. I’d estimate it on average saves me about 1 hour of work per day. More than the time saved, the value of LLMs has been lowering the activation energy needed to get started. With data science and coding related prompts, I can arrive at answers much more directly and therefore quickly than trying to search Google and read StackOverflow answers. The code GPT-4 returns doesn’t always work the first time (zero-shot). In most cases, if an error is returned by that code, putting the error code back into the prompt will allow GPT-4 to generate correct code (one-shot, few-shot).\nAlong with Github Copilot, which is like autocomplete for code in an IDE like VS Code or PyCharm, I will likely never go back to coding without these assistants. They make me that much more productive. Though it’s also difficult to quantify how much more productive, 5%? 10%? 50%? There have been stories of people losing their jobs because of these technologies, but these are still relatively rare. I think the short-term impacts of these tools is making those that use them much more productive than those that don’t. Allen Downey wrote a post about LLM-assisted programming where he said:\n\nWhich brings me to what I think will be the most important skill for LLM-assisted programming: reading code. LLMs can generate code much faster than we can understand it, so the ability to read, understand, and check code will be critical.\n\n\nThe other skill that will become more important is meta-language, that is, the vocabulary we use to talk about programs. In my correlation in Elm example, I asked ChatGPT to “factor out the anonymous function”, and it new exactly what I meant. In general, it seems to understand the meta-language of programming well, so it will be useful if we can speak it.\n\nI tend to agree with his points. Reading code is going to be critical. Also knowing the right terminology or “meta-language” as Downey calls it to prompt the LLM is also critical. For example, using Github Copilot I was working in a Jupyter Notebook preparing some data for a model that was in a dataframe. I wrote a comment “# pivot this from wide to long” and the LLM was able to generate the code to do exactly what I needed. This took 5 seconds instead of 30-60 seconds to Google and arrive at this SO answer. But one would need to know what terms like “pivot” and what “wide” and “long” data are (see Hadley Wickham’s Tidy Data paper to learn more).\nTechnological advancements inevitably change jobs and work dynamics. Some jobs may disappear, while others may evolve, and new ones will emerge. Although it’s difficult to predict the pace and extent of these changes, there already have been a few studies on the topic. But I would take these with a grain of salt given how difficult it is to forecast the future.\n\n2023-03-02 - How will Language Modelers like ChatGPT Affect Occupations and Industries?\n2023-03-17 - GPTs are GPTs: An Early Look at the Labor Market Impact Potential of Large Language Models\n2023-04-23 - The Future of ChatGPT-enabled Labor Market: A Preliminary Study\n\nWhat is more valuable is waiting for real-world examples of how LLMs are affecting work. Here are some examples I’ve seen:\n\n2023-05-02 - IBM CEO Arvind Krishna says 30% of backoffice non-customer facing roles like human resources being replaced by AI. That’s 30% of 26,000 roles or 7,800 roles being replaced over the next 5 years. See this article for more details.\n2023-04-27 - In a letter to Dropbox employees, CEO Drew Houston said the company is laying off 16% of its workforce. He said the company is shifting its focus to early-stage product development and AI. See the full letter here. Two very interesting quotes where he talks about not being able to upskill his current workforce and needing to hire new talent:\n\n\nSecond, and more consequentially, the AI era of computing has finally arrived. We’ve believed for many years that AI will give us new superpowers and completely transform knowledge work. And we’ve been building towards this future for a long time, as this year’s product pipeline will demonstrate.\n\n\nIn an ideal world, we’d simply shift people from one team to another. And we’ve done that wherever possible. However, our next stage of growth requires a different mix of skill sets, particularly in AI and early-stage product development. We’ve been bringing in great talent in these areas over the last couple years and we’ll need even more.\n\nIt’ll be certainly interesting to see how these technologies continue to evolve and how they affect work."
  },
  {
    "objectID": "posts/2023-05-28-staying-human/index.html",
    "href": "posts/2023-05-28-staying-human/index.html",
    "title": "Staying Human in the Age of LLMs",
    "section": "",
    "text": "The WSJ’s Ben Cohen wrote an article highlighting Professor Po-Shen Loh, a math professor from Carnegie Mellon University and coach for Team USA’s International Mathematical Olympiad. He’s currently touring the country with a mission to inspire a love of mathematics and provide practical guidance for the new challenges brought by AI and tools like ChatGPT (giving 50 lectures in 32 cities in 35 days!). Loh’s message is clear: to survive in this era of artificial intelligence, one must lean into what makes us human.\nLoh emphasizes the importance of creativity, emotion, and human uniqueness, skills that AI cannot replicate, and which will become increasingly valuable as AI becomes more advanced. He wants young minds to understand the importance of their humanity in an AI-dominated future. However, this lesson is not just for students but applies to all businesses trying to navigate the uncharted territory of AI integration.\nThe new generation, Loh asserts, will have a better intuitive understanding of AI as they’re the first to grow up with this technology as a constant in their lives. With tools like ChatGPT being used in everyday life, young people are already interacting with and understanding the implications of AI. Being a millenial, though I do remember a time when there was no internet and needing to use a physical copy of Encylopedia Brittanica to do research, my generation grew up with Google and being able to access information at our fingertips. This next generation will grow up with AI and ChatGPT-like technologies as a constant in their lives.\nPo-Shen Loh’s message, while initially targeted towards students, has a universality that is applicable beyond the boundaries of classrooms; it serves as crucial advice for anyone preparing for the future of work in an AI-integrated world. Loh emphasizes the indispensable qualities of being able to create value and identify human pain points. In his words, “The future of jobs is figuring out how to find pain points, and a pain point is a human pain… You need to be able to create value. People who make value will always have opportunities.”\nI wholeheartedly concur with Loh’s perspective. In today’s rapidly advancing digital age, we can already see a distinct division emerging between those leveraging large language models (LLMs) like ChatGPT effectively in their work, and those who do not. These tools can augment human capabilities, enable more efficient processes, and offer innovative solutions to complex problems.\nHowever, it is not the tools alone that will secure a competitive advantage. Instead, it is the ability to apply these tools ingeniously and to couple their computational prowess with human creativity, intuition, and understanding of complex human needs. This blend of technological aptitude and human sensitivity is what will differentiate the truly successful individuals and organizations in the future.\nLoh’s message should serve as a call to action for individuals and businesses alike: value creation, coupled with understanding and addressing human-centric concerns, is what will allow us to thrive in the AI-enhanced future. Those who can combine their unique human skills with the power of AI, to enhance their problem-solving capabilities and offer more value, will always find themselves at an advantageous position."
  },
  {
    "objectID": "posts/2023-03-24-mac-apps/index.html",
    "href": "posts/2023-03-24-mac-apps/index.html",
    "title": "Useful Applications (mostly for Mac)",
    "section": "",
    "text": "In this blog post, I’ll introduce you to a list of useful applications, covering both developer tools and productivity applications that I’ve found useful over the years. I’ll also provide you with a brief overview of each app, including its key features and how it can help you improve your workflow. This is mostly Mac focused, though some of these are available on other operating systems.\n\nProductivity\nGoogle Chrome: I’ve tried other browsers but I still find myself going back to Chrome.\nWorkflowy: A simple yet powerful app for note-taking, outlining, and task management, Workflowy helps you organize your thoughts and projects using nested lists and intuitive keyboard shortcuts. It’s simple at it’s core as Workflowy is essentially an infinitely nested bulleted list. They’ve added additional features over the years like mirroring lists which I’ve found helpful. Notion may have more features but I haven’t overcome the intertia needed to switch yet.\nTodoist: A great multi platform to-do list app. One of my favorite features is being able to type dates and/or times that Todoist will parse into a due date. Because of my poor memory, I need to write everything down. If it’s task-related, it will go into Todoist. On a related note, the Reminders app on an Apple Watch is also useful for capturing todos on the go. I hold the crown to activate Siri and say “Remind me to do X at tomorrow at 10pm” and this reminder will pop-up at tomorrow 10pm on my iPhone.\nRectangle: A window management app for macOS, Rectangle enables you to quickly and effortlessly resize and organize your windows using keyboard shortcuts or by dragging windows to screen edges. Iused to use ShiftIt which did something similar but Rectangle does the same thing but works on the latest versions of macOS.\nStats: An open-source system monitor for macOS, Stats provides you with detailed information on your CPU, memory, disk, network, and battery usage, all accessible from your menu bar. I used to pay for iStat Menus but stats is an open source version.\nAmphetamine: Keep your Mac awake and prevent it from sleeping with Amphetamine, a powerful and customizable app that allows you to set rules based on applications, time, or power source. Similar to the Caffiene app.\nBe Focused: A productivity-enhancing time management app, Be Focused utilizes the Pomodoro Technique to help you break work into manageable intervals, maintain focus, and stay on track. I find using Pomodoros, setting 25 minute timers of focused work to be incredibly helpful.\nHidden Bar: A minimalist app that allows you to declutter your Mac’s menu bar by hiding icons you don’t need to see all the time, Hidden Bar lets you access these icons with a simple click whenever needed.\n1Password: A reliable password manager. Been using it since version 5.\n\n\nDeveloper Tools\nHomebrew: A must-have package manager for macOS, Homebrew makes it easy to install, update, and manage software packages, including command-line tools and graphical applications.\nVisual Studio Code: A versatile and free source code editor developed by Microsoft, Visual Studio Code supports a wide range of programming languages and comes with built-in support for Git, intelligent code completion, and a plethora of extensions to customize your coding environment.\niTerm2: A highly customizable and feature-rich terminal emulator for macOS, iTerm2 improves upon the default Terminal app with features like split panes, search functionality, and extensive customization options.\nAnaconda/Miniconda: Anaconda is a powerful Python and R distribution that simplifies package management and deployment, while Miniconda is its lightweight counterpart. Both options provide you with the essential tools to set up and manage your data science and machine learning environments.\nzsh: zsh has become my bash replacement.\nOh My Zsh: Makes zsh more useful with a bunch of plugins.\nSublime Text: A sophisticated and lightning-fast text editor designed for code, markup, and prose, Sublime Text offers a sleek interface, multiple selections, and a highly extensible plugin API.\nHere’s a bash script to install all of these packages:\n#!/bin/bash\n\n# Install Homebrew if not already installed\nif ! command -v brew &gt;/dev/null 2&gt;&1; then\n  /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)\"\nfi\n\n# Update Homebrew and install required packages\nbrew update\nbrew tap homebrew/cask\nbrew tap homebrew/cask-versions\n\n# Productivity\nbrew install --cask google-chrome\nbrew install --cask workflowy\nbrew install --cask todoist\nbrew install --cask rectangle\nbrew install --cask stats\nbrew install --cask amphetamine\nbrew install --cask be-focused\nbrew install --cask hiddenbar\nbrew install --cask 1password\n# uncomment for 1password 6.8.9\n# brew install --cask https://raw.githubusercontent.com/Homebrew/homebrew-cask-versions/master/Casks/1password6.rb\nbrew install --cask dropbox\n\n# Developer Tools\nbrew install --cask visual-studio-code\nbrew install --cask iterm2\nbrew install anaconda\nbrew install zsh\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nbrew install --cask sublime-text\n\necho \"Installation complete!\"\nSave the script in a file named install_apps.sh and make it executable using the following command:\nchmod +x install_apps.sh\nFinally, run the script using:\n./install_apps.sh"
  }
]